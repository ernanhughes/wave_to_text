{"text": " All right, so today we're going to be looking at AI and specifically how to make it a whole lot smarter, but without needing, you know, like a giant supercomputer. You're interested in these sparse expert models, right? And specifically this paper about STMOe, stable and transferable mixture of experts. It sounds kind of intimidating. I think the idea is actually really elegant. It is. Think about it this way. Instead of one massive AI brain, you know, trying to process everything. What if you had a team of specialized experts? What if you had a team of people who were able to make a smart AI? What if you had a team of people who were able to make a smart computer? What if you had a team of people who were able to make a smart computer? What if you had a team of people who were able to make a smart computer? What if you had a Each one incredibly good at their own thing. That's the core concept behind these sparse expert models. OK, so it's less like one giant dictionary. More like having a linguist, a grammarian, a poet all working together. Yeah, that's a great analogy. And the ST part is really key here. Stable and transferable. Earlier attempts at this kind of AI were, well, a bit temperamental. STMOe is designed to be more reliable and also adaptable, meaning you can train it on one task and then easily apply it to something new without it forgetting everything it learned. So it's like having a team that can not only specialize, but also learn new skills really quickly. I've already seen the potential here. The paper mentions something pretty wild about robustness too. Absolutely. Imagine you're reading a text and you randomly skip like every tenth word. You can probably still understand the gist, right? Researchers found that these STMOe models have a similar ability. They can handle these missing chunks of information without completely falling apart. That's huge. Think about it. If these models can deal with like incomplete data, that makes them incredibly powerful for real world scenarios, analyzing damaged documents, understanding speech with errors, even making sense of, you know, fragmented online information. You're getting it. This robustness is a game changer. But as with anything, there are these tradeoffs. One thing that jumped out at me is that sparse models can be prone to overfitting, especially with smaller data sets. That sounds like that specialist who's brilliant in their narrow field, but they struggle when they're faced with something outside their expertise. They need that broader perspective. Exactly. The research suggests that fine tuning these models requires a different approach than what we use for the massive, dense models. Smaller batches of data, faster learning rates. It's like meeting a customized training regimen for like peak performance. And here's where things get really fascinating. So what happens when you close through these expert models? Isn't that cool? They traced individual words as they went through the model, like watching a tiny delivery truck carrying a word and dropping it off at the right expert's door. I love that. So instead of a black box, we're actually getting a peek behind the curtain of how this AI is actually thinking. What did they find? It was like watching different departments in a company, each with their own area of expertise. So we're not just training one giant AI. We're cultivating a whole ecosystem of specialized skills. And that, my friend, leads us to one of the biggest questions this research raises. They tried training these models on multiple languages. But something unexpected happened. They all became multilingual, handling every language thrown at them. So are they learning some kind of universal language structure, like a hidden code beneath all these human tongues? Or is it something about the way they're trained that's pushing them towards this jack-of-all-trades approach? Those are exactly the questions researchers are grappling with. And the answer could change how we think about AI and language forever. It makes you wonder what would happen if we could guide that specialization. Could we unlock even greater efficiency and accuracy? This is what I call the trivia. This is where I start to get a little mind-blown. We're talking about AI that not only understands language, but might be tapping into something fundamental about how it works. We are. And the implications are huge. Imagine AI that can seamlessly translate between any language. Or even help us decipher ancient texts by recognizing these deep linguistic structures. Could these models, with their focus on specific types of information, inadvertently amplify existing societal biases? It's an important point and something that needs careful consideration. As we develop these powerful tools, we have a responsibility to make sure they are used ethically and responsibly. One of the first things researchers had to figure out was how many experts should a model have? It seems intuitive that more experts would mean better performance. But that's not always the case. It's like having a team with all the best specialists, but their workspace is too small for them to actually collaborate effectively. Another key design element is something called the capacity factor, which basically determines how much information each expert can handle at once. OK, so it's like setting the size of each expert's desk, so to speak. Too small, and they're overwhelmed. Too big, and you're wasting space. A perfect analogy. And then there's the routing algorithm. This is the AI traffic cop that's been working on the AI. It's a system that decides which expert gets which piece of information. The research looked at several different routing strategies, and one that seems to work particularly well is called top two routing. So instead of sending a word to just one expert, it actually goes to the two that are most likely to understand it. Exactly. It's like having a backup plan, just in case that first expert isn't quite the right fit. The research also introduces this new routing technique. It's called batch prioritized routing, or BPR. Which seems especially helpful when you're working with limited capacity. BPR. Is that like a Priority Mail system for the AI, making sure the most important information gets delivered first, even during rush hour? You got it. BPR allows the model to make the smarter routing decisions by looking at all the words together instead of processing them one by one. OK, this is all starting to make sense. But let's get down to brass tacks here. How do these STMOE models actually perform in the real world? Did they put them through their paces? They did. The researchers tested them in the lab. They found that they were much faster in processing words than in the real world. And they found that they were much faster in processing words than in the real world. So they're not just better at routing. They're much faster at processing words. And So they tested them on a whole range of tasks from question answering to summarization to natural language inference. And honestly, the results are pretty impressive. So these aren't just theoretical toys. They can actually hold their own against the big guys. Not only hold their own, they often surpass them on a benchmark called SuperGLUE, which tests a variety of language understanding skills. The STMOE models actually beat the estimated human performance. They're outperforming humans on certain language tasks. Now, that's what I call progress. They also showed these remarkable improvements in summarization. Imagine an AI that can read a long news article and condense it down to the key points. No more information overload. That would definitely come in handy. What about other areas? Did they test them on anything like trivia questions? Yes, they did. They looked at closed book question answering, which means the model has to answer without any access to external information. And the STMOE models did incredibly well, suggesting they're capable of retaining a vast amount of data. So it's like they've absorbed all this information and can now use it to answer your questions on the fly, like a walking, talking encyclopedia. They even tested the models on data sets that were specifically designed to be tricky, full of ambiguous language and misleading questions. And even then, the STMOE models held their own, showing a level of robustness and common sense reasoning. That is pretty remarkable. That's encouraging. But were there any areas where they stumbled? No system is perfect, right? You're right. There were a few areas where they didn't quite reach the top. For example, on a data set focused on reading comprehension and answering questions based on a specific passage, their performance wasn't as stellar. So maybe they still need a bit more practice when it comes to deep analysis of complex texts. And while they aced the overall SuperGLU benchmark, their scores on certain subtasks within that weren't as impressive. It's like being a straight A student, but still having that one subject you struggle with. Makes sense. But even with those limitations, it sounds like the research paints a pretty optimistic picture for the future of AI. It does. The success of these STMOE models has these major implications. It shows that we can build powerful AI systems that are also efficient and sustainable, using far less energy and computational resources than those massive models we've become accustomed to. So it's not just about making AI smarter. It's about making it greener and more accessible too. That's fantastic. Absolutely. This could democratize AI, making it available to smaller companies, research groups, even individuals who might not have access to these huge computing clusters. Now, I remember you mentioned something about the researchers actually visualizing how information moves through these models. That sounds pretty mind-blowing. It is. They tracked individual words as they were processed by the different experts, creating a visual map of the AI's thought process, so to speak. And what they discovered was fascinating. What were those AI brains up to? The encoder experts, the ones responsible for processing the input, were highly specialized, as we've discussed. But when they looked at the decoder experts, the ones generating the output, they found something surprising. Let me guess. They weren't as specialized? Exactly. The decoder experts seem to be more generalists, comfortable handling a wider range of tasks. That's a question that has researchers scratching their heads. Does it reflect something fundamental about the nature of language itself? Or is it just an artifact of the way these models are currently trained? It's like we've opened up this black box of AI. And instead of finding these simple answers, we've discovered a whole new set of mysteries. That's the beauty of scientific exploration. Every answer leads to more questions, pushing us further down the rabbit hole of knowledge. But what about the intriguing finding about multilingualism, those experts stubbornly refusing to specialize by language? What are the implications of that? This is where things get really interesting. Does this mean that at some deep level, all languages share a common structure, a universal grammar that underlies the incredible diversity of human communication? Or is it simply a consequence of how these models are trained, pushing them towards a more generalized approach to language? So we have AI that can effortlessly translate between any language, decipher ancient texts, even maybe help us understand how language evolved in the first place. But if it's just an artifact of the training process, then the question becomes, can we change that process? Can we guide those experts towards more specialized linguistic skills? Those are questions that will drive AI research for years to come. And the answers could reshape our understanding of both artificial and human intelligence. Let's take a moment to recap what we've learned about STEM OE. We've delved into some of the fascinating questions raised by this research, such as the specialization of encoder versus decoder experts, and the surprising lack of language specialization when trained on multilingual data. Not necessarily. Think of it this way. Sparsity allows us to do more with less. It's like optimizing the layout of a city. Instead of sprawling suburbs, we're building these dense, interconnected urban centers. So we can still achieve incredible things with AI, but we can do it in a more sustainable and efficient way. It's like we're discovering a whole new set of architectural principles for building AI. It's not just about brute force anymore. It's about elegance in efficiency. And that brings us back to one of the most fascinating aspects of this research, the way these specialized experts seem to emerge organically during training. It's like they're self-organizing, almost like cells forming different organs in a developing embryo. So it's like they planted a seed and then nurtured the AI as it grew, allowing those specialized skills to blossom. And that raises profound questions about the nature of learning, both in AI and in humans. How does the self-organization occur? What are the underlying principles that guide the formation of expertise? It's like we're witnessing a form of AI evolution in action where the fittest experts survive and thrive based on their ability to handle specific types of information. And it underscores the importance of the training process itself. It's not just about feeding the AI data. It's about creating the right environment for learning and adaptation. As we wrap up this deep dive, I want to circle back to something we discussed earlier. The idea that these sparse expert models might be reflecting some aspects of human cognition, the way our brains specialize in different tasks. It's a compelling thought, isn't it? We have areas dedicated to language, vision, memory, motor skills. And we don't use all of our brainpower for every task we allocate our resources strategically. So could these AI models be too complicated? And could they be too complicated to understand? And could they be teaching us something about ourselves? Could they be revealing fundamental principles of how intelligence, both biological and artificial, arises from these specialized systems working together? That's one of the most exciting frontiers of AI research. As we build increasingly sophisticated models, we're not only developing new technologies, we're also gaining insights into the very nature of thought and learning. This deep dive has been a real journey full of surprising twists and turns. We ended up exploring some of the deepest mysteries of AI and the human mind. And to our listener, we hope this has inspired you to keep exploring, keep questioning, and keep diving deep into this fascinating world of AI. Who knows what other wonders await us out there? If this deep dive has left you wanting more, we encourage you to check out the Estimo research paper you sent us. It's a treasure trove of insights. And until next time, keep that curiosity burning bright.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 31.36, "text": " All right, so today we're going to be looking at AI and specifically how to make it a whole lot smarter, but without needing, you know, like a giant supercomputer. You're interested in these sparse expert models, right? And specifically this paper about STMOe, stable and transferable mixture of experts. It sounds kind of intimidating. I think the idea is actually really elegant. It is. Think about it this way. Instead of one massive AI brain, you know, trying to process everything. What if you had a team of specialized experts? What if you had a team of people who were able to make a smart AI? What if you had a team of people who were able to make a smart computer? What if you had a team of people who were able to make a smart computer? What if you had a team of people who were able to make a smart computer? What if you had a", "tokens": [50364, 1057, 558, 11, 370, 220, 83, 378, 320, 321, 434, 516, 220, 1353, 312, 1237, 412, 7318, 293, 637, 3045, 351, 984, 577, 220, 1353, 652, 309, 257, 1379, 688, 20294, 11, 457, 1553, 18006, 11, 291, 458, 11, 411, 257, 7410, 36708, 13, 509, 434, 3102, 294, 220, 42678, 637, 11668, 5844, 5245, 11, 558, 30, 400, 637, 3045, 351, 804, 356, 220, 11176, 3035, 466, 4904, 18976, 68, 11, 8351, 293, 220, 24999, 612, 712, 9925, 295, 8572, 13, 467, 3263, 733, 295, 29714, 13, 286, 220, 21074, 220, 3322, 1558, 307, 767, 534, 21117, 13, 467, 307, 13, 6557, 466, 309, 220, 11176, 636, 13, 7156, 295, 472, 5994, 7318, 3567, 11, 291, 458, 11, 220, 83, 19076, 220, 1353, 1399, 1203, 13, 708, 498, 291, 632, 257, 220, 975, 335, 295, 19813, 8572, 30, 708, 498, 291, 632, 257, 220, 975, 335, 295, 561, 567, 645, 1075, 220, 1353, 652, 257, 4069, 7318, 30, 708, 498, 291, 632, 257, 220, 975, 335, 295, 561, 567, 645, 1075, 220, 1353, 652, 257, 4069, 3820, 30, 708, 498, 291, 632, 257, 220, 975, 335, 295, 561, 567, 645, 1075, 220, 1353, 652, 257, 4069, 3820, 30, 708, 498, 291, 632, 257, 220, 975, 335, 295, 561, 567, 645, 1075, 220, 1353, 652, 257, 4069, 3820, 30, 708, 498, 291, 632, 257], "temperature": 0.0, "avg_logprob": -0.2960362752278646, "compression_ratio": 2.3577464788732394, "no_speech_prob": 0.007165997754782438, "confidence": 0.748, "words": [{"text": "All", "start": 0.0, "end": 0.14, "confidence": 0.233}, {"text": "right,", "start": 0.14, "end": 0.18, "confidence": 0.99}, {"text": "so", "start": 0.34, "end": 0.56, "confidence": 0.931}, {"text": "today", "start": 0.56, "end": 1.44, "confidence": 0.926}, {"text": "we're", "start": 1.44, "end": 1.5, "confidence": 0.947}, {"text": "going", "start": 1.5, "end": 1.62, "confidence": 0.584}, {"text": "to", "start": 1.62, "end": 1.68, "confidence": 0.997}, {"text": "be", "start": 1.68, "end": 1.7, "confidence": 0.992}, {"text": "looking", "start": 1.7, "end": 2.0, "confidence": 0.957}, {"text": "at", "start": 2.0, "end": 2.34, "confidence": 0.995}, {"text": "AI", "start": 2.34, "end": 2.9, "confidence": 0.945}, {"text": "and", "start": 2.9, "end": 3.56, "confidence": 0.486}, {"text": "specifically", "start": 3.56, "end": 4.02, "confidence": 0.676}, {"text": "how", "start": 4.02, "end": 4.48, "confidence": 0.972}, {"text": "to", "start": 4.48, "end": 4.5, "confidence": 0.995}, {"text": "make", "start": 4.5, "end": 4.52, "confidence": 0.99}, {"text": "it", "start": 4.52, "end": 4.56, "confidence": 0.984}, {"text": "a", "start": 4.56, "end": 4.58, "confidence": 0.995}, {"text": "whole", "start": 4.58, "end": 4.74, "confidence": 0.863}, {"text": "lot", "start": 4.74, "end": 4.94, "confidence": 0.976}, {"text": "smarter,", "start": 4.94, "end": 5.4, "confidence": 0.485}, {"text": "but", "start": 5.9, "end": 5.92, "confidence": 0.821}, {"text": "without", "start": 5.92, "end": 6.32, "confidence": 0.99}, {"text": "needing,", "start": 6.32, "end": 7.32, "confidence": 0.73}, {"text": "you", "start": 7.44, "end": 7.56, "confidence": 0.852}, {"text": "know,", "start": 7.56, "end": 7.66, "confidence": 0.972}, {"text": "like", "start": 7.76, "end": 7.78, "confidence": 0.961}, {"text": "a", "start": 7.78, "end": 7.8, "confidence": 0.974}, {"text": "giant", "start": 7.8, "end": 8.12, "confidence": 0.841}, {"text": "supercomputer.", "start": 8.12, "end": 8.88, "confidence": 0.945}, {"text": "You're", "start": 9.42, "end": 9.66, "confidence": 0.816}, {"text": "interested", "start": 9.66, "end": 9.98, "confidence": 0.469}, {"text": "in", "start": 9.98, "end": 10.18, "confidence": 0.981}, {"text": "these", "start": 10.18, "end": 10.24, "confidence": 0.974}, {"text": "sparse", "start": 10.24, "end": 10.9, "confidence": 0.956}, {"text": "expert", "start": 10.9, "end": 11.48, "confidence": 0.691}, {"text": "models,", "start": 11.48, "end": 11.7, "confidence": 0.955}, {"text": "right?", "start": 12.42, "end": 12.52, "confidence": 0.967}, {"text": "And", "start": 12.68, "end": 12.7, "confidence": 0.903}, {"text": "specifically", "start": 12.7, "end": 13.32, "confidence": 0.776}, {"text": "this", "start": 13.32, "end": 13.44, "confidence": 0.765}, {"text": "paper", "start": 13.44, "end": 13.8, "confidence": 0.843}, {"text": "about", "start": 13.8, "end": 14.52, "confidence": 0.961}, {"text": "STMOe,", "start": 14.52, "end": 15.28, "confidence": 0.608}, {"text": "stable", "start": 15.74, "end": 15.96, "confidence": 0.819}, {"text": "and", "start": 15.96, "end": 16.52, "confidence": 0.976}, {"text": "transferable", "start": 16.52, "end": 16.76, "confidence": 0.943}, {"text": "mixture", "start": 16.76, "end": 17.24, "confidence": 0.744}, {"text": "of", "start": 17.24, "end": 17.4, "confidence": 0.994}, {"text": "experts.", "start": 17.4, "end": 17.82, "confidence": 0.886}, {"text": "It", "start": 18.28, "end": 18.78, "confidence": 0.782}, {"text": "sounds", "start": 18.78, "end": 18.98, "confidence": 0.954}, {"text": "kind", "start": 18.98, "end": 19.14, "confidence": 0.944}, {"text": "of", "start": 19.14, "end": 19.24, "confidence": 0.986}, {"text": "intimidating.", "start": 19.24, "end": 19.66, "confidence": 0.866}, {"text": "I", "start": 19.86, "end": 19.92, "confidence": 0.75}, {"text": "think", "start": 19.92, "end": 20.06, "confidence": 0.996}, {"text": "the", "start": 20.06, "end": 20.16, "confidence": 0.998}, {"text": "idea", "start": 20.16, "end": 20.5, "confidence": 0.933}, {"text": "is", "start": 20.5, "end": 20.62, "confidence": 0.977}, {"text": "actually", "start": 20.62, "end": 20.74, "confidence": 0.97}, {"text": "really", "start": 20.74, "end": 20.96, "confidence": 0.9}, {"text": "elegant.", "start": 20.96, "end": 21.42, "confidence": 0.988}, {"text": "It", "start": 21.42, "end": 21.6, "confidence": 0.789}, {"text": "is.", "start": 21.6, "end": 22.02, "confidence": 0.981}, {"text": "Think", "start": 22.94, "end": 22.96, "confidence": 0.882}, {"text": "about", "start": 22.96, "end": 23.08, "confidence": 0.971}, {"text": "it", "start": 23.08, "end": 23.14, "confidence": 0.983}, {"text": "this", "start": 23.14, "end": 23.26, "confidence": 0.973}, {"text": "way.", "start": 23.26, "end": 23.56, "confidence": 0.998}, {"text": "Instead", "start": 23.6, "end": 23.82, "confidence": 0.851}, {"text": "of", "start": 23.82, "end": 23.96, "confidence": 0.992}, {"text": "one", "start": 23.96, "end": 24.14, "confidence": 0.984}, {"text": "massive", "start": 24.14, "end": 24.84, "confidence": 0.95}, {"text": "AI", "start": 24.84, "end": 25.34, "confidence": 0.818}, {"text": "brain,", "start": 25.34, "end": 25.74, "confidence": 0.966}, {"text": "you", "start": 26.16, "end": 26.32, "confidence": 0.887}, {"text": "know,", "start": 26.32, "end": 26.5, "confidence": 0.958}, {"text": "trying", "start": 26.54, "end": 26.58, "confidence": 0.97}, {"text": "to", "start": 26.58, "end": 26.98, "confidence": 0.998}, {"text": "process", "start": 26.98, "end": 27.0, "confidence": 0.958}, {"text": "everything.", "start": 27.0, "end": 27.44, "confidence": 0.965}, {"text": "What", "start": 28.0, "end": 28.02, "confidence": 0.832}, {"text": "if", "start": 28.02, "end": 28.16, "confidence": 0.977}, {"text": "you", "start": 28.16, "end": 28.24, "confidence": 0.994}, {"text": "had", "start": 28.24, "end": 28.36, "confidence": 0.972}, {"text": "a", "start": 28.36, "end": 28.48, "confidence": 0.996}, {"text": "team", "start": 28.48, "end": 28.76, "confidence": 0.991}, {"text": "of", "start": 28.76, "end": 28.94, "confidence": 0.987}, {"text": "specialized", "start": 28.94, "end": 29.82, "confidence": 0.405}, {"text": "experts?", "start": 29.82, "end": 29.98, "confidence": 0.402}, {"text": "What", "start": 29.98, "end": 30.0, "confidence": 0.251}, {"text": "if", "start": 30.0, "end": 30.02, "confidence": 0.544}, {"text": "you", "start": 30.02, "end": 30.04, "confidence": 0.508}, {"text": "had", "start": 30.04, "end": 30.06, "confidence": 0.578}, {"text": "a", "start": 30.06, "end": 30.08, "confidence": 0.536}, {"text": "team", "start": 30.08, "end": 30.1, "confidence": 0.592}, {"text": "of", "start": 30.1, "end": 30.12, "confidence": 0.931}, {"text": "people", "start": 30.12, "end": 30.14, "confidence": 0.057}, {"text": "who", "start": 30.14, "end": 30.16, "confidence": 0.32}, {"text": "were", "start": 30.16, "end": 30.18, "confidence": 0.178}, {"text": "able", "start": 30.18, "end": 30.2, "confidence": 0.059}, {"text": "to", "start": 30.2, "end": 30.22, "confidence": 0.982}, {"text": "make", "start": 30.22, "end": 30.24, "confidence": 0.109}, {"text": "a", "start": 30.24, "end": 30.26, "confidence": 0.167}, {"text": "smart", "start": 30.26, "end": 30.28, "confidence": 0.128}, {"text": "AI?", "start": 30.28, "end": 30.3, "confidence": 0.123}, {"text": "What", "start": 30.3, "end": 30.32, "confidence": 0.228}, {"text": "if", "start": 30.32, "end": 30.34, "confidence": 0.732}, {"text": "you", "start": 30.34, "end": 30.36, "confidence": 0.609}, {"text": "had", "start": 30.36, "end": 30.38, "confidence": 0.778}, {"text": "a", "start": 30.38, "end": 30.4, "confidence": 0.76}, {"text": "team", "start": 30.4, "end": 30.42, "confidence": 0.851}, {"text": "of", "start": 30.42, "end": 30.44, "confidence": 0.915}, {"text": "people", "start": 30.44, "end": 30.46, "confidence": 0.263}, {"text": "who", "start": 30.46, "end": 30.48, "confidence": 0.734}, {"text": "were", "start": 30.48, "end": 30.5, "confidence": 0.435}, {"text": "able", "start": 30.5, "end": 30.52, "confidence": 0.527}, {"text": "to", "start": 30.52, "end": 30.54, "confidence": 0.989}, {"text": "make", "start": 30.54, "end": 30.56, "confidence": 0.478}, {"text": "a", "start": 30.56, "end": 30.58, "confidence": 0.417}, {"text": "smart", "start": 30.58, "end": 30.6, "confidence": 0.566}, {"text": "computer?", "start": 30.6, "end": 30.62, "confidence": 0.264}, {"text": "What", "start": 30.62, "end": 30.64, "confidence": 0.412}, {"text": "if", "start": 30.64, "end": 30.66, "confidence": 0.875}, {"text": "you", "start": 30.66, "end": 30.68, "confidence": 0.888}, {"text": "had", "start": 30.68, "end": 30.7, "confidence": 0.925}, {"text": "a", "start": 30.7, "end": 30.72, "confidence": 0.949}, {"text": "team", "start": 30.72, "end": 30.74, "confidence": 0.974}, {"text": "of", "start": 30.74, "end": 30.76, "confidence": 0.946}, {"text": "people", "start": 30.76, "end": 30.78, "confidence": 0.708}, {"text": "who", "start": 30.78, "end": 30.8, "confidence": 0.832}, {"text": "were", "start": 30.8, "end": 30.82, "confidence": 0.712}, {"text": "able", "start": 30.82, "end": 30.84, "confidence": 0.829}, {"text": "to", "start": 30.84, "end": 30.86, "confidence": 0.988}, {"text": "make", "start": 30.86, "end": 30.88, "confidence": 0.891}, {"text": "a", "start": 30.88, "end": 30.9, "confidence": 0.765}, {"text": "smart", "start": 30.9, "end": 30.92, "confidence": 0.761}, {"text": "computer?", "start": 30.92, "end": 30.94, "confidence": 0.384}, {"text": "What", "start": 30.94, "end": 30.96, "confidence": 0.377}, {"text": "if", "start": 30.96, "end": 30.98, "confidence": 0.862}, {"text": "you", "start": 30.98, "end": 31.0, "confidence": 0.884}, {"text": "had", "start": 31.0, "end": 31.02, "confidence": 0.932}, {"text": "a", "start": 31.02, "end": 31.04, "confidence": 0.957}, {"text": "team", "start": 31.04, "end": 31.06, "confidence": 0.978}, {"text": "of", "start": 31.06, "end": 31.08, "confidence": 0.957}, {"text": "people", "start": 31.08, "end": 31.1, "confidence": 0.729}, {"text": "who", "start": 31.1, "end": 31.12, "confidence": 0.876}, {"text": "were", "start": 31.12, "end": 31.14, "confidence": 0.828}, {"text": "able", "start": 31.14, "end": 31.16, "confidence": 0.863}, {"text": "to", "start": 31.16, "end": 31.18, "confidence": 0.989}, {"text": "make", "start": 31.18, "end": 31.2, "confidence": 0.917}, {"text": "a", "start": 31.2, "end": 31.22, "confidence": 0.824}, {"text": "smart", "start": 31.22, "end": 31.24, "confidence": 0.874}, {"text": "computer?", "start": 31.24, "end": 31.26, "confidence": 0.486}, {"text": "What", "start": 31.26, "end": 31.28, "confidence": 0.371}, {"text": "if", "start": 31.28, "end": 31.3, "confidence": 0.904}, {"text": "you", "start": 31.3, "end": 31.32, "confidence": 0.911}, {"text": "had", "start": 31.32, "end": 31.34, "confidence": 0.948}, {"text": "a", "start": 31.34, "end": 31.36, "confidence": 0.968}]}, {"id": 1, "seek": 3000, "start": 31.36, "end": 36.08, "text": " Each one incredibly good at their own thing. That's the core concept behind these sparse expert models.", "tokens": [50413, 6947, 472, 6252, 665, 412, 220, 3322, 347, 1065, 220, 825, 13, 663, 311, 220, 3322, 4965, 3410, 2261, 220, 42678, 637, 11668, 5844, 5245, 13, 50665], "temperature": 0.0, "avg_logprob": -0.17335002453296217, "compression_ratio": 1.6045016077170418, "no_speech_prob": 0.19425877928733826, "confidence": 0.923, "words": [{"text": "Each", "start": 31.36, "end": 31.42, "confidence": 0.419}, {"text": "one", "start": 31.42, "end": 31.84, "confidence": 0.982}, {"text": "incredibly", "start": 31.84, "end": 32.3, "confidence": 0.784}, {"text": "good", "start": 32.3, "end": 32.68, "confidence": 0.992}, {"text": "at", "start": 32.68, "end": 32.7, "confidence": 0.989}, {"text": "their", "start": 32.7, "end": 32.8, "confidence": 0.996}, {"text": "own", "start": 32.8, "end": 33.02, "confidence": 0.977}, {"text": "thing.", "start": 33.02, "end": 33.2, "confidence": 0.99}, {"text": "That's", "start": 33.2, "end": 33.5, "confidence": 0.977}, {"text": "the", "start": 33.5, "end": 33.66, "confidence": 0.998}, {"text": "core", "start": 33.66, "end": 33.9, "confidence": 0.993}, {"text": "concept", "start": 33.9, "end": 34.46, "confidence": 0.898}, {"text": "behind", "start": 34.46, "end": 34.7, "confidence": 0.977}, {"text": "these", "start": 34.7, "end": 34.96, "confidence": 0.93}, {"text": "sparse", "start": 34.96, "end": 35.36, "confidence": 0.945}, {"text": "expert", "start": 35.36, "end": 35.74, "confidence": 0.816}, {"text": "models.", "start": 35.74, "end": 36.08, "confidence": 0.932}]}, {"id": 2, "seek": 3000, "start": 36.16, "end": 47.08, "text": " OK, so it's less like one giant dictionary. More like having a linguist, a grammarian, a poet all working together. Yeah, that's a great analogy. And the ST part is really key here. Stable and transferable.", "tokens": [50665, 2264, 11, 370, 309, 311, 1570, 411, 472, 7410, 25890, 13, 5048, 411, 1419, 257, 21766, 468, 11, 257, 17570, 10652, 11, 257, 20874, 439, 1364, 220, 83, 9622, 13, 865, 11, 220, 6780, 311, 257, 869, 21663, 13, 400, 220, 3322, 4904, 644, 307, 534, 2141, 510, 13, 745, 712, 293, 220, 24999, 612, 712, 13, 51239], "temperature": 0.0, "avg_logprob": -0.17335002453296217, "compression_ratio": 1.6045016077170418, "no_speech_prob": 0.19425877928733826, "confidence": 0.867, "words": [{"text": "OK,", "start": 36.16, "end": 36.22, "confidence": 0.641}, {"text": "so", "start": 36.38, "end": 36.5, "confidence": 0.933}, {"text": "it's", "start": 36.5, "end": 36.72, "confidence": 0.987}, {"text": "less", "start": 36.72, "end": 36.94, "confidence": 0.844}, {"text": "like", "start": 36.94, "end": 37.06, "confidence": 0.986}, {"text": "one", "start": 37.06, "end": 37.3, "confidence": 0.99}, {"text": "giant", "start": 37.3, "end": 37.6, "confidence": 0.896}, {"text": "dictionary.", "start": 37.6, "end": 38.36, "confidence": 0.991}, {"text": "More", "start": 38.78, "end": 38.8, "confidence": 0.385}, {"text": "like", "start": 38.8, "end": 39.0, "confidence": 0.984}, {"text": "having", "start": 39.0, "end": 39.26, "confidence": 0.924}, {"text": "a", "start": 39.26, "end": 39.46, "confidence": 0.995}, {"text": "linguist,", "start": 39.46, "end": 39.86, "confidence": 0.939}, {"text": "a", "start": 40.0, "end": 40.4, "confidence": 0.963}, {"text": "grammarian,", "start": 40.4, "end": 40.8, "confidence": 0.959}, {"text": "a", "start": 40.98, "end": 41.18, "confidence": 0.959}, {"text": "poet", "start": 41.18, "end": 41.62, "confidence": 0.997}, {"text": "all", "start": 41.62, "end": 41.92, "confidence": 0.748}, {"text": "working", "start": 41.92, "end": 42.26, "confidence": 0.993}, {"text": "together.", "start": 42.26, "end": 42.46, "confidence": 0.804}, {"text": "Yeah,", "start": 42.46, "end": 42.64, "confidence": 0.543}, {"text": "that's", "start": 42.74, "end": 43.14, "confidence": 0.971}, {"text": "a", "start": 43.14, "end": 43.22, "confidence": 0.991}, {"text": "great", "start": 43.22, "end": 43.42, "confidence": 0.873}, {"text": "analogy.", "start": 43.42, "end": 43.7, "confidence": 0.294}, {"text": "And", "start": 43.78, "end": 43.8, "confidence": 0.911}, {"text": "the", "start": 43.8, "end": 43.98, "confidence": 0.994}, {"text": "ST", "start": 43.98, "end": 44.16, "confidence": 0.939}, {"text": "part", "start": 44.16, "end": 44.44, "confidence": 0.937}, {"text": "is", "start": 44.44, "end": 44.58, "confidence": 0.975}, {"text": "really", "start": 44.58, "end": 44.92, "confidence": 0.929}, {"text": "key", "start": 44.92, "end": 45.22, "confidence": 0.919}, {"text": "here.", "start": 45.22, "end": 45.62, "confidence": 0.875}, {"text": "Stable", "start": 45.7, "end": 46.12, "confidence": 0.762}, {"text": "and", "start": 46.12, "end": 46.42, "confidence": 0.98}, {"text": "transferable.", "start": 46.42, "end": 47.08, "confidence": 0.882}]}, {"id": 3, "seek": 3000, "start": 47.08, "end": 53.11, "text": " Earlier attempts at this kind of AI were, well, a bit temperamental. STMOe is designed to be more", "tokens": [51239, 3929, 2081, 260, 220, 1591, 4543, 82, 412, 220, 11176, 733, 295, 7318, 645, 11, 731, 11, 257, 857, 220, 18275, 610, 44538, 13, 4904, 18976, 68, 307, 730, 328, 9232, 220, 1353, 312, 544, 51515], "temperature": 0.0, "avg_logprob": -0.17335002453296217, "compression_ratio": 1.6045016077170418, "no_speech_prob": 0.19425877928733826, "confidence": 0.886, "words": [{"text": "Earlier", "start": 47.08, "end": 48.14, "confidence": 0.653}, {"text": "attempts", "start": 48.14, "end": 48.34, "confidence": 0.765}, {"text": "at", "start": 48.34, "end": 48.4, "confidence": 0.945}, {"text": "this", "start": 48.4, "end": 48.52, "confidence": 0.995}, {"text": "kind", "start": 48.52, "end": 48.78, "confidence": 0.978}, {"text": "of", "start": 48.78, "end": 48.88, "confidence": 0.994}, {"text": "AI", "start": 48.88, "end": 49.2, "confidence": 0.961}, {"text": "were,", "start": 49.2, "end": 49.4, "confidence": 0.969}, {"text": "well,", "start": 49.7, "end": 50.18, "confidence": 0.997}, {"text": "a", "start": 50.52, "end": 50.74, "confidence": 0.97}, {"text": "bit", "start": 50.74, "end": 50.78, "confidence": 0.98}, {"text": "temperamental.", "start": 50.78, "end": 51.38, "confidence": 0.985}, {"text": "STMOe", "start": 51.82, "end": 52.34, "confidence": 0.882}, {"text": "is", "start": 52.34, "end": 52.5, "confidence": 0.963}, {"text": "designed", "start": 52.5, "end": 52.78, "confidence": 0.777}, {"text": "to", "start": 52.78, "end": 52.86, "confidence": 0.991}, {"text": "be", "start": 52.86, "end": 52.88, "confidence": 0.994}, {"text": "more", "start": 52.88, "end": 53.11, "confidence": 0.941}]}, {"id": 4, "seek": 3000, "start": 53.11, "end": 57.81, "text": " reliable and also adaptable, meaning you can train it on one task and then easily apply it", "tokens": [51515, 1039, 654, 638, 293, 611, 6231, 712, 11, 3620, 291, 393, 220, 83, 7146, 309, 322, 472, 220, 83, 3863, 293, 220, 19096, 3612, 3079, 309, 51751], "temperature": 0.0, "avg_logprob": -0.17335002453296217, "compression_ratio": 1.6045016077170418, "no_speech_prob": 0.19425877928733826, "confidence": 0.92, "words": [{"text": "reliable", "start": 53.11, "end": 53.82, "confidence": 0.733}, {"text": "and", "start": 53.82, "end": 53.94, "confidence": 0.813}, {"text": "also", "start": 53.94, "end": 54.2, "confidence": 0.957}, {"text": "adaptable,", "start": 54.2, "end": 54.78, "confidence": 0.984}, {"text": "meaning", "start": 55.0, "end": 55.18, "confidence": 0.8}, {"text": "you", "start": 55.18, "end": 55.38, "confidence": 0.989}, {"text": "can", "start": 55.38, "end": 55.46, "confidence": 0.983}, {"text": "train", "start": 55.46, "end": 55.78, "confidence": 0.982}, {"text": "it", "start": 55.78, "end": 55.9, "confidence": 0.984}, {"text": "on", "start": 55.9, "end": 56.0, "confidence": 0.992}, {"text": "one", "start": 56.0, "end": 56.16, "confidence": 0.98}, {"text": "task", "start": 56.16, "end": 56.88, "confidence": 0.984}, {"text": "and", "start": 56.88, "end": 57.02, "confidence": 0.903}, {"text": "then", "start": 57.02, "end": 57.18, "confidence": 0.994}, {"text": "easily", "start": 57.18, "end": 57.46, "confidence": 0.951}, {"text": "apply", "start": 57.46, "end": 57.76, "confidence": 0.752}, {"text": "it", "start": 57.76, "end": 57.81, "confidence": 0.969}]}, {"id": 5, "seek": 5774, "start": 57.81, "end": 87.22, "text": " to something new without it forgetting everything it learned. So it's like having a team that can not only specialize, but also learn new skills really quickly. I've already seen the potential here. The paper mentions something pretty wild about robustness too. Absolutely. Imagine you're reading a text and you randomly skip like every tenth word. You can probably still understand the gist, right? Researchers found that these STMOe models have a similar ability. They can handle these missing chunks of information without completely falling apart.", "tokens": [50369, 220, 1353, 746, 777, 1553, 309, 25428, 1203, 309, 3264, 13, 407, 309, 311, 411, 1419, 257, 220, 975, 335, 220, 6780, 393, 406, 787, 37938, 11, 457, 611, 1466, 777, 3942, 534, 2661, 13, 286, 600, 1217, 1612, 220, 3322, 3995, 510, 13, 440, 3035, 23844, 746, 1238, 4868, 466, 13956, 1287, 220, 32599, 13, 7021, 13, 11739, 291, 434, 3760, 257, 220, 25111, 293, 291, 16979, 10023, 411, 633, 220, 83, 17966, 1349, 13, 509, 393, 1391, 920, 1223, 220, 3322, 290, 468, 11, 558, 30, 43555, 1352, 220, 6780, 220, 42678, 4904, 18976, 68, 5245, 362, 257, 2531, 3485, 13, 814, 393, 4813, 220, 42678, 5361, 24004, 295, 1589, 1553, 2584, 7440, 4936, 13, 51839], "temperature": 0.0, "avg_logprob": -0.15055413246154786, "compression_ratio": 1.6398809523809523, "no_speech_prob": 0.4965241551399231, "confidence": 0.89, "words": [{"text": "to", "start": 57.81, "end": 58.02, "confidence": 0.787}, {"text": "something", "start": 58.02, "end": 58.3, "confidence": 0.938}, {"text": "new", "start": 58.3, "end": 58.62, "confidence": 0.96}, {"text": "without", "start": 58.62, "end": 59.14, "confidence": 0.917}, {"text": "it", "start": 59.14, "end": 59.24, "confidence": 0.933}, {"text": "forgetting", "start": 59.24, "end": 59.62, "confidence": 0.848}, {"text": "everything", "start": 59.62, "end": 59.9, "confidence": 0.964}, {"text": "it", "start": 59.9, "end": 60.0, "confidence": 0.967}, {"text": "learned.", "start": 60.0, "end": 60.42, "confidence": 0.96}, {"text": "So", "start": 60.42, "end": 60.76, "confidence": 0.903}, {"text": "it's", "start": 60.76, "end": 60.92, "confidence": 0.985}, {"text": "like", "start": 60.92, "end": 61.1, "confidence": 0.976}, {"text": "having", "start": 61.1, "end": 61.24, "confidence": 0.949}, {"text": "a", "start": 61.24, "end": 61.34, "confidence": 0.998}, {"text": "team", "start": 61.34, "end": 61.76, "confidence": 0.979}, {"text": "that", "start": 61.76, "end": 62.06, "confidence": 0.984}, {"text": "can", "start": 62.06, "end": 62.08, "confidence": 0.955}, {"text": "not", "start": 62.08, "end": 62.34, "confidence": 0.95}, {"text": "only", "start": 62.34, "end": 62.36, "confidence": 0.982}, {"text": "specialize,", "start": 62.36, "end": 63.02, "confidence": 0.86}, {"text": "but", "start": 63.96, "end": 63.98, "confidence": 0.957}, {"text": "also", "start": 63.98, "end": 64.22, "confidence": 0.949}, {"text": "learn", "start": 64.22, "end": 64.82, "confidence": 0.969}, {"text": "new", "start": 64.82, "end": 64.84, "confidence": 0.936}, {"text": "skills", "start": 64.84, "end": 65.06, "confidence": 0.953}, {"text": "really", "start": 65.06, "end": 65.98, "confidence": 0.859}, {"text": "quickly.", "start": 65.98, "end": 66.0, "confidence": 0.952}, {"text": "I've", "start": 66.42, "end": 66.44, "confidence": 0.39}, {"text": "already", "start": 66.44, "end": 66.46, "confidence": 0.962}, {"text": "seen", "start": 66.46, "end": 66.48, "confidence": 0.974}, {"text": "the", "start": 66.48, "end": 66.86, "confidence": 0.995}, {"text": "potential", "start": 66.86, "end": 67.18, "confidence": 0.944}, {"text": "here.", "start": 67.18, "end": 67.64, "confidence": 0.882}, {"text": "The", "start": 68.04, "end": 68.06, "confidence": 0.83}, {"text": "paper", "start": 68.06, "end": 68.14, "confidence": 0.888}, {"text": "mentions", "start": 68.14, "end": 68.42, "confidence": 0.283}, {"text": "something", "start": 68.42, "end": 68.58, "confidence": 0.929}, {"text": "pretty", "start": 68.58, "end": 68.9, "confidence": 0.816}, {"text": "wild", "start": 68.9, "end": 69.18, "confidence": 0.982}, {"text": "about", "start": 69.18, "end": 69.34, "confidence": 0.976}, {"text": "robustness", "start": 69.34, "end": 70.02, "confidence": 0.988}, {"text": "too.", "start": 70.02, "end": 70.1, "confidence": 0.874}, {"text": "Absolutely.", "start": 70.22, "end": 70.54, "confidence": 0.562}, {"text": "Imagine", "start": 70.88, "end": 71.14, "confidence": 0.875}, {"text": "you're", "start": 71.14, "end": 71.5, "confidence": 0.969}, {"text": "reading", "start": 71.5, "end": 71.52, "confidence": 0.926}, {"text": "a", "start": 71.52, "end": 71.58, "confidence": 0.997}, {"text": "text", "start": 71.58, "end": 72.02, "confidence": 0.886}, {"text": "and", "start": 72.02, "end": 72.74, "confidence": 0.649}, {"text": "you", "start": 72.74, "end": 72.9, "confidence": 0.988}, {"text": "randomly", "start": 72.9, "end": 73.28, "confidence": 0.364}, {"text": "skip", "start": 73.28, "end": 73.8, "confidence": 0.986}, {"text": "like", "start": 73.8, "end": 74.24, "confidence": 0.68}, {"text": "every", "start": 74.24, "end": 74.4, "confidence": 0.965}, {"text": "tenth", "start": 74.4, "end": 74.78, "confidence": 0.753}, {"text": "word.", "start": 74.78, "end": 75.22, "confidence": 0.99}, {"text": "You", "start": 75.64, "end": 75.82, "confidence": 0.986}, {"text": "can", "start": 75.82, "end": 75.88, "confidence": 0.984}, {"text": "probably", "start": 75.88, "end": 76.18, "confidence": 0.942}, {"text": "still", "start": 76.18, "end": 76.4, "confidence": 0.979}, {"text": "understand", "start": 76.4, "end": 76.78, "confidence": 0.931}, {"text": "the", "start": 76.78, "end": 76.86, "confidence": 0.992}, {"text": "gist,", "start": 76.86, "end": 76.98, "confidence": 0.988}, {"text": "right?", "start": 77.32, "end": 77.34, "confidence": 0.982}, {"text": "Researchers", "start": 77.34, "end": 78.02, "confidence": 0.556}, {"text": "found", "start": 78.02, "end": 78.62, "confidence": 0.988}, {"text": "that", "start": 78.62, "end": 78.78, "confidence": 0.985}, {"text": "these", "start": 78.78, "end": 79.08, "confidence": 0.951}, {"text": "STMOe", "start": 79.08, "end": 79.86, "confidence": 0.94}, {"text": "models", "start": 79.86, "end": 80.12, "confidence": 0.881}, {"text": "have", "start": 80.12, "end": 80.34, "confidence": 0.971}, {"text": "a", "start": 80.34, "end": 80.42, "confidence": 0.998}, {"text": "similar", "start": 80.42, "end": 80.98, "confidence": 0.903}, {"text": "ability.", "start": 80.98, "end": 81.44, "confidence": 0.986}, {"text": "They", "start": 81.48, "end": 81.96, "confidence": 0.952}, {"text": "can", "start": 81.96, "end": 82.16, "confidence": 0.987}, {"text": "handle", "start": 82.16, "end": 82.46, "confidence": 0.973}, {"text": "these", "start": 82.46, "end": 82.64, "confidence": 0.946}, {"text": "missing", "start": 82.64, "end": 83.3, "confidence": 0.97}, {"text": "chunks", "start": 83.3, "end": 83.48, "confidence": 0.96}, {"text": "of", "start": 83.48, "end": 83.72, "confidence": 0.991}, {"text": "information", "start": 83.72, "end": 84.32, "confidence": 0.861}, {"text": "without", "start": 84.32, "end": 85.58, "confidence": 0.94}, {"text": "completely", "start": 85.58, "end": 86.2, "confidence": 0.877}, {"text": "falling", "start": 86.2, "end": 86.74, "confidence": 0.952}, {"text": "apart.", "start": 86.74, "end": 87.22, "confidence": 0.969}]}, {"id": 6, "seek": 8774, "start": 87.74, "end": 117.28, "text": " That's huge. Think about it. If these models can deal with like incomplete data, that makes them incredibly powerful for real world scenarios, analyzing damaged documents, understanding speech with errors, even making sense of, you know, fragmented online information. You're getting it. This robustness is a game changer. But as with anything, there are these tradeoffs. One thing that jumped out at me is that sparse models can be prone to overfitting, especially with smaller data sets.", "tokens": [50379, 663, 311, 2603, 13, 6557, 466, 309, 13, 759, 220, 42678, 5245, 393, 2028, 365, 411, 31709, 1412, 11, 220, 6780, 1669, 220, 47959, 6252, 4005, 337, 957, 1002, 4191, 289, 2717, 11, 23663, 2422, 559, 292, 8512, 11, 3701, 6218, 365, 13603, 11, 754, 1455, 2020, 295, 11, 291, 458, 11, 9241, 14684, 2950, 1589, 13, 509, 434, 1242, 309, 13, 639, 13956, 1287, 307, 257, 1216, 22822, 13, 583, 382, 365, 1340, 11, 220, 15456, 366, 220, 42678, 220, 6903, 762, 19231, 13, 1485, 220, 825, 220, 6780, 13864, 484, 412, 385, 307, 220, 6780, 637, 11668, 5245, 393, 312, 25806, 220, 1353, 670, 69, 2414, 11, 2318, 365, 4356, 1412, 6352, 13, 51841], "temperature": 0.0, "avg_logprob": -0.14352216640440355, "compression_ratio": 1.6085526315789473, "no_speech_prob": 0.44398391246795654, "confidence": 0.903, "words": [{"text": "That's", "start": 87.74, "end": 88.38, "confidence": 0.971}, {"text": "huge.", "start": 88.38, "end": 88.98, "confidence": 0.943}, {"text": "Think", "start": 89.24, "end": 89.66, "confidence": 0.928}, {"text": "about", "start": 89.66, "end": 89.82, "confidence": 0.986}, {"text": "it.", "start": 89.82, "end": 90.16, "confidence": 0.946}, {"text": "If", "start": 90.26, "end": 90.28, "confidence": 0.994}, {"text": "these", "start": 90.28, "end": 90.5, "confidence": 0.991}, {"text": "models", "start": 90.5, "end": 91.14, "confidence": 0.945}, {"text": "can", "start": 91.14, "end": 91.2, "confidence": 0.97}, {"text": "deal", "start": 91.2, "end": 91.4, "confidence": 0.962}, {"text": "with", "start": 91.4, "end": 91.54, "confidence": 0.996}, {"text": "like", "start": 91.54, "end": 91.9, "confidence": 0.696}, {"text": "incomplete", "start": 91.9, "end": 92.9, "confidence": 0.93}, {"text": "data,", "start": 92.9, "end": 93.34, "confidence": 0.976}, {"text": "that", "start": 93.46, "end": 94.14, "confidence": 0.995}, {"text": "makes", "start": 94.14, "end": 94.56, "confidence": 0.964}, {"text": "them", "start": 94.56, "end": 94.58, "confidence": 0.973}, {"text": "incredibly", "start": 94.58, "end": 95.2, "confidence": 0.973}, {"text": "powerful", "start": 95.2, "end": 95.78, "confidence": 0.984}, {"text": "for", "start": 95.78, "end": 96.08, "confidence": 0.995}, {"text": "real", "start": 96.08, "end": 96.54, "confidence": 0.994}, {"text": "world", "start": 96.54, "end": 96.56, "confidence": 0.78}, {"text": "scenarios,", "start": 96.56, "end": 97.46, "confidence": 0.766}, {"text": "analyzing", "start": 97.84, "end": 98.28, "confidence": 0.309}, {"text": "damaged", "start": 98.28, "end": 98.82, "confidence": 0.7}, {"text": "documents,", "start": 98.82, "end": 99.44, "confidence": 0.909}, {"text": "understanding", "start": 100.58, "end": 100.6, "confidence": 0.733}, {"text": "speech", "start": 100.6, "end": 101.28, "confidence": 0.869}, {"text": "with", "start": 101.28, "end": 101.3, "confidence": 0.986}, {"text": "errors,", "start": 101.3, "end": 101.74, "confidence": 0.982}, {"text": "even", "start": 102.32, "end": 102.34, "confidence": 0.971}, {"text": "making", "start": 102.34, "end": 102.64, "confidence": 0.984}, {"text": "sense", "start": 102.64, "end": 103.04, "confidence": 0.918}, {"text": "of,", "start": 103.04, "end": 103.46, "confidence": 0.993}, {"text": "you", "start": 103.8, "end": 103.88, "confidence": 0.985}, {"text": "know,", "start": 103.88, "end": 103.9, "confidence": 0.966}, {"text": "fragmented", "start": 104.1, "end": 104.58, "confidence": 0.817}, {"text": "online", "start": 104.58, "end": 105.04, "confidence": 0.921}, {"text": "information.", "start": 105.04, "end": 105.74, "confidence": 0.881}, {"text": "You're", "start": 105.74, "end": 106.06, "confidence": 0.944}, {"text": "getting", "start": 106.06, "end": 106.28, "confidence": 0.978}, {"text": "it.", "start": 106.28, "end": 106.62, "confidence": 0.977}, {"text": "This", "start": 106.62, "end": 106.88, "confidence": 0.96}, {"text": "robustness", "start": 106.88, "end": 107.8, "confidence": 0.987}, {"text": "is", "start": 107.8, "end": 108.16, "confidence": 0.979}, {"text": "a", "start": 108.16, "end": 108.18, "confidence": 0.997}, {"text": "game", "start": 108.18, "end": 108.2, "confidence": 0.974}, {"text": "changer.", "start": 108.2, "end": 108.66, "confidence": 0.933}, {"text": "But", "start": 108.88, "end": 109.8, "confidence": 0.974}, {"text": "as", "start": 109.8, "end": 110.2, "confidence": 0.859}, {"text": "with", "start": 110.2, "end": 110.4, "confidence": 0.995}, {"text": "anything,", "start": 110.4, "end": 110.84, "confidence": 0.975}, {"text": "there", "start": 111.12, "end": 111.14, "confidence": 0.987}, {"text": "are", "start": 111.14, "end": 111.28, "confidence": 0.982}, {"text": "these", "start": 111.28, "end": 111.3, "confidence": 0.99}, {"text": "tradeoffs.", "start": 111.3, "end": 111.76, "confidence": 0.78}, {"text": "One", "start": 111.94, "end": 112.14, "confidence": 0.968}, {"text": "thing", "start": 112.14, "end": 112.28, "confidence": 0.996}, {"text": "that", "start": 112.28, "end": 112.34, "confidence": 0.997}, {"text": "jumped", "start": 112.34, "end": 112.58, "confidence": 0.895}, {"text": "out", "start": 112.58, "end": 112.76, "confidence": 0.984}, {"text": "at", "start": 112.76, "end": 112.84, "confidence": 0.996}, {"text": "me", "start": 112.84, "end": 113.16, "confidence": 0.998}, {"text": "is", "start": 113.16, "end": 113.18, "confidence": 0.976}, {"text": "that", "start": 113.18, "end": 113.32, "confidence": 0.996}, {"text": "sparse", "start": 113.32, "end": 113.7, "confidence": 0.956}, {"text": "models", "start": 113.7, "end": 114.06, "confidence": 0.918}, {"text": "can", "start": 114.06, "end": 114.24, "confidence": 0.986}, {"text": "be", "start": 114.24, "end": 114.44, "confidence": 0.997}, {"text": "prone", "start": 114.44, "end": 114.58, "confidence": 0.357}, {"text": "to", "start": 114.58, "end": 114.72, "confidence": 0.996}, {"text": "overfitting,", "start": 114.72, "end": 115.14, "confidence": 0.964}, {"text": "especially", "start": 116.02, "end": 116.16, "confidence": 0.984}, {"text": "with", "start": 116.16, "end": 116.38, "confidence": 0.993}, {"text": "smaller", "start": 116.38, "end": 116.82, "confidence": 0.515}, {"text": "data", "start": 116.82, "end": 117.06, "confidence": 0.864}, {"text": "sets.", "start": 117.06, "end": 117.28, "confidence": 0.573}]}, {"id": 7, "seek": 11728, "start": 117.28, "end": 143.76, "text": " That sounds like that specialist who's brilliant in their narrow field, but they struggle when they're faced with something outside their expertise. They need that broader perspective. Exactly. The research suggests that fine tuning these models requires a different approach than what we use for the massive, dense models. Smaller batches of data, faster learning rates. It's like meeting a customized training regimen for like peak performance. And here's where things get really fascinating.", "tokens": [50364, 663, 3263, 411, 220, 6780, 637, 68, 1013, 468, 567, 311, 10248, 294, 220, 3322, 347, 9432, 2519, 11, 457, 220, 13162, 7799, 562, 220, 13162, 434, 11446, 365, 746, 2380, 220, 3322, 347, 11769, 13, 814, 643, 220, 6780, 2006, 8312, 4585, 13, 7587, 13, 440, 2132, 3395, 4409, 220, 6780, 2489, 220, 83, 37726, 220, 42678, 5245, 7029, 257, 819, 3109, 220, 24852, 437, 321, 764, 337, 220, 3322, 5994, 11, 1441, 405, 5245, 13, 15287, 260, 15245, 279, 295, 1412, 11, 4663, 2539, 5937, 279, 13, 467, 311, 411, 3440, 257, 30581, 220, 17227, 1760, 1121, 19676, 337, 411, 10651, 3389, 13, 400, 510, 311, 689, 220, 825, 82, 483, 534, 10343, 13], "temperature": 0.0, "avg_logprob": -0.1409605155556889, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.38497695326805115, "confidence": 0.89, "words": [{"text": "That", "start": 117.28, "end": 117.66, "confidence": 0.293}, {"text": "sounds", "start": 117.66, "end": 117.68, "confidence": 0.57}, {"text": "like", "start": 117.68, "end": 117.74, "confidence": 0.985}, {"text": "that", "start": 117.74, "end": 117.88, "confidence": 0.98}, {"text": "specialist", "start": 117.88, "end": 118.34, "confidence": 0.757}, {"text": "who's", "start": 118.34, "end": 118.52, "confidence": 0.888}, {"text": "brilliant", "start": 118.52, "end": 119.04, "confidence": 0.779}, {"text": "in", "start": 119.04, "end": 119.2, "confidence": 0.982}, {"text": "their", "start": 119.2, "end": 119.36, "confidence": 0.993}, {"text": "narrow", "start": 119.36, "end": 119.72, "confidence": 0.692}, {"text": "field,", "start": 119.72, "end": 120.02, "confidence": 0.887}, {"text": "but", "start": 120.34, "end": 120.7, "confidence": 0.986}, {"text": "they", "start": 120.7, "end": 120.84, "confidence": 0.989}, {"text": "struggle", "start": 120.84, "end": 121.38, "confidence": 0.911}, {"text": "when", "start": 121.38, "end": 121.62, "confidence": 0.983}, {"text": "they're", "start": 121.62, "end": 121.88, "confidence": 0.985}, {"text": "faced", "start": 121.88, "end": 122.1, "confidence": 0.895}, {"text": "with", "start": 122.1, "end": 122.26, "confidence": 0.997}, {"text": "something", "start": 122.26, "end": 122.52, "confidence": 0.954}, {"text": "outside", "start": 122.52, "end": 122.86, "confidence": 0.966}, {"text": "their", "start": 122.86, "end": 123.08, "confidence": 0.934}, {"text": "expertise.", "start": 123.08, "end": 123.82, "confidence": 0.561}, {"text": "They", "start": 123.82, "end": 124.16, "confidence": 0.937}, {"text": "need", "start": 124.16, "end": 124.42, "confidence": 0.984}, {"text": "that", "start": 124.42, "end": 124.52, "confidence": 0.993}, {"text": "broader", "start": 124.52, "end": 124.88, "confidence": 0.933}, {"text": "perspective.", "start": 124.88, "end": 125.56, "confidence": 0.781}, {"text": "Exactly.", "start": 125.58, "end": 126.0, "confidence": 0.554}, {"text": "The", "start": 126.48, "end": 126.9, "confidence": 0.734}, {"text": "research", "start": 126.9, "end": 127.28, "confidence": 0.984}, {"text": "suggests", "start": 127.28, "end": 127.8, "confidence": 0.692}, {"text": "that", "start": 127.8, "end": 128.14, "confidence": 0.99}, {"text": "fine", "start": 128.14, "end": 128.58, "confidence": 0.826}, {"text": "tuning", "start": 128.58, "end": 128.84, "confidence": 0.919}, {"text": "these", "start": 128.84, "end": 129.1, "confidence": 0.938}, {"text": "models", "start": 129.1, "end": 129.98, "confidence": 0.944}, {"text": "requires", "start": 129.98, "end": 130.76, "confidence": 0.831}, {"text": "a", "start": 130.76, "end": 130.88, "confidence": 0.997}, {"text": "different", "start": 130.88, "end": 131.22, "confidence": 0.963}, {"text": "approach", "start": 131.22, "end": 131.66, "confidence": 0.928}, {"text": "than", "start": 131.66, "end": 131.84, "confidence": 0.988}, {"text": "what", "start": 131.84, "end": 132.0, "confidence": 0.997}, {"text": "we", "start": 132.0, "end": 132.12, "confidence": 0.992}, {"text": "use", "start": 132.12, "end": 132.36, "confidence": 0.849}, {"text": "for", "start": 132.36, "end": 132.5, "confidence": 0.996}, {"text": "the", "start": 132.5, "end": 132.52, "confidence": 0.997}, {"text": "massive,", "start": 132.52, "end": 133.18, "confidence": 0.965}, {"text": "dense", "start": 133.6, "end": 133.62, "confidence": 0.722}, {"text": "models.", "start": 133.62, "end": 134.52, "confidence": 0.915}, {"text": "Smaller", "start": 134.94, "end": 135.3, "confidence": 0.734}, {"text": "batches", "start": 135.3, "end": 135.66, "confidence": 0.968}, {"text": "of", "start": 135.66, "end": 135.82, "confidence": 0.995}, {"text": "data,", "start": 135.82, "end": 136.28, "confidence": 0.979}, {"text": "faster", "start": 136.48, "end": 136.98, "confidence": 0.979}, {"text": "learning", "start": 136.98, "end": 137.32, "confidence": 0.985}, {"text": "rates.", "start": 137.32, "end": 137.96, "confidence": 0.764}, {"text": "It's", "start": 137.96, "end": 138.44, "confidence": 0.995}, {"text": "like", "start": 138.44, "end": 138.58, "confidence": 0.988}, {"text": "meeting", "start": 138.58, "end": 138.78, "confidence": 0.734}, {"text": "a", "start": 138.78, "end": 138.98, "confidence": 0.999}, {"text": "customized", "start": 138.98, "end": 139.48, "confidence": 0.785}, {"text": "training", "start": 139.48, "end": 139.98, "confidence": 0.963}, {"text": "regimen", "start": 139.98, "end": 140.2, "confidence": 0.938}, {"text": "for", "start": 140.2, "end": 140.54, "confidence": 0.994}, {"text": "like", "start": 140.54, "end": 140.76, "confidence": 0.92}, {"text": "peak", "start": 140.76, "end": 140.88, "confidence": 0.879}, {"text": "performance.", "start": 140.88, "end": 141.42, "confidence": 0.96}, {"text": "And", "start": 141.54, "end": 141.64, "confidence": 0.891}, {"text": "here's", "start": 141.64, "end": 141.92, "confidence": 0.946}, {"text": "where", "start": 141.92, "end": 142.38, "confidence": 0.996}, {"text": "things", "start": 142.38, "end": 142.46, "confidence": 0.992}, {"text": "get", "start": 142.46, "end": 142.48, "confidence": 0.986}, {"text": "really", "start": 142.48, "end": 142.9, "confidence": 0.919}, {"text": "fascinating.", "start": 142.9, "end": 143.76, "confidence": 0.661}]}, {"id": 8, "seek": 14728, "start": 147.96, "end": 149.26, "text": " So what happens when you close through these expert models?", "tokens": [50364, 407, 437, 2314, 562, 291, 1998, 220, 11529, 220, 42678, 5844, 5245, 30, 50464], "temperature": 0.0, "avg_logprob": -0.2366162618001302, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.7684943079948425, "confidence": 0.405, "words": [{"text": "So", "start": 147.96, "end": 147.98, "confidence": 0.124}, {"text": "what", "start": 147.98, "end": 148.0, "confidence": 0.27}, {"text": "happens", "start": 148.0, "end": 148.02, "confidence": 0.153}, {"text": "when", "start": 148.02, "end": 148.04, "confidence": 0.276}, {"text": "you", "start": 148.04, "end": 148.06, "confidence": 0.337}, {"text": "close", "start": 148.06, "end": 148.08, "confidence": 0.073}, {"text": "through", "start": 148.08, "end": 148.26, "confidence": 0.917}, {"text": "these", "start": 148.26, "end": 148.56, "confidence": 0.982}, {"text": "expert", "start": 148.56, "end": 148.82, "confidence": 0.749}, {"text": "models?", "start": 148.82, "end": 149.26, "confidence": 0.918}]}, {"id": 9, "seek": 14728, "start": 149.3, "end": 157.58, "text": " Isn't that cool? They traced individual words as they went through the model, like watching a tiny delivery truck carrying a word and dropping it off at the right expert's door.", "tokens": [50464, 6998, 380, 220, 6780, 1627, 30, 814, 220, 6903, 3839, 2609, 2283, 382, 220, 13162, 1437, 220, 11529, 220, 3322, 2316, 11, 411, 1976, 257, 220, 83, 3519, 8982, 220, 83, 8161, 9792, 257, 1349, 293, 13601, 309, 766, 412, 220, 3322, 558, 5844, 311, 2853, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2366162618001302, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.7684943079948425, "confidence": 0.925, "words": [{"text": "Isn't", "start": 149.3, "end": 149.6, "confidence": 0.952}, {"text": "that", "start": 149.6, "end": 149.7, "confidence": 0.973}, {"text": "cool?", "start": 149.7, "end": 149.86, "confidence": 0.988}, {"text": "They", "start": 149.94, "end": 150.14, "confidence": 0.937}, {"text": "traced", "start": 150.14, "end": 150.44, "confidence": 0.756}, {"text": "individual", "start": 150.44, "end": 150.96, "confidence": 0.901}, {"text": "words", "start": 150.96, "end": 151.34, "confidence": 0.994}, {"text": "as", "start": 151.34, "end": 151.54, "confidence": 0.947}, {"text": "they", "start": 151.54, "end": 151.68, "confidence": 0.991}, {"text": "went", "start": 151.68, "end": 151.84, "confidence": 0.931}, {"text": "through", "start": 151.84, "end": 152.06, "confidence": 0.992}, {"text": "the", "start": 152.06, "end": 152.14, "confidence": 0.997}, {"text": "model,", "start": 152.14, "end": 152.44, "confidence": 0.667}, {"text": "like", "start": 152.56, "end": 152.64, "confidence": 0.963}, {"text": "watching", "start": 152.64, "end": 153.04, "confidence": 0.991}, {"text": "a", "start": 153.04, "end": 153.16, "confidence": 0.997}, {"text": "tiny", "start": 153.16, "end": 153.58, "confidence": 0.966}, {"text": "delivery", "start": 153.58, "end": 154.08, "confidence": 0.899}, {"text": "truck", "start": 154.08, "end": 154.34, "confidence": 0.96}, {"text": "carrying", "start": 154.34, "end": 154.62, "confidence": 0.873}, {"text": "a", "start": 154.62, "end": 154.78, "confidence": 0.993}, {"text": "word", "start": 154.78, "end": 155.04, "confidence": 0.993}, {"text": "and", "start": 155.04, "end": 155.62, "confidence": 0.916}, {"text": "dropping", "start": 155.62, "end": 155.86, "confidence": 0.833}, {"text": "it", "start": 155.86, "end": 156.04, "confidence": 0.984}, {"text": "off", "start": 156.04, "end": 156.24, "confidence": 0.993}, {"text": "at", "start": 156.24, "end": 156.36, "confidence": 0.982}, {"text": "the", "start": 156.36, "end": 156.46, "confidence": 0.999}, {"text": "right", "start": 156.46, "end": 156.62, "confidence": 0.98}, {"text": "expert's", "start": 156.62, "end": 157.1, "confidence": 0.679}, {"text": "door.", "start": 157.1, "end": 157.58, "confidence": 0.954}]}, {"id": 10, "seek": 14728, "start": 157.8, "end": 166.14, "text": " I love that. So instead of a black box, we're actually getting a peek behind the curtain of how this AI is actually thinking. What did they find?", "tokens": [50914, 286, 959, 220, 6780, 13, 407, 2602, 295, 257, 2211, 2424, 11, 321, 434, 767, 1242, 257, 19604, 2261, 220, 3322, 26789, 295, 577, 220, 11176, 7318, 307, 767, 220, 39873, 13, 708, 630, 220, 13162, 915, 30, 51314], "temperature": 0.0, "avg_logprob": -0.2366162618001302, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.7684943079948425, "confidence": 0.96, "words": [{"text": "I", "start": 157.8, "end": 158.2, "confidence": 0.717}, {"text": "love", "start": 158.2, "end": 158.76, "confidence": 0.994}, {"text": "that.", "start": 158.76, "end": 159.34, "confidence": 0.998}, {"text": "So", "start": 159.36, "end": 159.54, "confidence": 0.984}, {"text": "instead", "start": 159.54, "end": 159.84, "confidence": 0.963}, {"text": "of", "start": 159.84, "end": 159.96, "confidence": 0.996}, {"text": "a", "start": 159.96, "end": 160.02, "confidence": 0.998}, {"text": "black", "start": 160.02, "end": 160.32, "confidence": 0.99}, {"text": "box,", "start": 160.32, "end": 160.6, "confidence": 0.964}, {"text": "we're", "start": 160.76, "end": 160.78, "confidence": 0.982}, {"text": "actually", "start": 160.78, "end": 161.04, "confidence": 0.959}, {"text": "getting", "start": 161.04, "end": 161.32, "confidence": 0.984}, {"text": "a", "start": 161.32, "end": 162.04, "confidence": 0.998}, {"text": "peek", "start": 162.04, "end": 162.06, "confidence": 0.969}, {"text": "behind", "start": 162.06, "end": 163.16, "confidence": 0.975}, {"text": "the", "start": 163.16, "end": 163.4, "confidence": 0.999}, {"text": "curtain", "start": 163.4, "end": 163.58, "confidence": 0.962}, {"text": "of", "start": 163.58, "end": 163.76, "confidence": 0.968}, {"text": "how", "start": 163.76, "end": 163.94, "confidence": 0.989}, {"text": "this", "start": 163.94, "end": 164.06, "confidence": 0.995}, {"text": "AI", "start": 164.06, "end": 164.32, "confidence": 0.624}, {"text": "is", "start": 164.32, "end": 164.44, "confidence": 0.968}, {"text": "actually", "start": 164.44, "end": 164.68, "confidence": 0.968}, {"text": "thinking.", "start": 164.68, "end": 165.16, "confidence": 0.995}, {"text": "What", "start": 165.68, "end": 165.76, "confidence": 0.979}, {"text": "did", "start": 165.76, "end": 165.78, "confidence": 0.926}, {"text": "they", "start": 165.78, "end": 165.8, "confidence": 0.993}, {"text": "find?", "start": 165.8, "end": 166.14, "confidence": 0.96}]}, {"id": 11, "seek": 17728, "start": 177.78, "end": 198.68, "text": " It was like watching different departments in a company, each with their own area of expertise. So we're not just training one giant AI. We're cultivating a whole ecosystem of specialized skills. And that, my friend, leads us to one of the biggest questions this research raises. They tried training these models on multiple languages. But something unexpected happened.", "tokens": [50414, 467, 390, 411, 1976, 819, 9110, 76, 791, 294, 257, 2237, 11, 1184, 365, 220, 3322, 347, 1065, 1859, 295, 11769, 13, 407, 321, 434, 406, 445, 220, 17227, 1760, 472, 7410, 7318, 13, 492, 434, 15298, 990, 257, 1379, 11311, 295, 768, 1013, 1602, 3942, 13, 400, 220, 6780, 11, 452, 1277, 11, 6689, 505, 220, 1353, 472, 295, 220, 3322, 3880, 1651, 220, 11176, 2132, 19658, 13, 814, 220, 83, 2428, 220, 17227, 1760, 220, 42678, 5245, 322, 3866, 8650, 13, 583, 746, 13106, 2011, 13, 51414], "temperature": 0.0, "avg_logprob": -0.11513116857507727, "compression_ratio": 1.4979757085020242, "no_speech_prob": 0.8009596467018127, "confidence": 0.915, "words": [{"text": "It", "start": 177.78, "end": 177.86, "confidence": 0.399}, {"text": "was", "start": 177.86, "end": 177.88, "confidence": 0.859}, {"text": "like", "start": 177.88, "end": 177.9, "confidence": 0.955}, {"text": "watching", "start": 177.9, "end": 178.2, "confidence": 0.966}, {"text": "different", "start": 178.2, "end": 178.42, "confidence": 0.957}, {"text": "departments", "start": 178.42, "end": 179.0, "confidence": 0.891}, {"text": "in", "start": 179.0, "end": 179.02, "confidence": 0.983}, {"text": "a", "start": 179.02, "end": 179.34, "confidence": 0.99}, {"text": "company,", "start": 179.34, "end": 179.66, "confidence": 0.985}, {"text": "each", "start": 179.78, "end": 179.92, "confidence": 0.986}, {"text": "with", "start": 179.92, "end": 180.1, "confidence": 0.995}, {"text": "their", "start": 180.1, "end": 180.24, "confidence": 0.995}, {"text": "own", "start": 180.24, "end": 180.36, "confidence": 0.984}, {"text": "area", "start": 180.36, "end": 180.66, "confidence": 0.96}, {"text": "of", "start": 180.66, "end": 180.84, "confidence": 0.994}, {"text": "expertise.", "start": 180.84, "end": 181.26, "confidence": 0.632}, {"text": "So", "start": 181.4, "end": 181.62, "confidence": 0.502}, {"text": "we're", "start": 181.62, "end": 181.76, "confidence": 0.981}, {"text": "not", "start": 181.76, "end": 181.9, "confidence": 0.979}, {"text": "just", "start": 181.9, "end": 182.12, "confidence": 0.982}, {"text": "training", "start": 182.12, "end": 182.56, "confidence": 0.931}, {"text": "one", "start": 182.56, "end": 182.9, "confidence": 0.98}, {"text": "giant", "start": 182.9, "end": 183.3, "confidence": 0.869}, {"text": "AI.", "start": 183.3, "end": 183.76, "confidence": 0.991}, {"text": "We're", "start": 183.8, "end": 184.64, "confidence": 0.987}, {"text": "cultivating", "start": 184.64, "end": 185.04, "confidence": 0.871}, {"text": "a", "start": 185.04, "end": 185.16, "confidence": 0.991}, {"text": "whole", "start": 185.16, "end": 185.56, "confidence": 0.981}, {"text": "ecosystem", "start": 185.56, "end": 186.26, "confidence": 0.776}, {"text": "of", "start": 186.26, "end": 186.5, "confidence": 0.988}, {"text": "specialized", "start": 186.5, "end": 186.96, "confidence": 0.734}, {"text": "skills.", "start": 186.96, "end": 187.64, "confidence": 0.957}, {"text": "And", "start": 187.66, "end": 187.96, "confidence": 0.744}, {"text": "that,", "start": 187.96, "end": 188.9, "confidence": 0.993}, {"text": "my", "start": 188.92, "end": 189.42, "confidence": 0.993}, {"text": "friend,", "start": 189.42, "end": 189.82, "confidence": 0.974}, {"text": "leads", "start": 190.4, "end": 190.58, "confidence": 0.956}, {"text": "us", "start": 190.58, "end": 190.88, "confidence": 0.979}, {"text": "to", "start": 190.88, "end": 191.08, "confidence": 0.997}, {"text": "one", "start": 191.08, "end": 191.28, "confidence": 0.961}, {"text": "of", "start": 191.28, "end": 191.4, "confidence": 0.991}, {"text": "the", "start": 191.4, "end": 191.66, "confidence": 0.998}, {"text": "biggest", "start": 191.66, "end": 191.86, "confidence": 0.964}, {"text": "questions", "start": 191.86, "end": 192.36, "confidence": 0.985}, {"text": "this", "start": 192.36, "end": 192.5, "confidence": 0.983}, {"text": "research", "start": 192.5, "end": 192.92, "confidence": 0.99}, {"text": "raises.", "start": 192.92, "end": 193.7, "confidence": 0.658}, {"text": "They", "start": 193.88, "end": 193.96, "confidence": 0.87}, {"text": "tried", "start": 193.96, "end": 194.24, "confidence": 0.934}, {"text": "training", "start": 194.24, "end": 194.66, "confidence": 0.967}, {"text": "these", "start": 194.66, "end": 194.88, "confidence": 0.967}, {"text": "models", "start": 194.88, "end": 195.36, "confidence": 0.947}, {"text": "on", "start": 195.36, "end": 195.5, "confidence": 0.986}, {"text": "multiple", "start": 195.5, "end": 195.86, "confidence": 0.883}, {"text": "languages.", "start": 195.86, "end": 196.82, "confidence": 0.798}, {"text": "But", "start": 197.18, "end": 197.2, "confidence": 0.978}, {"text": "something", "start": 197.2, "end": 197.56, "confidence": 0.953}, {"text": "unexpected", "start": 197.56, "end": 198.22, "confidence": 0.883}, {"text": "happened.", "start": 198.22, "end": 198.68, "confidence": 0.944}]}, {"id": 12, "seek": 20728, "start": 207.78, "end": 236.9, "text": " They all became multilingual, handling every language thrown at them. So are they learning some kind of universal language structure, like a hidden code beneath all these human tongues? Or is it something about the way they're trained that's pushing them towards this jack-of-all-trades approach? Those are exactly the questions researchers are grappling with. And the answer could change how we think about AI and language forever. It makes you wonder what would happen if we could guide that specialization. Could we unlock even greater efficiency and accuracy? This is what I call the trivia.", "tokens": [50414, 814, 439, 3062, 2120, 4883, 901, 11, 13175, 633, 2856, 220, 392, 81, 648, 412, 220, 47959, 13, 407, 366, 220, 13162, 2539, 512, 733, 295, 11455, 2856, 342, 894, 42919, 11, 411, 257, 7633, 3089, 17149, 439, 220, 42678, 1952, 220, 83, 556, 1247, 30, 1610, 307, 309, 746, 466, 220, 3322, 636, 220, 13162, 434, 220, 17227, 2001, 220, 6780, 311, 7380, 220, 47959, 220, 83, 305, 2287, 220, 11176, 7109, 12, 2670, 12, 336, 12, 6903, 2977, 3109, 30, 3950, 366, 2293, 220, 3322, 1651, 10309, 366, 50086, 365, 13, 400, 220, 3322, 1867, 727, 1319, 577, 321, 220, 21074, 466, 7318, 293, 2856, 5680, 13, 467, 1669, 291, 2441, 437, 576, 1051, 498, 321, 727, 5934, 220, 6780, 2121, 2144, 13, 7497, 321, 11634, 754, 5044, 1244, 299, 1053, 1344, 293, 220, 8476, 374, 2551, 30, 639, 307, 437, 286, 818, 220, 3322, 220, 83, 470, 11617, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1843120574951172, "compression_ratio": 1.6620111731843576, "no_speech_prob": 0.7540530562400818, "confidence": 0.837, "words": [{"text": "They", "start": 207.78, "end": 208.46, "confidence": 0.772}, {"text": "all", "start": 208.46, "end": 208.74, "confidence": 0.969}, {"text": "became", "start": 208.74, "end": 209.12, "confidence": 0.637}, {"text": "multilingual,", "start": 209.12, "end": 210.04, "confidence": 0.817}, {"text": "handling", "start": 210.52, "end": 210.78, "confidence": 0.967}, {"text": "every", "start": 210.78, "end": 211.14, "confidence": 0.966}, {"text": "language", "start": 211.14, "end": 211.68, "confidence": 0.852}, {"text": "thrown", "start": 211.68, "end": 212.0, "confidence": 0.984}, {"text": "at", "start": 212.0, "end": 212.14, "confidence": 0.99}, {"text": "them.", "start": 212.14, "end": 212.32, "confidence": 0.987}, {"text": "So", "start": 212.32, "end": 212.46, "confidence": 0.543}, {"text": "are", "start": 212.46, "end": 212.7, "confidence": 0.979}, {"text": "they", "start": 212.7, "end": 212.8, "confidence": 0.991}, {"text": "learning", "start": 212.8, "end": 213.18, "confidence": 0.986}, {"text": "some", "start": 213.18, "end": 213.4, "confidence": 0.821}, {"text": "kind", "start": 213.4, "end": 213.66, "confidence": 0.979}, {"text": "of", "start": 213.66, "end": 213.74, "confidence": 0.995}, {"text": "universal", "start": 213.74, "end": 214.32, "confidence": 0.948}, {"text": "language", "start": 214.32, "end": 214.58, "confidence": 0.844}, {"text": "structure,", "start": 214.58, "end": 215.12, "confidence": 0.827}, {"text": "like", "start": 215.74, "end": 215.76, "confidence": 0.977}, {"text": "a", "start": 215.76, "end": 215.94, "confidence": 0.998}, {"text": "hidden", "start": 215.94, "end": 216.12, "confidence": 0.942}, {"text": "code", "start": 216.12, "end": 216.52, "confidence": 0.969}, {"text": "beneath", "start": 216.52, "end": 216.84, "confidence": 0.845}, {"text": "all", "start": 216.84, "end": 217.04, "confidence": 0.986}, {"text": "these", "start": 217.04, "end": 217.12, "confidence": 0.991}, {"text": "human", "start": 217.12, "end": 217.44, "confidence": 0.959}, {"text": "tongues?", "start": 217.44, "end": 217.92, "confidence": 0.992}, {"text": "Or", "start": 217.92, "end": 218.38, "confidence": 0.858}, {"text": "is", "start": 218.38, "end": 218.58, "confidence": 0.976}, {"text": "it", "start": 218.58, "end": 218.62, "confidence": 0.975}, {"text": "something", "start": 218.62, "end": 219.02, "confidence": 0.95}, {"text": "about", "start": 219.02, "end": 219.38, "confidence": 0.978}, {"text": "the", "start": 219.38, "end": 219.74, "confidence": 0.997}, {"text": "way", "start": 219.74, "end": 219.76, "confidence": 0.996}, {"text": "they're", "start": 219.76, "end": 219.82, "confidence": 0.984}, {"text": "trained", "start": 219.82, "end": 220.4, "confidence": 0.964}, {"text": "that's", "start": 220.4, "end": 221.24, "confidence": 0.83}, {"text": "pushing", "start": 221.24, "end": 221.4, "confidence": 0.849}, {"text": "them", "start": 221.4, "end": 221.64, "confidence": 0.991}, {"text": "towards", "start": 221.64, "end": 222.04, "confidence": 0.982}, {"text": "this", "start": 222.04, "end": 222.32, "confidence": 0.996}, {"text": "jack-of-all-trades", "start": 222.32, "end": 223.24, "confidence": 0.892}, {"text": "approach?", "start": 223.24, "end": 223.78, "confidence": 0.952}, {"text": "Those", "start": 223.78, "end": 224.06, "confidence": 0.524}, {"text": "are", "start": 224.06, "end": 224.42, "confidence": 0.988}, {"text": "exactly", "start": 224.42, "end": 224.98, "confidence": 0.985}, {"text": "the", "start": 224.98, "end": 225.04, "confidence": 0.999}, {"text": "questions", "start": 225.04, "end": 225.46, "confidence": 0.989}, {"text": "researchers", "start": 225.46, "end": 226.04, "confidence": 0.862}, {"text": "are", "start": 226.04, "end": 226.16, "confidence": 0.98}, {"text": "grappling", "start": 226.16, "end": 226.5, "confidence": 0.759}, {"text": "with.", "start": 226.5, "end": 226.84, "confidence": 0.995}, {"text": "And", "start": 226.86, "end": 227.04, "confidence": 0.967}, {"text": "the", "start": 227.04, "end": 227.14, "confidence": 0.996}, {"text": "answer", "start": 227.14, "end": 227.56, "confidence": 0.961}, {"text": "could", "start": 227.56, "end": 227.72, "confidence": 0.997}, {"text": "change", "start": 227.72, "end": 227.96, "confidence": 0.991}, {"text": "how", "start": 227.96, "end": 228.14, "confidence": 0.987}, {"text": "we", "start": 228.14, "end": 228.18, "confidence": 0.987}, {"text": "think", "start": 228.18, "end": 228.4, "confidence": 0.997}, {"text": "about", "start": 228.4, "end": 228.58, "confidence": 0.981}, {"text": "AI", "start": 228.58, "end": 229.04, "confidence": 0.953}, {"text": "and", "start": 229.04, "end": 229.2, "confidence": 0.964}, {"text": "language", "start": 229.2, "end": 229.48, "confidence": 0.776}, {"text": "forever.", "start": 229.48, "end": 229.9, "confidence": 0.968}, {"text": "It", "start": 230.2, "end": 230.42, "confidence": 0.948}, {"text": "makes", "start": 230.42, "end": 230.58, "confidence": 0.972}, {"text": "you", "start": 230.58, "end": 230.72, "confidence": 0.993}, {"text": "wonder", "start": 230.72, "end": 231.04, "confidence": 0.968}, {"text": "what", "start": 231.04, "end": 231.54, "confidence": 0.578}, {"text": "would", "start": 231.54, "end": 231.72, "confidence": 0.997}, {"text": "happen", "start": 231.72, "end": 232.04, "confidence": 0.944}, {"text": "if", "start": 232.04, "end": 232.22, "confidence": 0.977}, {"text": "we", "start": 232.22, "end": 232.28, "confidence": 0.994}, {"text": "could", "start": 232.28, "end": 232.46, "confidence": 0.994}, {"text": "guide", "start": 232.46, "end": 232.72, "confidence": 0.987}, {"text": "that", "start": 232.72, "end": 232.96, "confidence": 0.997}, {"text": "specialization.", "start": 232.96, "end": 233.88, "confidence": 0.988}, {"text": "Could", "start": 233.88, "end": 234.22, "confidence": 0.95}, {"text": "we", "start": 234.22, "end": 234.34, "confidence": 0.994}, {"text": "unlock", "start": 234.34, "end": 234.68, "confidence": 0.983}, {"text": "even", "start": 234.68, "end": 234.9, "confidence": 0.968}, {"text": "greater", "start": 234.9, "end": 235.34, "confidence": 0.874}, {"text": "efficiency", "start": 235.34, "end": 235.92, "confidence": 0.735}, {"text": "and", "start": 235.92, "end": 236.08, "confidence": 0.983}, {"text": "accuracy?", "start": 236.08, "end": 236.62, "confidence": 0.783}, {"text": "This", "start": 236.76, "end": 236.78, "confidence": 0.468}, {"text": "is", "start": 236.78, "end": 236.8, "confidence": 0.963}, {"text": "what", "start": 236.8, "end": 236.82, "confidence": 0.577}, {"text": "I", "start": 236.82, "end": 236.84, "confidence": 0.283}, {"text": "call", "start": 236.84, "end": 236.86, "confidence": 0.213}, {"text": "the", "start": 236.86, "end": 236.88, "confidence": 0.341}, {"text": "trivia.", "start": 236.88, "end": 236.9, "confidence": 0.134}]}, {"id": 13, "seek": 23728, "start": 237.78, "end": 245.72, "text": " This is where I start to get a little mind-blown. We're talking about AI that not only understands language, but might be tapping into something fundamental about how it works.", "tokens": [50414, 639, 307, 689, 286, 722, 220, 1353, 483, 257, 707, 1575, 12, 5199, 648, 13, 492, 434, 220, 29302, 278, 466, 7318, 220, 6780, 406, 787, 833, 372, 2967, 2856, 11, 457, 1062, 312, 220, 1328, 3759, 666, 746, 8088, 466, 577, 309, 1985, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1768858457866468, "compression_ratio": 1.5186721991701244, "no_speech_prob": 0.7706932425498962, "confidence": 0.903, "words": [{"text": "This", "start": 237.78, "end": 237.8, "confidence": 0.34}, {"text": "is", "start": 237.8, "end": 237.82, "confidence": 0.986}, {"text": "where", "start": 237.82, "end": 237.84, "confidence": 0.992}, {"text": "I", "start": 237.84, "end": 237.86, "confidence": 0.919}, {"text": "start", "start": 237.86, "end": 237.88, "confidence": 0.867}, {"text": "to", "start": 237.88, "end": 237.9, "confidence": 0.99}, {"text": "get", "start": 237.9, "end": 237.92, "confidence": 0.984}, {"text": "a", "start": 237.92, "end": 238.04, "confidence": 0.931}, {"text": "little", "start": 238.04, "end": 238.06, "confidence": 0.733}, {"text": "mind-blown.", "start": 238.06, "end": 238.44, "confidence": 0.873}, {"text": "We're", "start": 238.64, "end": 238.9, "confidence": 0.987}, {"text": "talking", "start": 238.9, "end": 239.14, "confidence": 0.99}, {"text": "about", "start": 239.14, "end": 239.48, "confidence": 0.973}, {"text": "AI", "start": 239.48, "end": 239.66, "confidence": 0.791}, {"text": "that", "start": 239.66, "end": 240.3, "confidence": 0.99}, {"text": "not", "start": 240.3, "end": 240.52, "confidence": 0.974}, {"text": "only", "start": 240.52, "end": 240.66, "confidence": 0.991}, {"text": "understands", "start": 240.66, "end": 241.26, "confidence": 0.691}, {"text": "language,", "start": 241.26, "end": 241.68, "confidence": 0.862}, {"text": "but", "start": 242.6, "end": 242.62, "confidence": 0.981}, {"text": "might", "start": 242.62, "end": 243.12, "confidence": 0.939}, {"text": "be", "start": 243.12, "end": 243.24, "confidence": 0.978}, {"text": "tapping", "start": 243.24, "end": 243.56, "confidence": 0.98}, {"text": "into", "start": 243.56, "end": 243.78, "confidence": 0.932}, {"text": "something", "start": 243.78, "end": 244.2, "confidence": 0.949}, {"text": "fundamental", "start": 244.2, "end": 244.8, "confidence": 0.965}, {"text": "about", "start": 244.8, "end": 244.98, "confidence": 0.977}, {"text": "how", "start": 244.98, "end": 245.14, "confidence": 0.991}, {"text": "it", "start": 245.14, "end": 245.34, "confidence": 0.989}, {"text": "works.", "start": 245.34, "end": 245.72, "confidence": 0.985}]}, {"id": 14, "seek": 23728, "start": 246.88, "end": 257.84, "text": " We are. And the implications are huge. Imagine AI that can seamlessly translate between any language. Or even help us decipher ancient texts by recognizing these deep linguistic structures.", "tokens": [50864, 492, 366, 13, 400, 220, 3322, 8484, 299, 763, 366, 2603, 13, 11739, 7318, 220, 6780, 393, 38083, 220, 24999, 17593, 1296, 604, 2856, 13, 1610, 754, 854, 505, 49859, 7832, 220, 25111, 82, 538, 18538, 220, 42678, 2452, 22949, 84, 3142, 342, 44513, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1768858457866468, "compression_ratio": 1.5186721991701244, "no_speech_prob": 0.7706932425498962, "confidence": 0.877, "words": [{"text": "We", "start": 246.88, "end": 246.9, "confidence": 0.981}, {"text": "are.", "start": 246.9, "end": 246.92, "confidence": 0.994}, {"text": "And", "start": 247.02, "end": 247.16, "confidence": 0.987}, {"text": "the", "start": 247.16, "end": 247.3, "confidence": 0.999}, {"text": "implications", "start": 247.3, "end": 247.82, "confidence": 0.627}, {"text": "are", "start": 247.82, "end": 248.02, "confidence": 0.99}, {"text": "huge.", "start": 248.02, "end": 248.8, "confidence": 0.931}, {"text": "Imagine", "start": 249.02, "end": 249.42, "confidence": 0.962}, {"text": "AI", "start": 249.42, "end": 249.88, "confidence": 0.985}, {"text": "that", "start": 249.88, "end": 250.0, "confidence": 0.996}, {"text": "can", "start": 250.0, "end": 250.1, "confidence": 0.986}, {"text": "seamlessly", "start": 250.1, "end": 250.54, "confidence": 0.619}, {"text": "translate", "start": 250.54, "end": 251.16, "confidence": 0.991}, {"text": "between", "start": 251.16, "end": 251.38, "confidence": 0.935}, {"text": "any", "start": 251.38, "end": 251.66, "confidence": 0.96}, {"text": "language.", "start": 251.66, "end": 252.06, "confidence": 0.867}, {"text": "Or", "start": 252.72, "end": 252.74, "confidence": 0.991}, {"text": "even", "start": 252.74, "end": 253.0, "confidence": 0.956}, {"text": "help", "start": 253.0, "end": 253.28, "confidence": 0.973}, {"text": "us", "start": 253.28, "end": 253.32, "confidence": 0.982}, {"text": "decipher", "start": 253.32, "end": 253.72, "confidence": 0.968}, {"text": "ancient", "start": 253.72, "end": 254.1, "confidence": 0.939}, {"text": "texts", "start": 254.1, "end": 255.26, "confidence": 0.877}, {"text": "by", "start": 255.26, "end": 255.54, "confidence": 0.747}, {"text": "recognizing", "start": 255.54, "end": 256.12, "confidence": 0.959}, {"text": "these", "start": 256.12, "end": 256.4, "confidence": 0.97}, {"text": "deep", "start": 256.4, "end": 256.66, "confidence": 0.976}, {"text": "linguistic", "start": 256.66, "end": 257.2, "confidence": 0.63}, {"text": "structures.", "start": 257.2, "end": 257.84, "confidence": 0.733}]}, {"id": 15, "seek": 26728, "start": 267.78, "end": 285.48, "text": " Could these models, with their focus on specific types of information, inadvertently amplify existing societal biases? It's an important point and something that needs careful consideration. As we develop these powerful tools, we have a responsibility to make sure they are used ethically and responsibly.", "tokens": [50414, 7497, 220, 42678, 5245, 11, 365, 220, 3322, 347, 1879, 322, 637, 3045, 1089, 220, 874, 5190, 295, 1589, 11, 49152, 2276, 669, 564, 2505, 6741, 33472, 272, 654, 6196, 30, 467, 311, 364, 1021, 935, 293, 746, 220, 6780, 2203, 5026, 12381, 13, 1018, 321, 1905, 338, 404, 220, 42678, 4005, 220, 83, 29298, 11, 321, 362, 257, 6357, 220, 1353, 652, 988, 220, 13162, 366, 1143, 6468, 984, 293, 2914, 3545, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12816647120884486, "compression_ratio": 1.4950980392156863, "no_speech_prob": 0.833673357963562, "confidence": 0.89, "words": [{"text": "Could", "start": 267.78, "end": 267.8, "confidence": 0.77}, {"text": "these", "start": 267.8, "end": 267.82, "confidence": 0.953}, {"text": "models,", "start": 267.82, "end": 268.6, "confidence": 0.924}, {"text": "with", "start": 269.48, "end": 269.5, "confidence": 0.993}, {"text": "their", "start": 269.5, "end": 269.68, "confidence": 0.993}, {"text": "focus", "start": 269.68, "end": 270.08, "confidence": 0.878}, {"text": "on", "start": 270.08, "end": 270.52, "confidence": 0.991}, {"text": "specific", "start": 270.52, "end": 271.28, "confidence": 0.869}, {"text": "types", "start": 271.28, "end": 271.38, "confidence": 0.979}, {"text": "of", "start": 271.38, "end": 271.48, "confidence": 0.992}, {"text": "information,", "start": 271.48, "end": 272.12, "confidence": 0.857}, {"text": "inadvertently", "start": 273.06, "end": 273.56, "confidence": 0.965}, {"text": "amplify", "start": 273.56, "end": 274.28, "confidence": 0.805}, {"text": "existing", "start": 274.28, "end": 274.76, "confidence": 0.913}, {"text": "societal", "start": 274.76, "end": 275.34, "confidence": 0.945}, {"text": "biases?", "start": 275.34, "end": 275.92, "confidence": 0.861}, {"text": "It's", "start": 275.92, "end": 276.38, "confidence": 0.77}, {"text": "an", "start": 276.38, "end": 276.46, "confidence": 0.97}, {"text": "important", "start": 276.46, "end": 276.8, "confidence": 0.957}, {"text": "point", "start": 276.8, "end": 277.4, "confidence": 0.979}, {"text": "and", "start": 277.4, "end": 277.42, "confidence": 0.354}, {"text": "something", "start": 277.42, "end": 277.7, "confidence": 0.943}, {"text": "that", "start": 277.7, "end": 277.9, "confidence": 0.994}, {"text": "needs", "start": 277.9, "end": 278.02, "confidence": 0.976}, {"text": "careful", "start": 278.02, "end": 278.36, "confidence": 0.994}, {"text": "consideration.", "start": 278.36, "end": 279.02, "confidence": 0.972}, {"text": "As", "start": 279.52, "end": 279.76, "confidence": 0.947}, {"text": "we", "start": 279.76, "end": 279.94, "confidence": 0.988}, {"text": "develop", "start": 279.94, "end": 280.38, "confidence": 0.779}, {"text": "these", "start": 280.38, "end": 280.5, "confidence": 0.959}, {"text": "powerful", "start": 280.5, "end": 280.92, "confidence": 0.962}, {"text": "tools,", "start": 280.92, "end": 281.24, "confidence": 0.784}, {"text": "we", "start": 281.48, "end": 281.5, "confidence": 0.989}, {"text": "have", "start": 281.5, "end": 281.66, "confidence": 0.975}, {"text": "a", "start": 281.66, "end": 281.8, "confidence": 0.987}, {"text": "responsibility", "start": 281.8, "end": 282.42, "confidence": 0.985}, {"text": "to", "start": 282.42, "end": 282.74, "confidence": 0.998}, {"text": "make", "start": 282.74, "end": 283.7, "confidence": 0.319}, {"text": "sure", "start": 283.7, "end": 283.72, "confidence": 0.968}, {"text": "they", "start": 283.72, "end": 283.74, "confidence": 0.979}, {"text": "are", "start": 283.74, "end": 283.76, "confidence": 0.761}, {"text": "used", "start": 283.76, "end": 283.78, "confidence": 0.964}, {"text": "ethically", "start": 283.78, "end": 284.26, "confidence": 0.931}, {"text": "and", "start": 284.26, "end": 284.68, "confidence": 0.949}, {"text": "responsibly.", "start": 284.68, "end": 285.48, "confidence": 0.96}]}, {"id": 16, "seek": 29728, "start": 297.8, "end": 307.46, "text": " One of the first things researchers had to figure out was how many experts should a model have? It seems intuitive that more experts would mean better performance. But that's not always the case.", "tokens": [50414, 1485, 295, 220, 3322, 700, 220, 825, 82, 10309, 632, 220, 1353, 2573, 484, 390, 577, 867, 8572, 820, 257, 2316, 362, 30, 467, 2544, 21769, 220, 6780, 544, 8572, 576, 914, 1101, 3389, 13, 583, 220, 6780, 311, 406, 1009, 220, 3322, 1389, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19257227579752603, "compression_ratio": 1.3732394366197183, "no_speech_prob": 0.8224157691001892, "confidence": 0.858, "words": [{"text": "One", "start": 297.8, "end": 299.24, "confidence": 0.128}, {"text": "of", "start": 299.24, "end": 299.4, "confidence": 0.934}, {"text": "the", "start": 299.4, "end": 299.6, "confidence": 0.997}, {"text": "first", "start": 299.6, "end": 299.84, "confidence": 0.896}, {"text": "things", "start": 299.84, "end": 300.04, "confidence": 0.979}, {"text": "researchers", "start": 300.04, "end": 300.36, "confidence": 0.918}, {"text": "had", "start": 300.36, "end": 300.52, "confidence": 0.956}, {"text": "to", "start": 300.52, "end": 300.6, "confidence": 0.998}, {"text": "figure", "start": 300.6, "end": 300.82, "confidence": 0.985}, {"text": "out", "start": 300.82, "end": 300.98, "confidence": 0.985}, {"text": "was", "start": 300.98, "end": 301.06, "confidence": 0.87}, {"text": "how", "start": 301.06, "end": 301.3, "confidence": 0.581}, {"text": "many", "start": 301.3, "end": 301.64, "confidence": 0.992}, {"text": "experts", "start": 301.64, "end": 302.2, "confidence": 0.834}, {"text": "should", "start": 302.2, "end": 302.34, "confidence": 0.827}, {"text": "a", "start": 302.34, "end": 302.58, "confidence": 0.914}, {"text": "model", "start": 302.58, "end": 302.72, "confidence": 0.599}, {"text": "have?", "start": 302.72, "end": 302.82, "confidence": 0.977}, {"text": "It", "start": 302.92, "end": 303.0, "confidence": 0.784}, {"text": "seems", "start": 303.0, "end": 303.3, "confidence": 0.817}, {"text": "intuitive", "start": 303.3, "end": 303.92, "confidence": 0.872}, {"text": "that", "start": 303.92, "end": 304.1, "confidence": 0.962}, {"text": "more", "start": 304.1, "end": 304.28, "confidence": 0.952}, {"text": "experts", "start": 304.28, "end": 304.72, "confidence": 0.639}, {"text": "would", "start": 304.72, "end": 304.8, "confidence": 0.942}, {"text": "mean", "start": 304.8, "end": 305.02, "confidence": 0.962}, {"text": "better", "start": 305.02, "end": 305.32, "confidence": 0.981}, {"text": "performance.", "start": 305.32, "end": 305.9, "confidence": 0.946}, {"text": "But", "start": 306.38, "end": 306.46, "confidence": 0.481}, {"text": "that's", "start": 306.46, "end": 306.58, "confidence": 0.961}, {"text": "not", "start": 306.58, "end": 306.78, "confidence": 0.97}, {"text": "always", "start": 306.78, "end": 306.98, "confidence": 0.956}, {"text": "the", "start": 306.98, "end": 307.1, "confidence": 0.999}, {"text": "case.", "start": 307.1, "end": 307.46, "confidence": 0.97}]}, {"id": 17, "seek": 32728, "start": 328.58, "end": 335.76, "text": " It's like having a team with all the best specialists, but their workspace is too small for them to actually collaborate effectively.", "tokens": [50414, 467, 311, 411, 1419, 257, 220, 975, 335, 365, 439, 220, 3322, 1151, 637, 68, 1013, 1751, 11, 457, 220, 3322, 347, 589, 24824, 307, 220, 32599, 1359, 337, 220, 47959, 220, 1353, 767, 18338, 1244, 22909, 356, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22546620117990593, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.5938809514045715, "confidence": 0.86, "words": [{"text": "It's", "start": 328.58, "end": 329.42, "confidence": 0.901}, {"text": "like", "start": 329.42, "end": 329.58, "confidence": 0.98}, {"text": "having", "start": 329.58, "end": 329.84, "confidence": 0.931}, {"text": "a", "start": 329.84, "end": 329.98, "confidence": 0.99}, {"text": "team", "start": 329.98, "end": 330.28, "confidence": 0.982}, {"text": "with", "start": 330.28, "end": 330.44, "confidence": 0.989}, {"text": "all", "start": 330.44, "end": 330.62, "confidence": 0.967}, {"text": "the", "start": 330.62, "end": 330.68, "confidence": 0.99}, {"text": "best", "start": 330.68, "end": 330.96, "confidence": 0.978}, {"text": "specialists,", "start": 330.96, "end": 332.22, "confidence": 0.709}, {"text": "but", "start": 332.26, "end": 332.8, "confidence": 0.984}, {"text": "their", "start": 332.8, "end": 333.0, "confidence": 0.994}, {"text": "workspace", "start": 333.0, "end": 333.48, "confidence": 0.523}, {"text": "is", "start": 333.48, "end": 333.66, "confidence": 0.982}, {"text": "too", "start": 333.66, "end": 333.76, "confidence": 0.987}, {"text": "small", "start": 333.76, "end": 334.22, "confidence": 0.896}, {"text": "for", "start": 334.22, "end": 334.36, "confidence": 0.987}, {"text": "them", "start": 334.36, "end": 334.5, "confidence": 0.98}, {"text": "to", "start": 334.5, "end": 334.72, "confidence": 0.996}, {"text": "actually", "start": 334.72, "end": 335.0, "confidence": 0.908}, {"text": "collaborate", "start": 335.0, "end": 335.54, "confidence": 0.329}, {"text": "effectively.", "start": 335.54, "end": 335.76, "confidence": 0.714}]}, {"id": 18, "seek": 32728, "start": 336.88, "end": 343.78, "text": " Another key design element is something called the capacity factor, which basically determines how much information each expert can handle at once.", "tokens": [50814, 3996, 2141, 1715, 4478, 307, 746, 1219, 220, 3322, 1410, 19008, 5952, 11, 597, 1936, 1141, 966, 1652, 577, 709, 1589, 1184, 5844, 393, 4813, 412, 1564, 13, 51164], "temperature": 0.0, "avg_logprob": -0.22546620117990593, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.5938809514045715, "confidence": 0.916, "words": [{"text": "Another", "start": 336.88, "end": 337.14, "confidence": 0.934}, {"text": "key", "start": 337.14, "end": 337.5, "confidence": 0.895}, {"text": "design", "start": 337.5, "end": 338.08, "confidence": 0.979}, {"text": "element", "start": 338.08, "end": 338.28, "confidence": 0.988}, {"text": "is", "start": 338.28, "end": 338.48, "confidence": 0.977}, {"text": "something", "start": 338.48, "end": 338.66, "confidence": 0.915}, {"text": "called", "start": 338.66, "end": 338.9, "confidence": 0.948}, {"text": "the", "start": 338.9, "end": 339.18, "confidence": 0.996}, {"text": "capacity", "start": 339.18, "end": 339.58, "confidence": 0.788}, {"text": "factor,", "start": 339.58, "end": 340.02, "confidence": 0.832}, {"text": "which", "start": 340.34, "end": 340.38, "confidence": 0.99}, {"text": "basically", "start": 340.38, "end": 340.82, "confidence": 0.981}, {"text": "determines", "start": 340.82, "end": 341.38, "confidence": 0.762}, {"text": "how", "start": 341.38, "end": 341.58, "confidence": 0.989}, {"text": "much", "start": 341.58, "end": 341.84, "confidence": 0.991}, {"text": "information", "start": 341.84, "end": 342.46, "confidence": 0.872}, {"text": "each", "start": 342.46, "end": 342.78, "confidence": 0.986}, {"text": "expert", "start": 342.78, "end": 343.2, "confidence": 0.849}, {"text": "can", "start": 343.2, "end": 343.36, "confidence": 0.985}, {"text": "handle", "start": 343.36, "end": 343.7, "confidence": 0.985}, {"text": "at", "start": 343.7, "end": 343.76, "confidence": 0.986}, {"text": "once.", "start": 343.76, "end": 343.78, "confidence": 0.99}]}, {"id": 19, "seek": 32728, "start": 344.6, "end": 356.9, "text": " OK, so it's like setting the size of each expert's desk, so to speak. Too small, and they're overwhelmed. Too big, and you're wasting space. A perfect analogy. And then there's the routing algorithm. This is the AI traffic cop that's been working on the AI.", "tokens": [51214, 2264, 11, 370, 309, 311, 411, 3287, 220, 3322, 2744, 295, 1184, 5844, 311, 10026, 11, 370, 220, 1353, 1710, 13, 11395, 1359, 11, 293, 220, 13162, 434, 19042, 13, 11395, 955, 11, 293, 291, 434, 20457, 1901, 13, 316, 2176, 16660, 88, 13, 400, 220, 19096, 220, 15456, 311, 220, 3322, 367, 24500, 3501, 284, 355, 76, 13, 639, 307, 220, 3322, 7318, 220, 17227, 3341, 2971, 220, 6780, 311, 668, 1364, 322, 220, 3322, 7318, 13, 51814], "temperature": 0.0, "avg_logprob": -0.22546620117990593, "compression_ratio": 1.679127725856698, "no_speech_prob": 0.5938809514045715, "confidence": 0.75, "words": [{"text": "OK,", "start": 344.6, "end": 344.74, "confidence": 0.498}, {"text": "so", "start": 344.84, "end": 344.96, "confidence": 0.937}, {"text": "it's", "start": 344.96, "end": 345.1, "confidence": 0.988}, {"text": "like", "start": 345.1, "end": 345.42, "confidence": 0.981}, {"text": "setting", "start": 345.42, "end": 345.76, "confidence": 0.972}, {"text": "the", "start": 345.76, "end": 345.88, "confidence": 0.999}, {"text": "size", "start": 345.88, "end": 346.14, "confidence": 0.962}, {"text": "of", "start": 346.14, "end": 346.32, "confidence": 0.995}, {"text": "each", "start": 346.32, "end": 346.68, "confidence": 0.988}, {"text": "expert's", "start": 346.68, "end": 347.16, "confidence": 0.723}, {"text": "desk,", "start": 347.16, "end": 347.54, "confidence": 0.977}, {"text": "so", "start": 347.78, "end": 347.8, "confidence": 0.96}, {"text": "to", "start": 347.8, "end": 347.98, "confidence": 0.998}, {"text": "speak.", "start": 347.98, "end": 348.1, "confidence": 0.996}, {"text": "Too", "start": 348.22, "end": 348.9, "confidence": 0.882}, {"text": "small,", "start": 348.9, "end": 349.32, "confidence": 0.902}, {"text": "and", "start": 349.68, "end": 349.7, "confidence": 0.976}, {"text": "they're", "start": 349.7, "end": 349.92, "confidence": 0.985}, {"text": "overwhelmed.", "start": 349.92, "end": 350.42, "confidence": 0.856}, {"text": "Too", "start": 350.44, "end": 350.94, "confidence": 0.898}, {"text": "big,", "start": 350.94, "end": 351.3, "confidence": 0.987}, {"text": "and", "start": 351.3, "end": 351.32, "confidence": 0.984}, {"text": "you're", "start": 351.32, "end": 351.5, "confidence": 0.987}, {"text": "wasting", "start": 351.5, "end": 351.96, "confidence": 0.989}, {"text": "space.", "start": 351.96, "end": 352.36, "confidence": 0.974}, {"text": "A", "start": 352.5, "end": 352.62, "confidence": 0.686}, {"text": "perfect", "start": 352.62, "end": 353.02, "confidence": 0.98}, {"text": "analogy.", "start": 353.02, "end": 353.5, "confidence": 0.66}, {"text": "And", "start": 353.52, "end": 353.72, "confidence": 0.629}, {"text": "then", "start": 353.72, "end": 353.88, "confidence": 0.99}, {"text": "there's", "start": 353.88, "end": 354.04, "confidence": 0.978}, {"text": "the", "start": 354.04, "end": 354.16, "confidence": 0.995}, {"text": "routing", "start": 354.16, "end": 354.56, "confidence": 0.72}, {"text": "algorithm.", "start": 354.56, "end": 355.26, "confidence": 0.694}, {"text": "This", "start": 355.82, "end": 355.84, "confidence": 0.625}, {"text": "is", "start": 355.84, "end": 355.98, "confidence": 0.98}, {"text": "the", "start": 355.98, "end": 356.12, "confidence": 0.992}, {"text": "AI", "start": 356.12, "end": 356.6, "confidence": 0.943}, {"text": "traffic", "start": 356.6, "end": 356.76, "confidence": 0.785}, {"text": "cop", "start": 356.76, "end": 356.78, "confidence": 0.973}, {"text": "that's", "start": 356.78, "end": 356.8, "confidence": 0.444}, {"text": "been", "start": 356.8, "end": 356.82, "confidence": 0.078}, {"text": "working", "start": 356.82, "end": 356.84, "confidence": 0.13}, {"text": "on", "start": 356.84, "end": 356.86, "confidence": 0.623}, {"text": "the", "start": 356.86, "end": 356.88, "confidence": 0.368}, {"text": "AI.", "start": 356.88, "end": 356.9, "confidence": 0.075}]}, {"id": 20, "seek": 35728, "start": 357.78, "end": 367.1, "text": " It's a system that decides which expert gets which piece of information. The research looked at several different routing strategies, and one that seems to work particularly well is called top two routing.", "tokens": [50414, 467, 311, 257, 1185, 220, 6780, 14898, 597, 5844, 2170, 597, 2522, 295, 1589, 13, 440, 2132, 2956, 412, 2940, 819, 32722, 5464, 414, 82, 11, 293, 472, 220, 6780, 2544, 220, 1353, 589, 644, 299, 425, 289, 356, 731, 307, 1219, 220, 19337, 220, 20534, 32722, 13, 50864], "temperature": 0.0, "avg_logprob": -0.16954203417701444, "compression_ratio": 1.684887459807074, "no_speech_prob": 0.14520250260829926, "confidence": 0.757, "words": [{"text": "It's", "start": 357.78, "end": 357.8, "confidence": 0.492}, {"text": "a", "start": 357.8, "end": 357.82, "confidence": 0.446}, {"text": "system", "start": 357.82, "end": 357.84, "confidence": 0.048}, {"text": "that", "start": 357.84, "end": 357.86, "confidence": 0.775}, {"text": "decides", "start": 357.86, "end": 357.88, "confidence": 0.827}, {"text": "which", "start": 357.88, "end": 358.04, "confidence": 0.956}, {"text": "expert", "start": 358.04, "end": 358.6, "confidence": 0.781}, {"text": "gets", "start": 358.6, "end": 358.8, "confidence": 0.927}, {"text": "which", "start": 358.8, "end": 359.16, "confidence": 0.97}, {"text": "piece", "start": 359.16, "end": 359.52, "confidence": 0.977}, {"text": "of", "start": 359.52, "end": 359.54, "confidence": 0.995}, {"text": "information.", "start": 359.54, "end": 360.28, "confidence": 0.874}, {"text": "The", "start": 360.94, "end": 360.96, "confidence": 0.947}, {"text": "research", "start": 360.96, "end": 361.38, "confidence": 0.986}, {"text": "looked", "start": 361.38, "end": 361.64, "confidence": 0.865}, {"text": "at", "start": 361.64, "end": 361.74, "confidence": 0.994}, {"text": "several", "start": 361.74, "end": 362.06, "confidence": 0.861}, {"text": "different", "start": 362.06, "end": 362.42, "confidence": 0.962}, {"text": "routing", "start": 362.42, "end": 362.78, "confidence": 0.661}, {"text": "strategies,", "start": 362.78, "end": 363.54, "confidence": 0.712}, {"text": "and", "start": 363.7, "end": 363.8, "confidence": 0.983}, {"text": "one", "start": 363.8, "end": 364.0, "confidence": 0.978}, {"text": "that", "start": 364.0, "end": 364.12, "confidence": 0.972}, {"text": "seems", "start": 364.12, "end": 364.36, "confidence": 0.784}, {"text": "to", "start": 364.36, "end": 364.5, "confidence": 0.995}, {"text": "work", "start": 364.5, "end": 364.68, "confidence": 0.989}, {"text": "particularly", "start": 364.68, "end": 365.36, "confidence": 0.676}, {"text": "well", "start": 365.36, "end": 365.56, "confidence": 0.993}, {"text": "is", "start": 365.56, "end": 365.82, "confidence": 0.897}, {"text": "called", "start": 365.82, "end": 366.06, "confidence": 0.95}, {"text": "top", "start": 366.06, "end": 366.38, "confidence": 0.858}, {"text": "two", "start": 366.38, "end": 366.72, "confidence": 0.737}, {"text": "routing.", "start": 366.72, "end": 367.1, "confidence": 0.481}]}, {"id": 21, "seek": 35728, "start": 367.78, "end": 386.76, "text": " So instead of sending a word to just one expert, it actually goes to the two that are most likely to understand it. Exactly. It's like having a backup plan, just in case that first expert isn't quite the right fit. The research also introduces this new routing technique. It's called batch prioritized routing, or BPR.", "tokens": [50914, 407, 2602, 295, 7750, 257, 1349, 220, 1353, 445, 472, 5844, 11, 309, 767, 1709, 220, 1353, 220, 3322, 220, 20534, 220, 6780, 366, 881, 3700, 220, 1353, 1223, 309, 13, 7587, 13, 467, 311, 411, 1419, 257, 14807, 1393, 11, 445, 294, 1389, 220, 6780, 700, 5844, 1943, 380, 1596, 220, 3322, 558, 3318, 13, 440, 2132, 611, 560, 11452, 84, 887, 220, 11176, 777, 32722, 220, 29113, 1925, 13, 467, 311, 1219, 15245, 14846, 1602, 367, 24500, 11, 420, 363, 15958, 13, 51814], "temperature": 0.0, "avg_logprob": -0.16954203417701444, "compression_ratio": 1.684887459807074, "no_speech_prob": 0.14520250260829926, "confidence": 0.915, "words": [{"text": "So", "start": 367.78, "end": 367.8, "confidence": 0.969}, {"text": "instead", "start": 367.8, "end": 367.86, "confidence": 0.942}, {"text": "of", "start": 367.86, "end": 368.16, "confidence": 0.985}, {"text": "sending", "start": 368.16, "end": 368.18, "confidence": 0.958}, {"text": "a", "start": 368.18, "end": 368.4, "confidence": 0.989}, {"text": "word", "start": 368.4, "end": 368.58, "confidence": 0.994}, {"text": "to", "start": 368.58, "end": 368.68, "confidence": 0.997}, {"text": "just", "start": 368.68, "end": 368.86, "confidence": 0.981}, {"text": "one", "start": 368.86, "end": 369.3, "confidence": 0.982}, {"text": "expert,", "start": 369.3, "end": 370.28, "confidence": 0.708}, {"text": "it", "start": 370.72, "end": 370.74, "confidence": 0.982}, {"text": "actually", "start": 370.74, "end": 371.02, "confidence": 0.963}, {"text": "goes", "start": 371.02, "end": 371.34, "confidence": 0.964}, {"text": "to", "start": 371.34, "end": 371.42, "confidence": 0.998}, {"text": "the", "start": 371.42, "end": 371.54, "confidence": 0.998}, {"text": "two", "start": 371.54, "end": 371.76, "confidence": 0.991}, {"text": "that", "start": 371.76, "end": 371.92, "confidence": 0.885}, {"text": "are", "start": 371.92, "end": 372.0, "confidence": 0.982}, {"text": "most", "start": 372.0, "end": 372.22, "confidence": 0.952}, {"text": "likely", "start": 372.22, "end": 372.44, "confidence": 0.893}, {"text": "to", "start": 372.44, "end": 372.56, "confidence": 0.994}, {"text": "understand", "start": 372.56, "end": 372.98, "confidence": 0.921}, {"text": "it.", "start": 372.98, "end": 373.3, "confidence": 0.975}, {"text": "Exactly.", "start": 373.3, "end": 373.8, "confidence": 0.745}, {"text": "It's", "start": 374.08, "end": 374.14, "confidence": 0.987}, {"text": "like", "start": 374.14, "end": 374.3, "confidence": 0.985}, {"text": "having", "start": 374.3, "end": 374.5, "confidence": 0.921}, {"text": "a", "start": 374.5, "end": 374.64, "confidence": 0.996}, {"text": "backup", "start": 374.64, "end": 375.06, "confidence": 0.959}, {"text": "plan,", "start": 375.06, "end": 375.92, "confidence": 0.991}, {"text": "just", "start": 375.94, "end": 376.22, "confidence": 0.983}, {"text": "in", "start": 376.22, "end": 376.4, "confidence": 0.986}, {"text": "case", "start": 376.4, "end": 376.56, "confidence": 0.962}, {"text": "that", "start": 376.56, "end": 376.82, "confidence": 0.959}, {"text": "first", "start": 376.82, "end": 377.16, "confidence": 0.936}, {"text": "expert", "start": 377.16, "end": 377.66, "confidence": 0.855}, {"text": "isn't", "start": 377.66, "end": 378.06, "confidence": 0.989}, {"text": "quite", "start": 378.06, "end": 378.3, "confidence": 0.969}, {"text": "the", "start": 378.3, "end": 378.38, "confidence": 0.998}, {"text": "right", "start": 378.38, "end": 378.68, "confidence": 0.984}, {"text": "fit.", "start": 378.68, "end": 379.24, "confidence": 0.965}, {"text": "The", "start": 379.28, "end": 379.82, "confidence": 0.59}, {"text": "research", "start": 379.82, "end": 380.22, "confidence": 0.987}, {"text": "also", "start": 380.22, "end": 380.48, "confidence": 0.951}, {"text": "introduces", "start": 380.48, "end": 381.04, "confidence": 0.644}, {"text": "this", "start": 381.04, "end": 381.34, "confidence": 0.979}, {"text": "new", "start": 381.34, "end": 381.68, "confidence": 0.95}, {"text": "routing", "start": 381.68, "end": 382.06, "confidence": 0.508}, {"text": "technique.", "start": 382.06, "end": 382.8, "confidence": 0.956}, {"text": "It's", "start": 383.1, "end": 383.3, "confidence": 0.948}, {"text": "called", "start": 383.3, "end": 383.52, "confidence": 0.963}, {"text": "batch", "start": 383.52, "end": 384.1, "confidence": 0.977}, {"text": "prioritized", "start": 384.1, "end": 384.96, "confidence": 0.822}, {"text": "routing,", "start": 384.96, "end": 385.36, "confidence": 0.728}, {"text": "or", "start": 385.96, "end": 386.06, "confidence": 0.935}, {"text": "BPR.", "start": 386.06, "end": 386.76, "confidence": 0.982}]}, {"id": 22, "seek": 38728, "start": 387.78, "end": 418.24, "text": " Which seems especially helpful when you're working with limited capacity. BPR. Is that like a Priority Mail system for the AI, making sure the most important information gets delivered first, even during rush hour? You got it. BPR allows the model to make the smarter routing decisions by looking at all the words together instead of processing them one by one. OK, this is all starting to make sense. But let's get down to brass tacks here. How do these STMOE models actually perform in the real world? Did they put them through their paces? They did. The researchers tested them in the lab. They found that they were much faster in processing words than in the real world. And they found that they were much faster in processing words than in the real world. So they're not just better at routing. They're much faster at processing words. And", "tokens": [50414, 3013, 2544, 2318, 4961, 562, 291, 434, 1364, 365, 5567, 1410, 19008, 13, 363, 15958, 13, 1119, 220, 6780, 411, 257, 24032, 507, 29164, 1185, 337, 220, 3322, 7318, 11, 1455, 988, 220, 3322, 881, 1021, 1589, 2170, 1103, 592, 323, 67, 700, 11, 754, 1830, 9300, 1773, 30, 509, 658, 309, 13, 363, 15958, 4045, 220, 3322, 2316, 220, 1353, 652, 220, 3322, 4069, 260, 32722, 5327, 538, 1237, 412, 439, 220, 3322, 2283, 220, 83, 9622, 2602, 295, 9007, 220, 47959, 472, 538, 472, 13, 2264, 11, 220, 11176, 307, 439, 2891, 220, 1353, 652, 2020, 13, 583, 718, 311, 483, 760, 220, 1353, 26257, 220, 83, 7424, 510, 13, 1012, 360, 220, 42678, 4904, 18976, 36, 5245, 767, 2042, 294, 220, 3322, 957, 1002, 30, 2589, 220, 13162, 829, 220, 47959, 220, 11529, 220, 3322, 347, 280, 2116, 30, 814, 630, 13, 440, 10309, 220, 83, 21885, 220, 47959, 294, 220, 3322, 2715, 13, 814, 1352, 220, 6780, 220, 3322, 88, 645, 709, 4663, 294, 9007, 2283, 220, 24852, 294, 220, 3322, 957, 1002, 13, 400, 220, 13162, 1352, 220, 6780, 220, 3322, 88, 645, 709, 4663, 294, 9007, 2283, 220, 24852, 294, 220, 3322, 957, 1002, 13, 407, 220, 13162, 434, 406, 445, 1101, 412, 367, 24500, 13, 814, 434, 709, 4663, 412, 9007, 2283, 13, 400], "temperature": 0.0, "avg_logprob": -0.41570637792749787, "compression_ratio": 1.931350114416476, "no_speech_prob": 0.10056159645318985, "confidence": 0.649, "words": [{"text": "Which", "start": 387.78, "end": 387.82, "confidence": 0.937}, {"text": "seems", "start": 387.82, "end": 388.12, "confidence": 0.909}, {"text": "especially", "start": 388.12, "end": 388.82, "confidence": 0.988}, {"text": "helpful", "start": 388.82, "end": 389.18, "confidence": 0.585}, {"text": "when", "start": 389.18, "end": 389.44, "confidence": 0.992}, {"text": "you're", "start": 389.44, "end": 389.66, "confidence": 0.99}, {"text": "working", "start": 389.66, "end": 389.9, "confidence": 0.997}, {"text": "with", "start": 389.9, "end": 390.0, "confidence": 0.995}, {"text": "limited", "start": 390.0, "end": 391.04, "confidence": 0.978}, {"text": "capacity.", "start": 391.04, "end": 391.08, "confidence": 0.82}, {"text": "BPR.", "start": 391.14, "end": 391.76, "confidence": 0.781}, {"text": "Is", "start": 391.96, "end": 392.56, "confidence": 0.968}, {"text": "that", "start": 392.56, "end": 392.64, "confidence": 0.979}, {"text": "like", "start": 392.64, "end": 392.82, "confidence": 0.971}, {"text": "a", "start": 392.82, "end": 392.88, "confidence": 0.997}, {"text": "Priority", "start": 392.88, "end": 393.6, "confidence": 0.727}, {"text": "Mail", "start": 393.6, "end": 393.62, "confidence": 0.93}, {"text": "system", "start": 393.62, "end": 393.96, "confidence": 0.838}, {"text": "for", "start": 393.96, "end": 394.18, "confidence": 0.99}, {"text": "the", "start": 394.18, "end": 394.26, "confidence": 0.992}, {"text": "AI,", "start": 394.26, "end": 394.66, "confidence": 0.985}, {"text": "making", "start": 394.78, "end": 395.36, "confidence": 0.973}, {"text": "sure", "start": 395.36, "end": 395.66, "confidence": 0.979}, {"text": "the", "start": 395.66, "end": 395.72, "confidence": 0.993}, {"text": "most", "start": 395.72, "end": 396.3, "confidence": 0.941}, {"text": "important", "start": 396.3, "end": 396.32, "confidence": 0.961}, {"text": "information", "start": 396.32, "end": 396.82, "confidence": 0.842}, {"text": "gets", "start": 396.82, "end": 396.96, "confidence": 0.95}, {"text": "delivered", "start": 396.96, "end": 397.48, "confidence": 0.729}, {"text": "first,", "start": 397.48, "end": 398.06, "confidence": 0.96}, {"text": "even", "start": 398.28, "end": 398.54, "confidence": 0.974}, {"text": "during", "start": 398.54, "end": 398.76, "confidence": 0.906}, {"text": "rush", "start": 398.76, "end": 399.04, "confidence": 0.982}, {"text": "hour?", "start": 399.04, "end": 399.24, "confidence": 0.974}, {"text": "You", "start": 399.24, "end": 399.5, "confidence": 0.872}, {"text": "got", "start": 399.5, "end": 399.76, "confidence": 0.964}, {"text": "it.", "start": 399.76, "end": 400.0, "confidence": 0.983}, {"text": "BPR", "start": 400.18, "end": 400.52, "confidence": 0.938}, {"text": "allows", "start": 400.52, "end": 401.0, "confidence": 0.915}, {"text": "the", "start": 401.0, "end": 401.2, "confidence": 0.998}, {"text": "model", "start": 401.2, "end": 401.44, "confidence": 0.627}, {"text": "to", "start": 401.44, "end": 401.62, "confidence": 0.997}, {"text": "make", "start": 401.62, "end": 401.88, "confidence": 0.99}, {"text": "the", "start": 401.88, "end": 401.98, "confidence": 0.948}, {"text": "smarter", "start": 401.98, "end": 402.5, "confidence": 0.784}, {"text": "routing", "start": 402.5, "end": 402.82, "confidence": 0.502}, {"text": "decisions", "start": 402.82, "end": 403.44, "confidence": 0.954}, {"text": "by", "start": 403.44, "end": 403.78, "confidence": 0.971}, {"text": "looking", "start": 403.78, "end": 403.96, "confidence": 0.951}, {"text": "at", "start": 403.96, "end": 404.14, "confidence": 0.989}, {"text": "all", "start": 404.14, "end": 404.34, "confidence": 0.981}, {"text": "the", "start": 404.34, "end": 404.42, "confidence": 0.994}, {"text": "words", "start": 404.42, "end": 404.76, "confidence": 0.994}, {"text": "together", "start": 404.76, "end": 405.22, "confidence": 0.987}, {"text": "instead", "start": 405.22, "end": 405.58, "confidence": 0.736}, {"text": "of", "start": 405.58, "end": 405.74, "confidence": 0.992}, {"text": "processing", "start": 405.74, "end": 406.26, "confidence": 0.936}, {"text": "them", "start": 406.26, "end": 406.58, "confidence": 0.978}, {"text": "one", "start": 406.58, "end": 406.7, "confidence": 0.976}, {"text": "by", "start": 406.7, "end": 406.86, "confidence": 0.954}, {"text": "one.", "start": 406.86, "end": 407.22, "confidence": 0.992}, {"text": "OK,", "start": 407.22, "end": 407.46, "confidence": 0.633}, {"text": "this", "start": 407.78, "end": 407.8, "confidence": 0.974}, {"text": "is", "start": 407.8, "end": 407.96, "confidence": 0.955}, {"text": "all", "start": 407.96, "end": 408.12, "confidence": 0.985}, {"text": "starting", "start": 408.12, "end": 408.4, "confidence": 0.979}, {"text": "to", "start": 408.4, "end": 408.44, "confidence": 0.997}, {"text": "make", "start": 408.44, "end": 408.64, "confidence": 0.99}, {"text": "sense.", "start": 408.64, "end": 408.82, "confidence": 0.874}, {"text": "But", "start": 409.04, "end": 409.06, "confidence": 0.89}, {"text": "let's", "start": 409.06, "end": 409.1, "confidence": 0.992}, {"text": "get", "start": 409.1, "end": 409.32, "confidence": 0.989}, {"text": "down", "start": 409.32, "end": 409.56, "confidence": 0.991}, {"text": "to", "start": 409.56, "end": 409.66, "confidence": 0.97}, {"text": "brass", "start": 409.66, "end": 410.26, "confidence": 0.973}, {"text": "tacks", "start": 410.26, "end": 410.28, "confidence": 0.929}, {"text": "here.", "start": 410.28, "end": 410.5, "confidence": 0.863}, {"text": "How", "start": 410.56, "end": 410.7, "confidence": 0.986}, {"text": "do", "start": 410.7, "end": 410.84, "confidence": 0.874}, {"text": "these", "start": 410.84, "end": 410.98, "confidence": 0.98}, {"text": "STMOE", "start": 410.98, "end": 411.72, "confidence": 0.598}, {"text": "models", "start": 411.72, "end": 412.12, "confidence": 0.921}, {"text": "actually", "start": 412.12, "end": 412.68, "confidence": 0.947}, {"text": "perform", "start": 412.68, "end": 413.26, "confidence": 0.93}, {"text": "in", "start": 413.26, "end": 413.52, "confidence": 0.985}, {"text": "the", "start": 413.52, "end": 413.54, "confidence": 0.999}, {"text": "real", "start": 413.54, "end": 413.8, "confidence": 0.993}, {"text": "world?", "start": 413.8, "end": 414.08, "confidence": 0.995}, {"text": "Did", "start": 414.22, "end": 414.24, "confidence": 0.838}, {"text": "they", "start": 414.24, "end": 414.46, "confidence": 0.991}, {"text": "put", "start": 414.46, "end": 414.66, "confidence": 0.987}, {"text": "them", "start": 414.66, "end": 414.82, "confidence": 0.979}, {"text": "through", "start": 414.82, "end": 414.92, "confidence": 0.992}, {"text": "their", "start": 414.92, "end": 415.06, "confidence": 0.992}, {"text": "paces?", "start": 415.06, "end": 415.28, "confidence": 0.982}, {"text": "They", "start": 415.66, "end": 415.68, "confidence": 0.812}, {"text": "did.", "start": 415.68, "end": 416.2, "confidence": 0.981}, {"text": "The", "start": 416.5, "end": 416.52, "confidence": 0.396}, {"text": "researchers", "start": 416.52, "end": 416.96, "confidence": 0.817}, {"text": "tested", "start": 416.96, "end": 417.26, "confidence": 0.907}, {"text": "them", "start": 417.26, "end": 417.28, "confidence": 0.487}, {"text": "in", "start": 417.28, "end": 417.3, "confidence": 0.194}, {"text": "the", "start": 417.3, "end": 417.32, "confidence": 0.401}, {"text": "lab.", "start": 417.32, "end": 417.34, "confidence": 0.585}, {"text": "They", "start": 417.34, "end": 417.36, "confidence": 0.177}, {"text": "found", "start": 417.36, "end": 417.38, "confidence": 0.124}, {"text": "that", "start": 417.38, "end": 417.4, "confidence": 0.386}, {"text": "they", "start": 417.4, "end": 417.42, "confidence": 0.205}, {"text": "were", "start": 417.42, "end": 417.44, "confidence": 0.106}, {"text": "much", "start": 417.44, "end": 417.46, "confidence": 0.137}, {"text": "faster", "start": 417.46, "end": 417.48, "confidence": 0.353}, {"text": "in", "start": 417.48, "end": 417.5, "confidence": 0.212}, {"text": "processing", "start": 417.5, "end": 417.52, "confidence": 0.065}, {"text": "words", "start": 417.52, "end": 417.54, "confidence": 0.201}, {"text": "than", "start": 417.54, "end": 417.56, "confidence": 0.61}, {"text": "in", "start": 417.56, "end": 417.58, "confidence": 0.407}, {"text": "the", "start": 417.58, "end": 417.6, "confidence": 0.418}, {"text": "real", "start": 417.6, "end": 417.62, "confidence": 0.407}, {"text": "world.", "start": 417.62, "end": 417.64, "confidence": 0.974}, {"text": "And", "start": 417.64, "end": 417.66, "confidence": 0.137}, {"text": "they", "start": 417.66, "end": 417.68, "confidence": 0.358}, {"text": "found", "start": 417.68, "end": 417.7, "confidence": 0.191}, {"text": "that", "start": 417.7, "end": 417.72, "confidence": 0.533}, {"text": "they", "start": 417.72, "end": 417.74, "confidence": 0.301}, {"text": "were", "start": 417.74, "end": 417.76, "confidence": 0.251}, {"text": "much", "start": 417.76, "end": 417.78, "confidence": 0.488}, {"text": "faster", "start": 417.78, "end": 417.8, "confidence": 0.517}, {"text": "in", "start": 417.8, "end": 417.82, "confidence": 0.842}, {"text": "processing", "start": 417.82, "end": 417.84, "confidence": 0.088}, {"text": "words", "start": 417.84, "end": 417.86, "confidence": 0.369}, {"text": "than", "start": 417.86, "end": 417.88, "confidence": 0.669}, {"text": "in", "start": 417.88, "end": 417.9, "confidence": 0.962}, {"text": "the", "start": 417.9, "end": 417.92, "confidence": 0.957}, {"text": "real", "start": 417.92, "end": 417.94, "confidence": 0.917}, {"text": "world.", "start": 417.94, "end": 417.96, "confidence": 0.992}, {"text": "So", "start": 417.96, "end": 417.98, "confidence": 0.197}, {"text": "they're", "start": 417.98, "end": 418.0, "confidence": 0.289}, {"text": "not", "start": 418.0, "end": 418.02, "confidence": 0.097}, {"text": "just", "start": 418.02, "end": 418.04, "confidence": 0.105}, {"text": "better", "start": 418.04, "end": 418.06, "confidence": 0.061}, {"text": "at", "start": 418.06, "end": 418.08, "confidence": 0.392}, {"text": "routing.", "start": 418.08, "end": 418.1, "confidence": 0.24}, {"text": "They're", "start": 418.1, "end": 418.12, "confidence": 0.586}, {"text": "much", "start": 418.12, "end": 418.14, "confidence": 0.321}, {"text": "faster", "start": 418.14, "end": 418.16, "confidence": 0.532}, {"text": "at", "start": 418.16, "end": 418.18, "confidence": 0.505}, {"text": "processing", "start": 418.18, "end": 418.2, "confidence": 0.077}, {"text": "words.", "start": 418.2, "end": 418.22, "confidence": 0.407}, {"text": "And", "start": 418.22, "end": 418.24, "confidence": 0.163}]}, {"id": 23, "seek": 41728, "start": 418.24, "end": 447.1, "text": " So they tested them on a whole range of tasks from question answering to summarization to natural language inference. And honestly, the results are pretty impressive. So these aren't just theoretical toys. They can actually hold their own against the big guys. Not only hold their own, they often surpass them on a benchmark called SuperGLUE, which tests a variety of language understanding skills. The STMOE models actually beat the estimated human performance. They're outperforming humans on certain language tasks. Now, that's what I call progress.", "tokens": [50413, 407, 220, 13162, 220, 83, 21885, 220, 47959, 322, 257, 1379, 3613, 295, 220, 83, 296, 1694, 490, 1168, 13430, 220, 1353, 14611, 2144, 220, 1353, 3303, 2856, 13596, 655, 13, 400, 6095, 11, 220, 3322, 3542, 366, 1238, 704, 22733, 13, 407, 220, 42678, 3212, 380, 445, 220, 3322, 26262, 804, 220, 83, 939, 82, 13, 814, 393, 767, 1797, 220, 3322, 347, 1065, 1970, 220, 3322, 955, 1074, 13, 1726, 787, 1797, 220, 3322, 347, 1065, 11, 220, 13162, 2049, 27650, 220, 47959, 322, 257, 18927, 1219, 4548, 38, 43, 16309, 11, 597, 220, 83, 4409, 257, 1374, 1684, 88, 295, 2856, 3701, 3942, 13, 440, 4904, 18976, 36, 5245, 767, 4224, 220, 3322, 871, 33862, 292, 1952, 3389, 13, 814, 434, 484, 610, 48610, 6255, 322, 1629, 2856, 220, 83, 296, 1694, 13, 823, 11, 220, 6780, 311, 437, 286, 818, 4205, 13], "temperature": 0.0, "avg_logprob": -0.15681396948324666, "compression_ratio": 1.6932515337423313, "no_speech_prob": 0.22287052869796753, "confidence": 0.869, "words": [{"text": "So", "start": 418.24, "end": 418.26, "confidence": 0.198}, {"text": "they", "start": 418.26, "end": 418.28, "confidence": 0.459}, {"text": "tested", "start": 418.28, "end": 418.3, "confidence": 0.908}, {"text": "them", "start": 418.3, "end": 418.32, "confidence": 0.967}, {"text": "on", "start": 418.32, "end": 418.34, "confidence": 0.984}, {"text": "a", "start": 418.34, "end": 418.36, "confidence": 0.992}, {"text": "whole", "start": 418.36, "end": 418.38, "confidence": 0.97}, {"text": "range", "start": 418.38, "end": 418.5, "confidence": 0.787}, {"text": "of", "start": 418.5, "end": 418.62, "confidence": 0.981}, {"text": "tasks", "start": 418.62, "end": 419.12, "confidence": 0.978}, {"text": "from", "start": 419.12, "end": 419.34, "confidence": 0.477}, {"text": "question", "start": 419.34, "end": 419.78, "confidence": 0.96}, {"text": "answering", "start": 419.78, "end": 420.26, "confidence": 0.723}, {"text": "to", "start": 420.26, "end": 420.68, "confidence": 0.872}, {"text": "summarization", "start": 420.68, "end": 421.48, "confidence": 0.949}, {"text": "to", "start": 421.48, "end": 421.7, "confidence": 0.875}, {"text": "natural", "start": 421.7, "end": 422.1, "confidence": 0.953}, {"text": "language", "start": 422.1, "end": 422.56, "confidence": 0.865}, {"text": "inference.", "start": 422.56, "end": 422.94, "confidence": 0.834}, {"text": "And", "start": 423.08, "end": 423.5, "confidence": 0.959}, {"text": "honestly,", "start": 423.5, "end": 424.08, "confidence": 0.84}, {"text": "the", "start": 424.54, "end": 424.56, "confidence": 0.995}, {"text": "results", "start": 424.56, "end": 424.92, "confidence": 0.643}, {"text": "are", "start": 424.92, "end": 425.08, "confidence": 0.957}, {"text": "pretty", "start": 425.08, "end": 425.32, "confidence": 0.984}, {"text": "impressive.", "start": 425.32, "end": 425.8, "confidence": 0.683}, {"text": "So", "start": 425.82, "end": 425.92, "confidence": 0.579}, {"text": "these", "start": 425.92, "end": 426.08, "confidence": 0.966}, {"text": "aren't", "start": 426.08, "end": 426.34, "confidence": 0.837}, {"text": "just", "start": 426.34, "end": 426.36, "confidence": 0.949}, {"text": "theoretical", "start": 426.36, "end": 426.84, "confidence": 0.888}, {"text": "toys.", "start": 426.84, "end": 427.32, "confidence": 0.779}, {"text": "They", "start": 427.34, "end": 427.36, "confidence": 0.96}, {"text": "can", "start": 427.36, "end": 427.54, "confidence": 0.987}, {"text": "actually", "start": 427.54, "end": 427.78, "confidence": 0.865}, {"text": "hold", "start": 427.78, "end": 428.04, "confidence": 0.991}, {"text": "their", "start": 428.04, "end": 428.24, "confidence": 0.995}, {"text": "own", "start": 428.24, "end": 428.52, "confidence": 0.989}, {"text": "against", "start": 428.52, "end": 428.7, "confidence": 0.953}, {"text": "the", "start": 428.7, "end": 428.86, "confidence": 0.997}, {"text": "big", "start": 428.86, "end": 429.22, "confidence": 0.987}, {"text": "guys.", "start": 429.22, "end": 429.64, "confidence": 0.981}, {"text": "Not", "start": 429.64, "end": 429.9, "confidence": 0.596}, {"text": "only", "start": 429.9, "end": 430.14, "confidence": 0.981}, {"text": "hold", "start": 430.14, "end": 430.46, "confidence": 0.981}, {"text": "their", "start": 430.46, "end": 430.84, "confidence": 0.993}, {"text": "own,", "start": 430.84, "end": 431.24, "confidence": 0.983}, {"text": "they", "start": 431.24, "end": 431.72, "confidence": 0.973}, {"text": "often", "start": 431.72, "end": 431.96, "confidence": 0.772}, {"text": "surpass", "start": 431.96, "end": 432.5, "confidence": 0.799}, {"text": "them", "start": 432.5, "end": 432.88, "confidence": 0.978}, {"text": "on", "start": 432.88, "end": 433.36, "confidence": 0.838}, {"text": "a", "start": 433.36, "end": 433.48, "confidence": 0.988}, {"text": "benchmark", "start": 433.48, "end": 433.98, "confidence": 0.937}, {"text": "called", "start": 433.98, "end": 434.32, "confidence": 0.914}, {"text": "SuperGLUE,", "start": 434.32, "end": 435.74, "confidence": 0.773}, {"text": "which", "start": 436.38, "end": 436.6, "confidence": 0.986}, {"text": "tests", "start": 436.6, "end": 437.06, "confidence": 0.985}, {"text": "a", "start": 437.06, "end": 437.08, "confidence": 0.985}, {"text": "variety", "start": 437.08, "end": 437.58, "confidence": 0.78}, {"text": "of", "start": 437.58, "end": 437.98, "confidence": 0.991}, {"text": "language", "start": 437.98, "end": 438.1, "confidence": 0.765}, {"text": "understanding", "start": 438.1, "end": 438.52, "confidence": 0.488}, {"text": "skills.", "start": 438.52, "end": 439.08, "confidence": 0.952}, {"text": "The", "start": 439.08, "end": 439.68, "confidence": 0.949}, {"text": "STMOE", "start": 439.68, "end": 440.3, "confidence": 0.955}, {"text": "models", "start": 440.3, "end": 440.7, "confidence": 0.873}, {"text": "actually", "start": 440.7, "end": 441.0, "confidence": 0.919}, {"text": "beat", "start": 441.0, "end": 441.3, "confidence": 0.968}, {"text": "the", "start": 441.3, "end": 441.4, "confidence": 0.998}, {"text": "estimated", "start": 441.4, "end": 441.9, "confidence": 0.81}, {"text": "human", "start": 441.9, "end": 442.28, "confidence": 0.949}, {"text": "performance.", "start": 442.28, "end": 442.8, "confidence": 0.948}, {"text": "They're", "start": 442.92, "end": 443.26, "confidence": 0.77}, {"text": "outperforming", "start": 443.26, "end": 443.88, "confidence": 0.685}, {"text": "humans", "start": 443.88, "end": 444.38, "confidence": 0.849}, {"text": "on", "start": 444.38, "end": 444.5, "confidence": 0.992}, {"text": "certain", "start": 444.5, "end": 444.84, "confidence": 0.974}, {"text": "language", "start": 444.84, "end": 445.16, "confidence": 0.839}, {"text": "tasks.", "start": 445.16, "end": 445.76, "confidence": 0.989}, {"text": "Now,", "start": 445.76, "end": 445.94, "confidence": 0.745}, {"text": "that's", "start": 445.96, "end": 446.38, "confidence": 0.978}, {"text": "what", "start": 446.38, "end": 446.4, "confidence": 0.99}, {"text": "I", "start": 446.4, "end": 446.48, "confidence": 0.992}, {"text": "call", "start": 446.48, "end": 446.66, "confidence": 0.986}, {"text": "progress.", "start": 446.66, "end": 447.1, "confidence": 0.875}]}, {"id": 24, "seek": 44728, "start": 447.28, "end": 450.42, "text": " They also showed these remarkable improvements in summarization.", "tokens": [50380, 814, 611, 4712, 220, 42678, 890, 809, 712, 13797, 294, 14611, 2144, 13, 50535], "temperature": 0.0, "avg_logprob": -0.23655831186394943, "compression_ratio": 1.6094674556213018, "no_speech_prob": 0.17996153235435486, "confidence": 0.839, "words": [{"text": "They", "start": 447.28, "end": 447.6, "confidence": 0.866}, {"text": "also", "start": 447.6, "end": 447.84, "confidence": 0.941}, {"text": "showed", "start": 447.84, "end": 448.14, "confidence": 0.794}, {"text": "these", "start": 448.14, "end": 448.22, "confidence": 0.984}, {"text": "remarkable", "start": 448.22, "end": 448.9, "confidence": 0.705}, {"text": "improvements", "start": 448.9, "end": 449.54, "confidence": 0.602}, {"text": "in", "start": 449.54, "end": 449.78, "confidence": 0.937}, {"text": "summarization.", "start": 449.78, "end": 450.42, "confidence": 0.991}]}, {"id": 25, "seek": 44728, "start": 451.14, "end": 458.38, "text": " Imagine an AI that can read a long news article and condense it down to the key points. No more information overload.", "tokens": [50557, 11739, 364, 7318, 220, 6780, 393, 1401, 257, 938, 2583, 7222, 293, 2224, 1288, 309, 760, 220, 1353, 220, 3322, 2141, 2793, 13, 883, 544, 1589, 28777, 13, 50923], "temperature": 0.0, "avg_logprob": -0.23655831186394943, "compression_ratio": 1.6094674556213018, "no_speech_prob": 0.17996153235435486, "confidence": 0.887, "words": [{"text": "Imagine", "start": 451.14, "end": 451.58, "confidence": 0.967}, {"text": "an", "start": 451.58, "end": 451.86, "confidence": 0.989}, {"text": "AI", "start": 451.86, "end": 452.28, "confidence": 0.489}, {"text": "that", "start": 452.28, "end": 452.52, "confidence": 0.995}, {"text": "can", "start": 452.52, "end": 452.6, "confidence": 0.99}, {"text": "read", "start": 452.6, "end": 452.76, "confidence": 0.962}, {"text": "a", "start": 452.76, "end": 453.1, "confidence": 0.998}, {"text": "long", "start": 453.1, "end": 453.44, "confidence": 0.997}, {"text": "news", "start": 453.44, "end": 454.08, "confidence": 0.988}, {"text": "article", "start": 454.08, "end": 454.68, "confidence": 0.948}, {"text": "and", "start": 454.68, "end": 455.08, "confidence": 0.925}, {"text": "condense", "start": 455.08, "end": 455.5, "confidence": 0.539}, {"text": "it", "start": 455.5, "end": 455.62, "confidence": 0.98}, {"text": "down", "start": 455.62, "end": 455.82, "confidence": 0.983}, {"text": "to", "start": 455.82, "end": 455.98, "confidence": 0.994}, {"text": "the", "start": 455.98, "end": 456.04, "confidence": 0.996}, {"text": "key", "start": 456.04, "end": 456.26, "confidence": 0.953}, {"text": "points.", "start": 456.26, "end": 456.86, "confidence": 0.887}, {"text": "No", "start": 456.92, "end": 457.18, "confidence": 0.889}, {"text": "more", "start": 457.18, "end": 457.38, "confidence": 0.985}, {"text": "information", "start": 457.38, "end": 457.9, "confidence": 0.893}, {"text": "overload.", "start": 457.9, "end": 458.38, "confidence": 0.652}]}, {"id": 26, "seek": 44728, "start": 458.74, "end": 477.32, "text": " That would definitely come in handy. What about other areas? Did they test them on anything like trivia questions? Yes, they did. They looked at closed book question answering, which means the model has to answer without any access to external information. And the STMOE models did incredibly well, suggesting they're capable of retaining a vast amount of data.", "tokens": [50951, 663, 576, 28781, 736, 808, 294, 13239, 13, 708, 466, 661, 3179, 30, 2589, 220, 13162, 220, 31636, 220, 47959, 322, 1340, 411, 220, 83, 470, 11617, 1651, 30, 1079, 11, 220, 13162, 630, 13, 814, 2956, 412, 5395, 1446, 1168, 13430, 11, 597, 1355, 220, 3322, 2316, 575, 220, 1353, 1867, 1553, 604, 2105, 220, 1353, 8320, 1589, 13, 400, 220, 3322, 4904, 18976, 36, 5245, 630, 6252, 731, 11, 3395, 8714, 220, 13162, 434, 8189, 295, 34936, 257, 8369, 2372, 295, 1412, 13, 51851], "temperature": 0.0, "avg_logprob": -0.23655831186394943, "compression_ratio": 1.6094674556213018, "no_speech_prob": 0.17996153235435486, "confidence": 0.874, "words": [{"text": "That", "start": 458.74, "end": 459.22, "confidence": 0.837}, {"text": "would", "start": 459.22, "end": 459.32, "confidence": 0.995}, {"text": "definitely", "start": 459.32, "end": 459.56, "confidence": 0.693}, {"text": "come", "start": 459.56, "end": 459.8, "confidence": 0.996}, {"text": "in", "start": 459.8, "end": 459.82, "confidence": 0.988}, {"text": "handy.", "start": 459.82, "end": 460.18, "confidence": 0.965}, {"text": "What", "start": 460.18, "end": 460.4, "confidence": 0.962}, {"text": "about", "start": 460.4, "end": 460.6, "confidence": 0.984}, {"text": "other", "start": 460.6, "end": 460.94, "confidence": 0.982}, {"text": "areas?", "start": 460.94, "end": 461.5, "confidence": 0.801}, {"text": "Did", "start": 461.68, "end": 461.7, "confidence": 0.967}, {"text": "they", "start": 461.7, "end": 461.76, "confidence": 0.987}, {"text": "test", "start": 461.76, "end": 461.98, "confidence": 0.986}, {"text": "them", "start": 461.98, "end": 462.12, "confidence": 0.983}, {"text": "on", "start": 462.12, "end": 462.26, "confidence": 0.987}, {"text": "anything", "start": 462.26, "end": 462.38, "confidence": 0.933}, {"text": "like", "start": 462.38, "end": 462.76, "confidence": 0.954}, {"text": "trivia", "start": 462.76, "end": 463.8, "confidence": 0.703}, {"text": "questions?", "start": 463.8, "end": 464.28, "confidence": 0.975}, {"text": "Yes,", "start": 464.3, "end": 464.72, "confidence": 0.716}, {"text": "they", "start": 464.86, "end": 465.1, "confidence": 0.988}, {"text": "did.", "start": 465.1, "end": 465.4, "confidence": 0.975}, {"text": "They", "start": 465.52, "end": 465.94, "confidence": 0.847}, {"text": "looked", "start": 465.94, "end": 466.18, "confidence": 0.889}, {"text": "at", "start": 466.18, "end": 466.36, "confidence": 0.989}, {"text": "closed", "start": 466.36, "end": 466.72, "confidence": 0.939}, {"text": "book", "start": 466.72, "end": 467.0, "confidence": 0.866}, {"text": "question", "start": 467.0, "end": 467.4, "confidence": 0.901}, {"text": "answering,", "start": 467.4, "end": 467.94, "confidence": 0.692}, {"text": "which", "start": 468.7, "end": 468.72, "confidence": 0.987}, {"text": "means", "start": 468.72, "end": 469.02, "confidence": 0.971}, {"text": "the", "start": 469.02, "end": 469.26, "confidence": 0.995}, {"text": "model", "start": 469.26, "end": 469.52, "confidence": 0.712}, {"text": "has", "start": 469.52, "end": 469.78, "confidence": 0.978}, {"text": "to", "start": 469.78, "end": 469.8, "confidence": 0.999}, {"text": "answer", "start": 469.8, "end": 470.14, "confidence": 0.968}, {"text": "without", "start": 470.14, "end": 470.44, "confidence": 0.989}, {"text": "any", "start": 470.44, "end": 470.8, "confidence": 0.962}, {"text": "access", "start": 470.8, "end": 471.2, "confidence": 0.987}, {"text": "to", "start": 471.2, "end": 471.4, "confidence": 0.998}, {"text": "external", "start": 471.4, "end": 471.72, "confidence": 0.69}, {"text": "information.", "start": 471.72, "end": 472.32, "confidence": 0.828}, {"text": "And", "start": 472.6, "end": 472.88, "confidence": 0.78}, {"text": "the", "start": 472.88, "end": 473.0, "confidence": 0.992}, {"text": "STMOE", "start": 473.0, "end": 473.58, "confidence": 0.952}, {"text": "models", "start": 473.58, "end": 473.82, "confidence": 0.785}, {"text": "did", "start": 473.82, "end": 474.04, "confidence": 0.964}, {"text": "incredibly", "start": 474.04, "end": 474.58, "confidence": 0.982}, {"text": "well,", "start": 474.58, "end": 475.04, "confidence": 0.991}, {"text": "suggesting", "start": 475.6, "end": 475.62, "confidence": 0.592}, {"text": "they're", "start": 475.62, "end": 475.74, "confidence": 0.972}, {"text": "capable", "start": 475.74, "end": 476.22, "confidence": 0.897}, {"text": "of", "start": 476.22, "end": 476.5, "confidence": 0.984}, {"text": "retaining", "start": 476.5, "end": 476.8, "confidence": 0.617}, {"text": "a", "start": 476.8, "end": 476.98, "confidence": 0.962}, {"text": "vast", "start": 476.98, "end": 477.26, "confidence": 0.521}, {"text": "amount", "start": 477.26, "end": 477.28, "confidence": 0.494}, {"text": "of", "start": 477.28, "end": 477.3, "confidence": 0.957}, {"text": "data.", "start": 477.3, "end": 477.32, "confidence": 0.381}]}, {"id": 27, "seek": 47728, "start": 478.16, "end": 484.44, "text": " So it's like they've absorbed all this information and can now use it to answer your questions on the fly, like a walking, talking encyclopedia.", "tokens": [50407, 407, 309, 311, 411, 220, 13162, 600, 20799, 439, 220, 11176, 1589, 293, 393, 586, 764, 309, 220, 1353, 1867, 428, 1651, 322, 220, 3322, 3603, 11, 411, 257, 4494, 11, 220, 29302, 278, 465, 34080, 27277, 654, 13, 50725], "temperature": 0.0, "avg_logprob": -0.16285210948879436, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.6008723974227905, "confidence": 0.92, "words": [{"text": "So", "start": 478.16, "end": 478.32, "confidence": 0.911}, {"text": "it's", "start": 478.32, "end": 478.48, "confidence": 0.853}, {"text": "like", "start": 478.48, "end": 478.62, "confidence": 0.986}, {"text": "they've", "start": 478.62, "end": 479.0, "confidence": 0.956}, {"text": "absorbed", "start": 479.0, "end": 479.12, "confidence": 0.366}, {"text": "all", "start": 479.12, "end": 479.26, "confidence": 0.992}, {"text": "this", "start": 479.26, "end": 479.74, "confidence": 0.996}, {"text": "information", "start": 479.74, "end": 480.36, "confidence": 0.886}, {"text": "and", "start": 480.36, "end": 480.84, "confidence": 0.955}, {"text": "can", "start": 480.84, "end": 481.0, "confidence": 0.989}, {"text": "now", "start": 481.0, "end": 481.1, "confidence": 0.961}, {"text": "use", "start": 481.1, "end": 481.32, "confidence": 0.918}, {"text": "it", "start": 481.32, "end": 481.48, "confidence": 0.988}, {"text": "to", "start": 481.48, "end": 481.56, "confidence": 0.997}, {"text": "answer", "start": 481.56, "end": 481.74, "confidence": 0.954}, {"text": "your", "start": 481.74, "end": 482.32, "confidence": 0.988}, {"text": "questions", "start": 482.32, "end": 482.38, "confidence": 0.988}, {"text": "on", "start": 482.38, "end": 482.4, "confidence": 0.992}, {"text": "the", "start": 482.4, "end": 482.62, "confidence": 0.999}, {"text": "fly,", "start": 482.62, "end": 482.7, "confidence": 0.994}, {"text": "like", "start": 482.8, "end": 482.96, "confidence": 0.983}, {"text": "a", "start": 482.96, "end": 483.0, "confidence": 0.997}, {"text": "walking,", "start": 483.0, "end": 483.36, "confidence": 0.966}, {"text": "talking", "start": 483.52, "end": 483.74, "confidence": 0.995}, {"text": "encyclopedia.", "start": 483.74, "end": 484.44, "confidence": 0.789}]}, {"id": 28, "seek": 47728, "start": 484.72, "end": 502.14, "text": " They even tested the models on data sets that were specifically designed to be tricky, full of ambiguous language and misleading questions. And even then, the STMOE models held their own, showing a level of robustness and common sense reasoning. That is pretty remarkable.", "tokens": [50735, 814, 754, 220, 83, 21885, 220, 3322, 5245, 322, 1412, 6352, 220, 6780, 645, 637, 3045, 351, 984, 730, 328, 9232, 220, 1353, 312, 220, 6903, 20539, 11, 1577, 295, 39465, 2856, 293, 3346, 306, 8166, 1651, 13, 400, 754, 220, 19096, 11, 220, 3322, 4904, 18976, 36, 5245, 5167, 220, 3322, 347, 1065, 11, 4099, 257, 1496, 295, 13956, 1287, 293, 2689, 2020, 319, 296, 16638, 13, 663, 307, 1238, 12802, 13, 51607], "temperature": 0.0, "avg_logprob": -0.16285210948879436, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.6008723974227905, "confidence": 0.893, "words": [{"text": "They", "start": 484.72, "end": 484.86, "confidence": 0.961}, {"text": "even", "start": 484.86, "end": 485.2, "confidence": 0.952}, {"text": "tested", "start": 485.2, "end": 485.52, "confidence": 0.986}, {"text": "the", "start": 485.52, "end": 485.66, "confidence": 0.999}, {"text": "models", "start": 485.66, "end": 486.1, "confidence": 0.925}, {"text": "on", "start": 486.1, "end": 486.4, "confidence": 0.995}, {"text": "data", "start": 486.4, "end": 486.78, "confidence": 0.515}, {"text": "sets", "start": 486.78, "end": 487.38, "confidence": 0.918}, {"text": "that", "start": 487.38, "end": 487.84, "confidence": 0.856}, {"text": "were", "start": 487.84, "end": 487.88, "confidence": 0.993}, {"text": "specifically", "start": 487.88, "end": 488.46, "confidence": 0.766}, {"text": "designed", "start": 488.46, "end": 488.94, "confidence": 0.819}, {"text": "to", "start": 488.94, "end": 489.04, "confidence": 0.999}, {"text": "be", "start": 489.04, "end": 489.1, "confidence": 0.995}, {"text": "tricky,", "start": 489.1, "end": 489.72, "confidence": 0.989}, {"text": "full", "start": 490.08, "end": 490.16, "confidence": 0.991}, {"text": "of", "start": 490.16, "end": 490.3, "confidence": 0.996}, {"text": "ambiguous", "start": 490.3, "end": 491.0, "confidence": 0.61}, {"text": "language", "start": 491.0, "end": 491.56, "confidence": 0.845}, {"text": "and", "start": 491.56, "end": 491.72, "confidence": 0.983}, {"text": "misleading", "start": 491.72, "end": 492.24, "confidence": 0.681}, {"text": "questions.", "start": 492.24, "end": 493.1, "confidence": 0.987}, {"text": "And", "start": 493.18, "end": 493.36, "confidence": 0.792}, {"text": "even", "start": 493.36, "end": 493.56, "confidence": 0.968}, {"text": "then,", "start": 493.56, "end": 494.24, "confidence": 0.995}, {"text": "the", "start": 494.34, "end": 494.42, "confidence": 0.996}, {"text": "STMOE", "start": 494.42, "end": 495.14, "confidence": 0.975}, {"text": "models", "start": 495.14, "end": 495.64, "confidence": 0.917}, {"text": "held", "start": 495.64, "end": 496.0, "confidence": 0.984}, {"text": "their", "start": 496.0, "end": 496.44, "confidence": 0.997}, {"text": "own,", "start": 496.44, "end": 497.1, "confidence": 0.988}, {"text": "showing", "start": 497.4, "end": 497.42, "confidence": 0.967}, {"text": "a", "start": 497.42, "end": 497.58, "confidence": 0.998}, {"text": "level", "start": 497.58, "end": 497.84, "confidence": 0.966}, {"text": "of", "start": 497.84, "end": 497.96, "confidence": 0.994}, {"text": "robustness", "start": 497.96, "end": 498.84, "confidence": 0.99}, {"text": "and", "start": 498.84, "end": 499.0, "confidence": 0.985}, {"text": "common", "start": 499.0, "end": 499.34, "confidence": 0.858}, {"text": "sense", "start": 499.34, "end": 499.68, "confidence": 0.883}, {"text": "reasoning.", "start": 499.68, "end": 500.32, "confidence": 0.77}, {"text": "That", "start": 500.7, "end": 500.88, "confidence": 0.951}, {"text": "is", "start": 500.88, "end": 501.08, "confidence": 0.983}, {"text": "pretty", "start": 501.08, "end": 501.46, "confidence": 0.985}, {"text": "remarkable.", "start": 501.46, "end": 502.14, "confidence": 0.372}]}, {"id": 29, "seek": 50214, "start": 502.14, "end": 532.12, "text": " That's encouraging. But were there any areas where they stumbled? No system is perfect, right? You're right. There were a few areas where they didn't quite reach the top. For example, on a data set focused on reading comprehension and answering questions based on a specific passage, their performance wasn't as stellar. So maybe they still need a bit more practice when it comes to deep analysis of complex texts. And while they aced the overall SuperGLU benchmark, their scores on certain subtasks within that weren't as impressive.", "tokens": [50365, 663, 311, 14580, 13, 583, 645, 220, 15456, 604, 3179, 689, 220, 13162, 36668, 30, 883, 1185, 307, 2176, 11, 558, 30, 509, 434, 558, 13, 821, 645, 257, 1326, 3179, 689, 220, 13162, 994, 380, 1596, 2524, 220, 3322, 220, 19337, 13, 1171, 1365, 11, 322, 257, 1412, 992, 5178, 322, 3760, 44991, 293, 13430, 1651, 2361, 322, 257, 637, 3045, 1089, 1320, 559, 68, 11, 220, 3322, 347, 3389, 2067, 380, 382, 42333, 13, 407, 1310, 220, 13162, 920, 643, 257, 857, 544, 3124, 562, 309, 1487, 220, 1353, 2452, 23014, 271, 295, 395, 781, 87, 220, 25111, 82, 13, 400, 1339, 220, 13162, 696, 292, 220, 3322, 4787, 4548, 38, 43, 52, 18927, 11, 220, 3322, 347, 13444, 322, 1629, 7257, 296, 1694, 1951, 220, 6780, 4999, 380, 382, 704, 22733, 13], "temperature": 0.0, "avg_logprob": -0.0917656473869825, "compression_ratio": 1.6330275229357798, "no_speech_prob": 0.22399653494358063, "confidence": 0.925, "words": [{"text": "That's", "start": 502.14, "end": 502.64, "confidence": 0.985}, {"text": "encouraging.", "start": 502.64, "end": 502.76, "confidence": 0.822}, {"text": "But", "start": 502.86, "end": 503.16, "confidence": 0.987}, {"text": "were", "start": 503.16, "end": 503.24, "confidence": 0.951}, {"text": "there", "start": 503.24, "end": 503.42, "confidence": 0.995}, {"text": "any", "start": 503.42, "end": 503.56, "confidence": 0.957}, {"text": "areas", "start": 503.56, "end": 503.98, "confidence": 0.755}, {"text": "where", "start": 503.98, "end": 504.2, "confidence": 0.993}, {"text": "they", "start": 504.2, "end": 504.32, "confidence": 0.99}, {"text": "stumbled?", "start": 504.32, "end": 504.92, "confidence": 0.575}, {"text": "No", "start": 506.18, "end": 506.2, "confidence": 0.982}, {"text": "system", "start": 506.2, "end": 506.58, "confidence": 0.987}, {"text": "is", "start": 506.58, "end": 506.68, "confidence": 0.979}, {"text": "perfect,", "start": 506.68, "end": 507.06, "confidence": 0.977}, {"text": "right?", "start": 507.14, "end": 507.4, "confidence": 0.983}, {"text": "You're", "start": 507.76, "end": 508.12, "confidence": 0.905}, {"text": "right.", "start": 508.12, "end": 508.36, "confidence": 0.987}, {"text": "There", "start": 508.44, "end": 508.62, "confidence": 0.928}, {"text": "were", "start": 508.62, "end": 508.78, "confidence": 0.994}, {"text": "a", "start": 508.78, "end": 509.02, "confidence": 0.998}, {"text": "few", "start": 509.02, "end": 509.12, "confidence": 0.881}, {"text": "areas", "start": 509.12, "end": 509.6, "confidence": 0.811}, {"text": "where", "start": 509.6, "end": 509.72, "confidence": 0.996}, {"text": "they", "start": 509.72, "end": 509.88, "confidence": 0.993}, {"text": "didn't", "start": 509.88, "end": 510.16, "confidence": 0.996}, {"text": "quite", "start": 510.16, "end": 510.34, "confidence": 0.977}, {"text": "reach", "start": 510.34, "end": 510.62, "confidence": 0.95}, {"text": "the", "start": 510.62, "end": 510.76, "confidence": 0.999}, {"text": "top.", "start": 510.76, "end": 511.1, "confidence": 0.981}, {"text": "For", "start": 511.38, "end": 511.64, "confidence": 0.944}, {"text": "example,", "start": 511.64, "end": 511.96, "confidence": 0.931}, {"text": "on", "start": 512.58, "end": 512.64, "confidence": 0.987}, {"text": "a", "start": 512.64, "end": 512.72, "confidence": 0.997}, {"text": "data", "start": 512.72, "end": 513.1, "confidence": 0.67}, {"text": "set", "start": 513.1, "end": 513.26, "confidence": 0.981}, {"text": "focused", "start": 513.26, "end": 513.54, "confidence": 0.672}, {"text": "on", "start": 513.54, "end": 513.78, "confidence": 0.994}, {"text": "reading", "start": 513.78, "end": 514.16, "confidence": 0.948}, {"text": "comprehension", "start": 514.16, "end": 514.92, "confidence": 0.987}, {"text": "and", "start": 514.92, "end": 515.62, "confidence": 0.94}, {"text": "answering", "start": 515.62, "end": 515.98, "confidence": 0.869}, {"text": "questions", "start": 515.98, "end": 516.44, "confidence": 0.99}, {"text": "based", "start": 516.44, "end": 516.78, "confidence": 0.975}, {"text": "on", "start": 516.78, "end": 516.86, "confidence": 0.994}, {"text": "a", "start": 516.86, "end": 517.08, "confidence": 0.997}, {"text": "specific", "start": 517.08, "end": 517.38, "confidence": 0.823}, {"text": "passage,", "start": 517.38, "end": 518.36, "confidence": 0.951}, {"text": "their", "start": 518.52, "end": 518.54, "confidence": 0.992}, {"text": "performance", "start": 518.54, "end": 518.96, "confidence": 0.962}, {"text": "wasn't", "start": 518.96, "end": 519.34, "confidence": 0.994}, {"text": "as", "start": 519.34, "end": 519.62, "confidence": 0.974}, {"text": "stellar.", "start": 519.62, "end": 519.98, "confidence": 0.594}, {"text": "So", "start": 520.16, "end": 520.32, "confidence": 0.692}, {"text": "maybe", "start": 520.32, "end": 520.5, "confidence": 0.979}, {"text": "they", "start": 520.5, "end": 520.74, "confidence": 0.992}, {"text": "still", "start": 520.74, "end": 520.96, "confidence": 0.993}, {"text": "need", "start": 520.96, "end": 521.12, "confidence": 0.984}, {"text": "a", "start": 521.12, "end": 521.28, "confidence": 0.994}, {"text": "bit", "start": 521.28, "end": 521.36, "confidence": 0.992}, {"text": "more", "start": 521.36, "end": 521.56, "confidence": 0.991}, {"text": "practice", "start": 521.56, "end": 522.1, "confidence": 0.913}, {"text": "when", "start": 522.1, "end": 522.28, "confidence": 0.984}, {"text": "it", "start": 522.28, "end": 522.3, "confidence": 0.988}, {"text": "comes", "start": 522.3, "end": 522.6, "confidence": 0.988}, {"text": "to", "start": 522.6, "end": 523.08, "confidence": 0.999}, {"text": "deep", "start": 523.08, "end": 523.34, "confidence": 0.983}, {"text": "analysis", "start": 523.34, "end": 523.86, "confidence": 0.94}, {"text": "of", "start": 523.86, "end": 524.0, "confidence": 0.994}, {"text": "complex", "start": 524.0, "end": 524.48, "confidence": 0.695}, {"text": "texts.", "start": 524.48, "end": 525.26, "confidence": 0.871}, {"text": "And", "start": 525.26, "end": 525.42, "confidence": 0.951}, {"text": "while", "start": 525.42, "end": 525.76, "confidence": 0.996}, {"text": "they", "start": 525.76, "end": 525.94, "confidence": 0.988}, {"text": "aced", "start": 525.94, "end": 526.3, "confidence": 0.936}, {"text": "the", "start": 526.3, "end": 526.5, "confidence": 0.991}, {"text": "overall", "start": 526.5, "end": 526.96, "confidence": 0.92}, {"text": "SuperGLU", "start": 526.96, "end": 527.86, "confidence": 0.751}, {"text": "benchmark,", "start": 527.86, "end": 528.44, "confidence": 0.938}, {"text": "their", "start": 529.2, "end": 529.3, "confidence": 0.992}, {"text": "scores", "start": 529.3, "end": 529.66, "confidence": 0.781}, {"text": "on", "start": 529.66, "end": 529.9, "confidence": 0.989}, {"text": "certain", "start": 529.9, "end": 530.16, "confidence": 0.987}, {"text": "subtasks", "start": 530.16, "end": 530.8, "confidence": 0.977}, {"text": "within", "start": 530.8, "end": 531.14, "confidence": 0.992}, {"text": "that", "start": 531.14, "end": 531.32, "confidence": 0.997}, {"text": "weren't", "start": 531.32, "end": 531.5, "confidence": 0.966}, {"text": "as", "start": 531.5, "end": 531.64, "confidence": 0.984}, {"text": "impressive.", "start": 531.64, "end": 532.12, "confidence": 0.737}]}, {"id": 30, "seek": 53214, "start": 532.14, "end": 561.24, "text": " It's like being a straight A student, but still having that one subject you struggle with. Makes sense. But even with those limitations, it sounds like the research paints a pretty optimistic picture for the future of AI. It does. The success of these STMOE models has these major implications. It shows that we can build powerful AI systems that are also efficient and sustainable, using far less energy and computational resources than those massive models we've become accustomed to. So it's not just about making AI smarter.", "tokens": [50364, 467, 311, 411, 885, 257, 2997, 316, 3107, 11, 457, 920, 1419, 220, 6780, 472, 3983, 291, 7799, 365, 13, 25245, 2020, 13, 583, 754, 365, 220, 49833, 2364, 31265, 11, 309, 3263, 411, 220, 3322, 2132, 28076, 257, 1238, 2427, 332, 468, 299, 3036, 337, 220, 3322, 2027, 295, 7318, 13, 467, 775, 13, 440, 2245, 295, 220, 42678, 4904, 18976, 36, 5245, 575, 220, 42678, 2563, 8484, 299, 763, 13, 467, 3110, 220, 6780, 321, 393, 1322, 4005, 7318, 3652, 220, 6780, 366, 611, 1244, 24549, 293, 11235, 11, 1228, 1400, 1570, 2281, 293, 28270, 3593, 220, 24852, 220, 49833, 5994, 5245, 321, 600, 1813, 35980, 220, 1353, 13, 407, 309, 311, 406, 445, 466, 1455, 7318, 4069, 260, 13, 51806], "temperature": 0.0, "avg_logprob": -0.12239186096191407, "compression_ratio": 1.6048632218844985, "no_speech_prob": 0.23319710791110992, "confidence": 0.9, "words": [{"text": "It's", "start": 532.14, "end": 532.32, "confidence": 0.99}, {"text": "like", "start": 532.32, "end": 532.46, "confidence": 0.988}, {"text": "being", "start": 532.46, "end": 532.7, "confidence": 0.98}, {"text": "a", "start": 532.7, "end": 533.04, "confidence": 0.997}, {"text": "straight", "start": 533.04, "end": 533.06, "confidence": 0.986}, {"text": "A", "start": 533.06, "end": 533.08, "confidence": 0.704}, {"text": "student,", "start": 533.08, "end": 533.42, "confidence": 0.979}, {"text": "but", "start": 533.6, "end": 533.62, "confidence": 0.988}, {"text": "still", "start": 533.62, "end": 533.74, "confidence": 0.99}, {"text": "having", "start": 533.74, "end": 533.98, "confidence": 0.92}, {"text": "that", "start": 533.98, "end": 534.24, "confidence": 0.992}, {"text": "one", "start": 534.24, "end": 534.64, "confidence": 0.989}, {"text": "subject", "start": 534.64, "end": 534.7, "confidence": 0.916}, {"text": "you", "start": 534.7, "end": 534.9, "confidence": 0.935}, {"text": "struggle", "start": 534.9, "end": 535.14, "confidence": 0.91}, {"text": "with.", "start": 535.14, "end": 535.28, "confidence": 0.99}, {"text": "Makes", "start": 535.34, "end": 535.5, "confidence": 0.544}, {"text": "sense.", "start": 535.5, "end": 536.06, "confidence": 0.91}, {"text": "But", "start": 536.14, "end": 536.32, "confidence": 0.902}, {"text": "even", "start": 536.32, "end": 536.48, "confidence": 0.968}, {"text": "with", "start": 536.48, "end": 536.68, "confidence": 0.996}, {"text": "those", "start": 536.68, "end": 536.88, "confidence": 0.994}, {"text": "limitations,", "start": 536.88, "end": 538.08, "confidence": 0.582}, {"text": "it", "start": 538.36, "end": 538.38, "confidence": 0.98}, {"text": "sounds", "start": 538.38, "end": 538.58, "confidence": 0.953}, {"text": "like", "start": 538.58, "end": 538.68, "confidence": 0.99}, {"text": "the", "start": 538.68, "end": 538.78, "confidence": 0.998}, {"text": "research", "start": 538.78, "end": 539.18, "confidence": 0.986}, {"text": "paints", "start": 539.18, "end": 539.38, "confidence": 0.839}, {"text": "a", "start": 539.38, "end": 539.4, "confidence": 0.996}, {"text": "pretty", "start": 539.4, "end": 539.98, "confidence": 0.988}, {"text": "optimistic", "start": 539.98, "end": 540.54, "confidence": 0.635}, {"text": "picture", "start": 540.54, "end": 540.84, "confidence": 0.966}, {"text": "for", "start": 540.84, "end": 541.14, "confidence": 0.993}, {"text": "the", "start": 541.14, "end": 541.16, "confidence": 0.999}, {"text": "future", "start": 541.16, "end": 541.46, "confidence": 0.986}, {"text": "of", "start": 541.46, "end": 541.54, "confidence": 0.989}, {"text": "AI.", "start": 541.54, "end": 541.78, "confidence": 0.891}, {"text": "It", "start": 542.1, "end": 542.26, "confidence": 0.788}, {"text": "does.", "start": 542.26, "end": 542.58, "confidence": 0.988}, {"text": "The", "start": 543.14, "end": 543.18, "confidence": 0.964}, {"text": "success", "start": 543.18, "end": 543.7, "confidence": 0.92}, {"text": "of", "start": 543.7, "end": 543.84, "confidence": 0.993}, {"text": "these", "start": 543.84, "end": 543.96, "confidence": 0.983}, {"text": "STMOE", "start": 543.96, "end": 544.48, "confidence": 0.954}, {"text": "models", "start": 544.48, "end": 544.82, "confidence": 0.886}, {"text": "has", "start": 544.82, "end": 545.04, "confidence": 0.948}, {"text": "these", "start": 545.04, "end": 545.2, "confidence": 0.961}, {"text": "major", "start": 545.2, "end": 545.6, "confidence": 0.924}, {"text": "implications.", "start": 545.6, "end": 546.1, "confidence": 0.678}, {"text": "It", "start": 546.64, "end": 547.06, "confidence": 0.967}, {"text": "shows", "start": 547.06, "end": 547.36, "confidence": 0.965}, {"text": "that", "start": 547.36, "end": 547.56, "confidence": 0.996}, {"text": "we", "start": 547.56, "end": 547.68, "confidence": 0.995}, {"text": "can", "start": 547.68, "end": 547.9, "confidence": 0.99}, {"text": "build", "start": 547.9, "end": 548.24, "confidence": 0.987}, {"text": "powerful", "start": 548.24, "end": 548.92, "confidence": 0.983}, {"text": "AI", "start": 548.92, "end": 549.26, "confidence": 0.977}, {"text": "systems", "start": 549.26, "end": 549.98, "confidence": 0.937}, {"text": "that", "start": 549.98, "end": 550.48, "confidence": 0.97}, {"text": "are", "start": 550.48, "end": 550.54, "confidence": 0.991}, {"text": "also", "start": 550.54, "end": 551.28, "confidence": 0.974}, {"text": "efficient", "start": 551.28, "end": 551.38, "confidence": 0.586}, {"text": "and", "start": 551.38, "end": 551.74, "confidence": 0.987}, {"text": "sustainable,", "start": 551.74, "end": 552.12, "confidence": 0.508}, {"text": "using", "start": 552.8, "end": 552.94, "confidence": 0.915}, {"text": "far", "start": 552.94, "end": 553.32, "confidence": 0.99}, {"text": "less", "start": 553.32, "end": 553.46, "confidence": 0.892}, {"text": "energy", "start": 553.46, "end": 554.0, "confidence": 0.899}, {"text": "and", "start": 554.0, "end": 554.2, "confidence": 0.987}, {"text": "computational", "start": 554.2, "end": 554.64, "confidence": 0.804}, {"text": "resources", "start": 554.64, "end": 555.56, "confidence": 0.677}, {"text": "than", "start": 555.56, "end": 556.22, "confidence": 0.978}, {"text": "those", "start": 556.22, "end": 556.44, "confidence": 0.994}, {"text": "massive", "start": 556.44, "end": 557.04, "confidence": 0.978}, {"text": "models", "start": 557.04, "end": 557.52, "confidence": 0.931}, {"text": "we've", "start": 557.52, "end": 557.96, "confidence": 0.976}, {"text": "become", "start": 557.96, "end": 557.98, "confidence": 0.971}, {"text": "accustomed", "start": 557.98, "end": 558.28, "confidence": 0.435}, {"text": "to.", "start": 558.28, "end": 558.52, "confidence": 0.997}, {"text": "So", "start": 558.56, "end": 558.7, "confidence": 0.842}, {"text": "it's", "start": 558.7, "end": 558.8, "confidence": 0.986}, {"text": "not", "start": 558.8, "end": 558.94, "confidence": 0.966}, {"text": "just", "start": 558.94, "end": 559.1, "confidence": 0.994}, {"text": "about", "start": 559.1, "end": 559.82, "confidence": 0.98}, {"text": "making", "start": 559.82, "end": 560.44, "confidence": 0.976}, {"text": "AI", "start": 560.44, "end": 560.46, "confidence": 0.939}, {"text": "smarter.", "start": 560.46, "end": 561.24, "confidence": 0.85}]}, {"id": 31, "seek": 56214, "start": 562.64, "end": 564.5, "text": " It's about making it greener and more accessible too. That's fantastic.", "tokens": [50414, 467, 311, 466, 1455, 309, 3092, 260, 293, 544, 9515, 220, 32599, 13, 663, 311, 5456, 13, 50514], "temperature": 0.0, "avg_logprob": -0.18839599026574028, "compression_ratio": 1.6750700280112045, "no_speech_prob": 0.633701741695404, "confidence": 0.828, "words": [{"text": "It's", "start": 562.64, "end": 562.66, "confidence": 0.598}, {"text": "about", "start": 562.66, "end": 562.68, "confidence": 0.609}, {"text": "making", "start": 562.68, "end": 562.7, "confidence": 0.969}, {"text": "it", "start": 562.7, "end": 562.72, "confidence": 0.964}, {"text": "greener", "start": 562.72, "end": 562.86, "confidence": 0.971}, {"text": "and", "start": 562.86, "end": 563.1, "confidence": 0.984}, {"text": "more", "start": 563.1, "end": 563.12, "confidence": 0.986}, {"text": "accessible", "start": 563.12, "end": 563.56, "confidence": 0.671}, {"text": "too.", "start": 563.56, "end": 563.86, "confidence": 0.719}, {"text": "That's", "start": 563.86, "end": 564.04, "confidence": 0.976}, {"text": "fantastic.", "start": 564.04, "end": 564.5, "confidence": 0.954}]}, {"id": 32, "seek": 56214, "start": 564.64, "end": 574.2, "text": " Absolutely. This could democratize AI, making it available to smaller companies, research groups, even individuals who might not have access to these huge computing clusters.", "tokens": [50514, 7021, 13, 639, 727, 1371, 905, 4481, 1125, 7318, 11, 1455, 309, 2435, 220, 1353, 4356, 3431, 11, 2132, 3935, 11, 754, 1016, 592, 327, 901, 82, 567, 1062, 406, 362, 2105, 220, 1353, 220, 42678, 2603, 15866, 23313, 13, 51014], "temperature": 0.0, "avg_logprob": -0.18839599026574028, "compression_ratio": 1.6750700280112045, "no_speech_prob": 0.633701741695404, "confidence": 0.882, "words": [{"text": "Absolutely.", "start": 564.64, "end": 565.08, "confidence": 0.946}, {"text": "This", "start": 565.44, "end": 565.52, "confidence": 0.962}, {"text": "could", "start": 565.52, "end": 565.7, "confidence": 0.997}, {"text": "democratize", "start": 565.7, "end": 566.5, "confidence": 0.851}, {"text": "AI,", "start": 566.5, "end": 566.86, "confidence": 0.935}, {"text": "making", "start": 567.1, "end": 567.12, "confidence": 0.972}, {"text": "it", "start": 567.12, "end": 567.34, "confidence": 0.986}, {"text": "available", "start": 567.34, "end": 567.72, "confidence": 0.522}, {"text": "to", "start": 567.72, "end": 567.9, "confidence": 0.996}, {"text": "smaller", "start": 567.9, "end": 568.28, "confidence": 0.588}, {"text": "companies,", "start": 568.28, "end": 569.06, "confidence": 0.925}, {"text": "research", "start": 569.46, "end": 569.74, "confidence": 0.985}, {"text": "groups,", "start": 569.74, "end": 570.56, "confidence": 0.772}, {"text": "even", "start": 570.7, "end": 570.86, "confidence": 0.859}, {"text": "individuals", "start": 570.86, "end": 571.5, "confidence": 0.856}, {"text": "who", "start": 571.5, "end": 571.62, "confidence": 0.978}, {"text": "might", "start": 571.62, "end": 571.82, "confidence": 0.952}, {"text": "not", "start": 571.82, "end": 572.02, "confidence": 0.971}, {"text": "have", "start": 572.02, "end": 572.16, "confidence": 0.982}, {"text": "access", "start": 572.16, "end": 572.64, "confidence": 0.966}, {"text": "to", "start": 572.64, "end": 572.88, "confidence": 0.996}, {"text": "these", "start": 572.88, "end": 573.02, "confidence": 0.982}, {"text": "huge", "start": 573.02, "end": 573.44, "confidence": 0.938}, {"text": "computing", "start": 573.44, "end": 573.74, "confidence": 0.819}, {"text": "clusters.", "start": 573.74, "end": 574.2, "confidence": 0.535}]}, {"id": 33, "seek": 56214, "start": 574.64, "end": 581.58, "text": " Now, I remember you mentioned something about the researchers actually visualizing how information moves through these models. That sounds pretty mind-blowing.", "tokens": [51014, 823, 11, 286, 1604, 291, 3074, 313, 292, 746, 466, 220, 3322, 10309, 767, 5056, 3319, 577, 1589, 6067, 220, 11529, 220, 42678, 5245, 13, 663, 3263, 1238, 1575, 12, 43788, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18839599026574028, "compression_ratio": 1.6750700280112045, "no_speech_prob": 0.633701741695404, "confidence": 0.878, "words": [{"text": "Now,", "start": 574.64, "end": 574.66, "confidence": 0.667}, {"text": "I", "start": 574.78, "end": 574.82, "confidence": 0.62}, {"text": "remember", "start": 574.82, "end": 574.86, "confidence": 0.992}, {"text": "you", "start": 574.86, "end": 574.96, "confidence": 0.99}, {"text": "mentioned", "start": 574.96, "end": 575.38, "confidence": 0.573}, {"text": "something", "start": 575.38, "end": 575.52, "confidence": 0.941}, {"text": "about", "start": 575.52, "end": 576.04, "confidence": 0.979}, {"text": "the", "start": 576.04, "end": 576.26, "confidence": 0.977}, {"text": "researchers", "start": 576.26, "end": 576.82, "confidence": 0.868}, {"text": "actually", "start": 576.82, "end": 577.0, "confidence": 0.88}, {"text": "visualizing", "start": 577.0, "end": 577.66, "confidence": 0.993}, {"text": "how", "start": 577.66, "end": 578.38, "confidence": 0.989}, {"text": "information", "start": 578.38, "end": 578.96, "confidence": 0.856}, {"text": "moves", "start": 578.96, "end": 579.44, "confidence": 0.972}, {"text": "through", "start": 579.44, "end": 579.66, "confidence": 0.99}, {"text": "these", "start": 579.66, "end": 579.88, "confidence": 0.985}, {"text": "models.", "start": 579.88, "end": 580.24, "confidence": 0.932}, {"text": "That", "start": 580.44, "end": 580.64, "confidence": 0.957}, {"text": "sounds", "start": 580.64, "end": 580.9, "confidence": 0.957}, {"text": "pretty", "start": 580.9, "end": 581.14, "confidence": 0.958}, {"text": "mind-blowing.", "start": 581.14, "end": 581.58, "confidence": 0.896}]}, {"id": 34, "seek": 56214, "start": 581.72, "end": 591.62, "text": " It is. They tracked individual words as they were processed by the different experts, creating a visual map of the AI's thought process, so to speak. And what they discovered was fascinating.", "tokens": [51364, 467, 307, 13, 814, 220, 19466, 292, 2609, 2283, 382, 220, 13162, 645, 18846, 538, 220, 3322, 819, 8572, 11, 4084, 257, 5056, 4471, 295, 220, 3322, 7318, 311, 220, 43135, 1399, 11, 370, 220, 1353, 1710, 13, 400, 437, 220, 13162, 6941, 390, 10343, 13, 51814], "temperature": 0.0, "avg_logprob": -0.18839599026574028, "compression_ratio": 1.6750700280112045, "no_speech_prob": 0.633701741695404, "confidence": 0.9, "words": [{"text": "It", "start": 581.72, "end": 581.84, "confidence": 0.524}, {"text": "is.", "start": 581.84, "end": 582.48, "confidence": 0.986}, {"text": "They", "start": 582.6, "end": 582.7, "confidence": 0.959}, {"text": "tracked", "start": 582.7, "end": 583.4, "confidence": 0.843}, {"text": "individual", "start": 583.4, "end": 583.74, "confidence": 0.899}, {"text": "words", "start": 583.74, "end": 584.26, "confidence": 0.997}, {"text": "as", "start": 584.26, "end": 584.6, "confidence": 0.976}, {"text": "they", "start": 584.6, "end": 584.76, "confidence": 0.991}, {"text": "were", "start": 584.76, "end": 584.86, "confidence": 0.993}, {"text": "processed", "start": 584.86, "end": 585.42, "confidence": 0.403}, {"text": "by", "start": 585.42, "end": 585.56, "confidence": 0.989}, {"text": "the", "start": 585.56, "end": 585.74, "confidence": 0.996}, {"text": "different", "start": 585.74, "end": 585.94, "confidence": 0.95}, {"text": "experts,", "start": 585.94, "end": 586.46, "confidence": 0.861}, {"text": "creating", "start": 586.58, "end": 586.72, "confidence": 0.887}, {"text": "a", "start": 586.72, "end": 586.92, "confidence": 0.998}, {"text": "visual", "start": 586.92, "end": 587.26, "confidence": 0.991}, {"text": "map", "start": 587.26, "end": 587.7, "confidence": 0.939}, {"text": "of", "start": 587.7, "end": 587.84, "confidence": 0.992}, {"text": "the", "start": 587.84, "end": 588.02, "confidence": 0.997}, {"text": "AI's", "start": 588.02, "end": 588.48, "confidence": 0.939}, {"text": "thought", "start": 588.48, "end": 588.68, "confidence": 0.995}, {"text": "process,", "start": 588.68, "end": 589.16, "confidence": 0.899}, {"text": "so", "start": 589.16, "end": 589.32, "confidence": 0.97}, {"text": "to", "start": 589.32, "end": 589.5, "confidence": 0.99}, {"text": "speak.", "start": 589.5, "end": 589.68, "confidence": 0.995}, {"text": "And", "start": 589.84, "end": 590.1, "confidence": 0.893}, {"text": "what", "start": 590.1, "end": 590.28, "confidence": 0.994}, {"text": "they", "start": 590.28, "end": 590.52, "confidence": 0.993}, {"text": "discovered", "start": 590.52, "end": 590.94, "confidence": 0.439}, {"text": "was", "start": 590.94, "end": 591.3, "confidence": 0.938}, {"text": "fascinating.", "start": 591.3, "end": 591.62, "confidence": 0.739}]}, {"id": 35, "seek": 59214, "start": 592.64, "end": 606.79, "text": " What were those AI brains up to? The encoder experts, the ones responsible for processing the input, were highly specialized, as we've discussed. But when they looked at the decoder experts, the ones generating the output, they found something surprising.", "tokens": [50414, 708, 645, 220, 49833, 7318, 15442, 493, 220, 1353, 30, 440, 2058, 19866, 8572, 11, 220, 3322, 2306, 6250, 337, 9007, 220, 3322, 4846, 11, 645, 5405, 19813, 11, 382, 321, 600, 717, 2169, 292, 13, 583, 562, 220, 13162, 2956, 412, 220, 3322, 979, 19866, 8572, 11, 220, 3322, 2306, 17746, 220, 3322, 5598, 11, 220, 13162, 1352, 746, 8830, 13, 51114], "temperature": 0.0, "avg_logprob": -0.14373016357421875, "compression_ratio": 1.6502057613168724, "no_speech_prob": 0.8664528131484985, "confidence": 0.861, "words": [{"text": "What", "start": 592.64, "end": 592.82, "confidence": 0.127}, {"text": "were", "start": 592.82, "end": 593.04, "confidence": 0.554}, {"text": "those", "start": 593.04, "end": 593.24, "confidence": 0.843}, {"text": "AI", "start": 593.24, "end": 593.48, "confidence": 0.795}, {"text": "brains", "start": 593.48, "end": 593.94, "confidence": 0.882}, {"text": "up", "start": 593.94, "end": 594.0, "confidence": 0.99}, {"text": "to?", "start": 594.0, "end": 594.2, "confidence": 0.999}, {"text": "The", "start": 594.3, "end": 594.46, "confidence": 0.666}, {"text": "encoder", "start": 594.46, "end": 594.96, "confidence": 0.954}, {"text": "experts,", "start": 594.96, "end": 595.6, "confidence": 0.833}, {"text": "the", "start": 595.82, "end": 596.0, "confidence": 0.959}, {"text": "ones", "start": 596.0, "end": 596.22, "confidence": 0.989}, {"text": "responsible", "start": 596.22, "end": 596.74, "confidence": 0.788}, {"text": "for", "start": 596.74, "end": 597.0, "confidence": 0.997}, {"text": "processing", "start": 597.0, "end": 597.44, "confidence": 0.909}, {"text": "the", "start": 597.44, "end": 597.58, "confidence": 0.978}, {"text": "input,", "start": 597.58, "end": 598.0, "confidence": 0.961}, {"text": "were", "start": 598.0, "end": 598.4, "confidence": 0.987}, {"text": "highly", "start": 598.4, "end": 598.72, "confidence": 0.804}, {"text": "specialized,", "start": 598.72, "end": 599.4, "confidence": 0.478}, {"text": "as", "start": 599.4, "end": 599.46, "confidence": 0.814}, {"text": "we've", "start": 599.46, "end": 599.68, "confidence": 0.987}, {"text": "discussed.", "start": 599.68, "end": 600.2, "confidence": 0.724}, {"text": "But", "start": 600.46, "end": 600.56, "confidence": 0.881}, {"text": "when", "start": 600.56, "end": 600.72, "confidence": 0.984}, {"text": "they", "start": 600.72, "end": 600.86, "confidence": 0.989}, {"text": "looked", "start": 600.86, "end": 601.08, "confidence": 0.881}, {"text": "at", "start": 601.08, "end": 601.26, "confidence": 0.991}, {"text": "the", "start": 601.26, "end": 601.42, "confidence": 0.997}, {"text": "decoder", "start": 601.42, "end": 601.98, "confidence": 0.971}, {"text": "experts,", "start": 601.98, "end": 602.66, "confidence": 0.886}, {"text": "the", "start": 602.8, "end": 603.16, "confidence": 0.976}, {"text": "ones", "start": 603.16, "end": 603.34, "confidence": 0.988}, {"text": "generating", "start": 603.34, "end": 603.82, "confidence": 0.548}, {"text": "the", "start": 603.82, "end": 604.12, "confidence": 0.997}, {"text": "output,", "start": 604.12, "end": 604.6, "confidence": 0.958}, {"text": "they", "start": 605.4, "end": 605.46, "confidence": 0.983}, {"text": "found", "start": 605.46, "end": 605.7, "confidence": 0.993}, {"text": "something", "start": 605.7, "end": 606.16, "confidence": 0.952}, {"text": "surprising.", "start": 606.16, "end": 606.79, "confidence": 0.944}]}, {"id": 36, "seek": 59214, "start": 606.79, "end": 615.5, "text": " Let me guess. They weren't as specialized? Exactly. The decoder experts seem to be more generalists, comfortable handling a wider range of tasks.", "tokens": [51114, 961, 385, 2041, 13, 814, 4999, 380, 382, 19813, 30, 7587, 13, 440, 979, 19866, 8572, 1643, 220, 1353, 312, 544, 2674, 1751, 11, 4619, 13175, 257, 11842, 3613, 295, 220, 83, 296, 1694, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14373016357421875, "compression_ratio": 1.6502057613168724, "no_speech_prob": 0.8664528131484985, "confidence": 0.923, "words": [{"text": "Let", "start": 606.79, "end": 607.2, "confidence": 0.896}, {"text": "me", "start": 607.2, "end": 607.3, "confidence": 0.999}, {"text": "guess.", "start": 607.3, "end": 607.54, "confidence": 0.992}, {"text": "They", "start": 607.74, "end": 607.88, "confidence": 0.971}, {"text": "weren't", "start": 607.88, "end": 608.02, "confidence": 0.961}, {"text": "as", "start": 608.02, "end": 608.16, "confidence": 0.985}, {"text": "specialized?", "start": 608.16, "end": 608.76, "confidence": 0.466}, {"text": "Exactly.", "start": 608.94, "end": 609.44, "confidence": 0.884}, {"text": "The", "start": 610.1, "end": 610.2, "confidence": 0.947}, {"text": "decoder", "start": 610.2, "end": 610.62, "confidence": 0.979}, {"text": "experts", "start": 610.62, "end": 611.04, "confidence": 0.873}, {"text": "seem", "start": 611.04, "end": 611.34, "confidence": 0.647}, {"text": "to", "start": 611.34, "end": 611.4, "confidence": 0.975}, {"text": "be", "start": 611.4, "end": 611.54, "confidence": 0.995}, {"text": "more", "start": 611.54, "end": 611.86, "confidence": 0.975}, {"text": "generalists,", "start": 611.86, "end": 612.8, "confidence": 0.979}, {"text": "comfortable", "start": 613.2, "end": 613.5, "confidence": 0.95}, {"text": "handling", "start": 613.5, "end": 614.0, "confidence": 0.969}, {"text": "a", "start": 614.0, "end": 614.42, "confidence": 0.994}, {"text": "wider", "start": 614.42, "end": 614.58, "confidence": 0.979}, {"text": "range", "start": 614.58, "end": 614.88, "confidence": 0.763}, {"text": "of", "start": 614.88, "end": 615.06, "confidence": 0.981}, {"text": "tasks.", "start": 615.06, "end": 615.5, "confidence": 0.982}]}, {"id": 37, "seek": 62214, "start": 623.92, "end": 635.18, "text": " That's a question that has researchers scratching their heads. Does it reflect something fundamental about the nature of language itself? Or is it just an artifact of the way these models are currently trained?", "tokens": [50414, 663, 311, 257, 1168, 220, 6780, 575, 10309, 29699, 220, 3322, 347, 8050, 13, 4402, 309, 5031, 746, 8088, 466, 220, 3322, 3687, 295, 2856, 2564, 30, 1610, 307, 309, 445, 364, 34806, 295, 220, 3322, 636, 220, 42678, 5245, 366, 1262, 1753, 356, 220, 17227, 2001, 30, 51014], "temperature": 0.0, "avg_logprob": -0.09796895186106364, "compression_ratio": 1.5967213114754097, "no_speech_prob": 0.7737557291984558, "confidence": 0.908, "words": [{"text": "That's", "start": 623.92, "end": 625.32, "confidence": 0.703}, {"text": "a", "start": 625.32, "end": 625.36, "confidence": 0.978}, {"text": "question", "start": 625.36, "end": 625.68, "confidence": 0.933}, {"text": "that", "start": 625.68, "end": 625.86, "confidence": 0.994}, {"text": "has", "start": 625.86, "end": 625.98, "confidence": 0.972}, {"text": "researchers", "start": 625.98, "end": 626.46, "confidence": 0.873}, {"text": "scratching", "start": 626.46, "end": 626.78, "confidence": 0.76}, {"text": "their", "start": 626.78, "end": 626.96, "confidence": 0.997}, {"text": "heads.", "start": 626.96, "end": 627.26, "confidence": 0.974}, {"text": "Does", "start": 627.6, "end": 627.78, "confidence": 0.971}, {"text": "it", "start": 627.78, "end": 628.04, "confidence": 0.986}, {"text": "reflect", "start": 628.04, "end": 628.2, "confidence": 0.699}, {"text": "something", "start": 628.2, "end": 628.52, "confidence": 0.943}, {"text": "fundamental", "start": 628.52, "end": 629.46, "confidence": 0.945}, {"text": "about", "start": 629.46, "end": 629.76, "confidence": 0.973}, {"text": "the", "start": 629.76, "end": 629.9, "confidence": 0.997}, {"text": "nature", "start": 629.9, "end": 630.26, "confidence": 0.949}, {"text": "of", "start": 630.26, "end": 630.38, "confidence": 0.992}, {"text": "language", "start": 630.38, "end": 630.88, "confidence": 0.85}, {"text": "itself?", "start": 630.88, "end": 631.6, "confidence": 0.657}, {"text": "Or", "start": 631.62, "end": 632.08, "confidence": 0.987}, {"text": "is", "start": 632.08, "end": 632.38, "confidence": 0.957}, {"text": "it", "start": 632.38, "end": 632.44, "confidence": 0.978}, {"text": "just", "start": 632.44, "end": 632.66, "confidence": 0.973}, {"text": "an", "start": 632.66, "end": 632.82, "confidence": 0.982}, {"text": "artifact", "start": 632.82, "end": 633.4, "confidence": 0.825}, {"text": "of", "start": 633.4, "end": 633.56, "confidence": 0.987}, {"text": "the", "start": 633.56, "end": 633.68, "confidence": 0.991}, {"text": "way", "start": 633.68, "end": 633.74, "confidence": 0.996}, {"text": "these", "start": 633.74, "end": 633.98, "confidence": 0.941}, {"text": "models", "start": 633.98, "end": 634.34, "confidence": 0.956}, {"text": "are", "start": 634.34, "end": 634.38, "confidence": 0.99}, {"text": "currently", "start": 634.38, "end": 634.8, "confidence": 0.669}, {"text": "trained?", "start": 634.8, "end": 635.18, "confidence": 0.964}]}, {"id": 38, "seek": 62214, "start": 635.58, "end": 642.45, "text": " It's like we've opened up this black box of AI. And instead of finding these simple answers, we've discovered a whole new set of mysteries.", "tokens": [51014, 467, 311, 411, 321, 600, 5625, 493, 220, 11176, 2211, 2424, 295, 7318, 13, 400, 2602, 295, 5006, 220, 42678, 2199, 6338, 11, 321, 600, 3622, 5887, 67, 257, 1379, 777, 992, 295, 30785, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09796895186106364, "compression_ratio": 1.5967213114754097, "no_speech_prob": 0.7737557291984558, "confidence": 0.933, "words": [{"text": "It's", "start": 635.58, "end": 635.8, "confidence": 0.97}, {"text": "like", "start": 635.8, "end": 635.86, "confidence": 0.989}, {"text": "we've", "start": 635.86, "end": 636.06, "confidence": 0.976}, {"text": "opened", "start": 636.06, "end": 636.42, "confidence": 0.934}, {"text": "up", "start": 636.42, "end": 636.6, "confidence": 0.975}, {"text": "this", "start": 636.6, "end": 636.68, "confidence": 0.995}, {"text": "black", "start": 636.68, "end": 637.08, "confidence": 0.989}, {"text": "box", "start": 637.08, "end": 637.44, "confidence": 0.976}, {"text": "of", "start": 637.44, "end": 637.62, "confidence": 0.994}, {"text": "AI.", "start": 637.62, "end": 638.02, "confidence": 0.984}, {"text": "And", "start": 638.46, "end": 638.54, "confidence": 0.981}, {"text": "instead", "start": 638.54, "end": 638.76, "confidence": 0.959}, {"text": "of", "start": 638.76, "end": 638.86, "confidence": 0.993}, {"text": "finding", "start": 638.86, "end": 639.18, "confidence": 0.929}, {"text": "these", "start": 639.18, "end": 639.34, "confidence": 0.959}, {"text": "simple", "start": 639.34, "end": 639.68, "confidence": 0.99}, {"text": "answers,", "start": 639.68, "end": 640.5, "confidence": 0.946}, {"text": "we've", "start": 640.66, "end": 640.78, "confidence": 0.987}, {"text": "discovered", "start": 640.78, "end": 641.1, "confidence": 0.625}, {"text": "a", "start": 641.1, "end": 641.16, "confidence": 0.996}, {"text": "whole", "start": 641.16, "end": 641.38, "confidence": 0.964}, {"text": "new", "start": 641.38, "end": 641.64, "confidence": 0.962}, {"text": "set", "start": 641.64, "end": 641.8, "confidence": 0.967}, {"text": "of", "start": 641.8, "end": 641.96, "confidence": 0.996}, {"text": "mysteries.", "start": 641.96, "end": 642.45, "confidence": 0.896}]}, {"id": 39, "seek": 62214, "start": 642.45, "end": 648.88, "text": " That's the beauty of scientific exploration. Every answer leads to more questions, pushing us further down the rabbit hole of knowledge.", "tokens": [51364, 663, 311, 220, 3322, 6643, 295, 2180, 317, 1089, 16197, 13, 2048, 1867, 6689, 220, 1353, 544, 1651, 11, 7380, 505, 3052, 760, 220, 3322, 19509, 5458, 295, 3601, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09796895186106364, "compression_ratio": 1.5967213114754097, "no_speech_prob": 0.7737557291984558, "confidence": 0.92, "words": [{"text": "That's", "start": 642.45, "end": 642.88, "confidence": 0.963}, {"text": "the", "start": 642.88, "end": 642.96, "confidence": 0.998}, {"text": "beauty", "start": 642.96, "end": 643.24, "confidence": 0.963}, {"text": "of", "start": 643.24, "end": 643.38, "confidence": 0.994}, {"text": "scientific", "start": 643.38, "end": 643.94, "confidence": 0.665}, {"text": "exploration.", "start": 643.94, "end": 644.56, "confidence": 0.974}, {"text": "Every", "start": 644.8, "end": 644.92, "confidence": 0.974}, {"text": "answer", "start": 644.92, "end": 645.26, "confidence": 0.927}, {"text": "leads", "start": 645.26, "end": 645.48, "confidence": 0.92}, {"text": "to", "start": 645.48, "end": 645.64, "confidence": 0.997}, {"text": "more", "start": 645.64, "end": 645.8, "confidence": 0.989}, {"text": "questions,", "start": 645.8, "end": 646.46, "confidence": 0.987}, {"text": "pushing", "start": 646.86, "end": 647.04, "confidence": 0.88}, {"text": "us", "start": 647.04, "end": 647.24, "confidence": 0.982}, {"text": "further", "start": 647.24, "end": 647.58, "confidence": 0.903}, {"text": "down", "start": 647.58, "end": 647.84, "confidence": 0.991}, {"text": "the", "start": 647.84, "end": 647.98, "confidence": 0.996}, {"text": "rabbit", "start": 647.98, "end": 648.28, "confidence": 0.855}, {"text": "hole", "start": 648.28, "end": 648.36, "confidence": 0.959}, {"text": "of", "start": 648.36, "end": 648.5, "confidence": 0.993}, {"text": "knowledge.", "start": 648.5, "end": 648.88, "confidence": 0.836}]}, {"id": 40, "seek": 65214, "start": 652.64, "end": 660.22, "text": " But what about the intriguing finding about multilingualism, those experts stubbornly refusing to specialize by language? What are the implications of that?", "tokens": [50414, 583, 437, 466, 220, 3322, 32503, 5006, 466, 2120, 4883, 901, 1434, 11, 220, 49833, 8572, 20266, 10324, 356, 37289, 220, 1353, 37938, 538, 2856, 30, 708, 366, 220, 3322, 8484, 24847, 295, 220, 6780, 30, 50764], "temperature": 0.0, "avg_logprob": -0.1629098093407786, "compression_ratio": 1.6723549488054608, "no_speech_prob": 0.6752110719680786, "confidence": 0.78, "words": [{"text": "But", "start": 652.64, "end": 652.66, "confidence": 0.12}, {"text": "what", "start": 652.66, "end": 652.68, "confidence": 0.177}, {"text": "about", "start": 652.68, "end": 652.7, "confidence": 0.554}, {"text": "the", "start": 652.7, "end": 652.72, "confidence": 0.717}, {"text": "intriguing", "start": 652.72, "end": 652.74, "confidence": 0.475}, {"text": "finding", "start": 652.74, "end": 653.0, "confidence": 0.972}, {"text": "about", "start": 653.0, "end": 653.28, "confidence": 0.968}, {"text": "multilingualism,", "start": 653.28, "end": 654.44, "confidence": 0.918}, {"text": "those", "start": 654.54, "end": 654.66, "confidence": 0.956}, {"text": "experts", "start": 654.66, "end": 655.18, "confidence": 0.931}, {"text": "stubbornly", "start": 655.18, "end": 656.0, "confidence": 0.876}, {"text": "refusing", "start": 656.0, "end": 656.68, "confidence": 0.942}, {"text": "to", "start": 656.68, "end": 657.0, "confidence": 0.998}, {"text": "specialize", "start": 657.0, "end": 657.5, "confidence": 0.896}, {"text": "by", "start": 657.5, "end": 657.6, "confidence": 0.969}, {"text": "language?", "start": 657.6, "end": 658.0, "confidence": 0.875}, {"text": "What", "start": 658.52, "end": 658.92, "confidence": 0.975}, {"text": "are", "start": 658.92, "end": 659.1, "confidence": 0.984}, {"text": "the", "start": 659.1, "end": 659.2, "confidence": 0.999}, {"text": "implications", "start": 659.2, "end": 659.7, "confidence": 0.618}, {"text": "of", "start": 659.7, "end": 659.92, "confidence": 0.966}, {"text": "that?", "start": 659.92, "end": 660.22, "confidence": 0.997}]}, {"id": 41, "seek": 65214, "start": 660.28, "end": 678.84, "text": " This is where things get really interesting. Does this mean that at some deep level, all languages share a common structure, a universal grammar that underlies the incredible diversity of human communication? Or is it simply a consequence of how these models are trained, pushing them towards a more generalized approach to language?", "tokens": [50764, 639, 307, 689, 220, 825, 82, 483, 534, 728, 8714, 13, 4402, 220, 11176, 914, 220, 6780, 412, 512, 2452, 1496, 11, 439, 8650, 2073, 257, 2689, 342, 894, 42919, 11, 257, 11455, 21353, 6209, 220, 6780, 833, 24119, 220, 3322, 4651, 8811, 295, 1952, 6101, 30, 1610, 307, 309, 2935, 257, 18326, 295, 577, 220, 42678, 5245, 366, 8895, 11, 7380, 220, 47959, 220, 83, 305, 2287, 257, 544, 44498, 3109, 220, 1353, 2856, 30, 51714], "temperature": 0.0, "avg_logprob": -0.1629098093407786, "compression_ratio": 1.6723549488054608, "no_speech_prob": 0.6752110719680786, "confidence": 0.904, "words": [{"text": "This", "start": 660.28, "end": 660.46, "confidence": 0.863}, {"text": "is", "start": 660.46, "end": 660.66, "confidence": 0.983}, {"text": "where", "start": 660.66, "end": 660.72, "confidence": 0.997}, {"text": "things", "start": 660.72, "end": 660.98, "confidence": 0.996}, {"text": "get", "start": 660.98, "end": 661.0, "confidence": 0.985}, {"text": "really", "start": 661.0, "end": 661.26, "confidence": 0.913}, {"text": "interesting.", "start": 661.26, "end": 661.78, "confidence": 0.692}, {"text": "Does", "start": 662.18, "end": 662.24, "confidence": 0.923}, {"text": "this", "start": 662.24, "end": 662.44, "confidence": 0.996}, {"text": "mean", "start": 662.44, "end": 662.7, "confidence": 0.983}, {"text": "that", "start": 662.7, "end": 663.06, "confidence": 0.982}, {"text": "at", "start": 663.06, "end": 663.82, "confidence": 0.675}, {"text": "some", "start": 663.82, "end": 664.14, "confidence": 0.778}, {"text": "deep", "start": 664.14, "end": 664.44, "confidence": 0.938}, {"text": "level,", "start": 664.44, "end": 664.74, "confidence": 0.951}, {"text": "all", "start": 665.5, "end": 665.52, "confidence": 0.989}, {"text": "languages", "start": 665.52, "end": 666.06, "confidence": 0.829}, {"text": "share", "start": 666.06, "end": 666.34, "confidence": 0.959}, {"text": "a", "start": 666.34, "end": 666.5, "confidence": 0.998}, {"text": "common", "start": 666.5, "end": 666.8, "confidence": 0.947}, {"text": "structure,", "start": 666.8, "end": 667.58, "confidence": 0.84}, {"text": "a", "start": 667.94, "end": 667.96, "confidence": 0.982}, {"text": "universal", "start": 667.96, "end": 668.5, "confidence": 0.945}, {"text": "grammar", "start": 668.5, "end": 668.72, "confidence": 0.741}, {"text": "that", "start": 668.72, "end": 669.02, "confidence": 0.973}, {"text": "underlies", "start": 669.02, "end": 669.38, "confidence": 0.987}, {"text": "the", "start": 669.38, "end": 669.52, "confidence": 0.998}, {"text": "incredible", "start": 669.52, "end": 670.12, "confidence": 0.969}, {"text": "diversity", "start": 670.12, "end": 670.62, "confidence": 0.682}, {"text": "of", "start": 670.62, "end": 671.12, "confidence": 0.99}, {"text": "human", "start": 671.12, "end": 671.14, "confidence": 0.966}, {"text": "communication?", "start": 671.14, "end": 671.72, "confidence": 0.836}, {"text": "Or", "start": 672.68, "end": 672.7, "confidence": 0.858}, {"text": "is", "start": 672.7, "end": 672.84, "confidence": 0.969}, {"text": "it", "start": 672.84, "end": 672.92, "confidence": 0.974}, {"text": "simply", "start": 672.92, "end": 673.28, "confidence": 0.927}, {"text": "a", "start": 673.28, "end": 673.44, "confidence": 0.994}, {"text": "consequence", "start": 673.44, "end": 674.14, "confidence": 0.982}, {"text": "of", "start": 674.14, "end": 674.32, "confidence": 0.989}, {"text": "how", "start": 674.32, "end": 674.72, "confidence": 0.982}, {"text": "these", "start": 674.72, "end": 674.9, "confidence": 0.981}, {"text": "models", "start": 674.9, "end": 675.38, "confidence": 0.923}, {"text": "are", "start": 675.38, "end": 675.4, "confidence": 0.984}, {"text": "trained,", "start": 675.4, "end": 675.8, "confidence": 0.251}, {"text": "pushing", "start": 676.14, "end": 676.2, "confidence": 0.838}, {"text": "them", "start": 676.2, "end": 676.48, "confidence": 0.98}, {"text": "towards", "start": 676.48, "end": 676.74, "confidence": 0.94}, {"text": "a", "start": 676.74, "end": 676.76, "confidence": 0.964}, {"text": "more", "start": 676.76, "end": 677.22, "confidence": 0.983}, {"text": "generalized", "start": 677.22, "end": 677.72, "confidence": 0.742}, {"text": "approach", "start": 677.72, "end": 678.14, "confidence": 0.95}, {"text": "to", "start": 678.14, "end": 678.36, "confidence": 0.987}, {"text": "language?", "start": 678.36, "end": 678.84, "confidence": 0.811}]}, {"id": 42, "seek": 68214, "start": 682.64, "end": 701.34, "text": " So we have AI that can effortlessly translate between any language, decipher ancient texts, even maybe help us understand how language evolved in the first place. But if it's just an artifact of the training process, then the question becomes, can we change that process? Can we guide those experts towards more specialized linguistic skills?", "tokens": [50414, 407, 321, 362, 7318, 220, 6780, 393, 4630, 12048, 220, 24999, 17593, 1296, 604, 2856, 11, 49859, 7832, 220, 25111, 82, 11, 754, 1310, 854, 505, 1223, 577, 2856, 1073, 37361, 67, 294, 220, 3322, 700, 1081, 13, 583, 498, 309, 311, 445, 364, 34806, 295, 220, 3322, 220, 17227, 1760, 1399, 11, 220, 19096, 220, 3322, 1168, 3643, 11, 393, 321, 1319, 220, 6780, 1399, 30, 1664, 321, 5934, 220, 49833, 8572, 220, 83, 305, 2287, 544, 768, 1013, 1602, 22949, 84, 3142, 3942, 30, 51314], "temperature": 0.0, "avg_logprob": -0.17205182059866483, "compression_ratio": 1.6501650165016502, "no_speech_prob": 0.8276246190071106, "confidence": 0.823, "words": [{"text": "So", "start": 682.64, "end": 682.66, "confidence": 0.063}, {"text": "we", "start": 682.66, "end": 682.68, "confidence": 0.177}, {"text": "have", "start": 682.68, "end": 682.7, "confidence": 0.129}, {"text": "AI", "start": 682.7, "end": 682.72, "confidence": 0.14}, {"text": "that", "start": 682.72, "end": 683.18, "confidence": 0.916}, {"text": "can", "start": 683.18, "end": 683.28, "confidence": 0.984}, {"text": "effortlessly", "start": 683.28, "end": 683.8, "confidence": 0.96}, {"text": "translate", "start": 683.8, "end": 684.44, "confidence": 0.984}, {"text": "between", "start": 684.44, "end": 684.68, "confidence": 0.945}, {"text": "any", "start": 684.68, "end": 684.92, "confidence": 0.959}, {"text": "language,", "start": 684.92, "end": 685.36, "confidence": 0.854}, {"text": "decipher", "start": 686.64, "end": 686.66, "confidence": 0.964}, {"text": "ancient", "start": 686.66, "end": 687.0, "confidence": 0.924}, {"text": "texts,", "start": 687.0, "end": 687.84, "confidence": 0.876}, {"text": "even", "start": 688.26, "end": 688.36, "confidence": 0.728}, {"text": "maybe", "start": 688.36, "end": 688.66, "confidence": 0.943}, {"text": "help", "start": 688.66, "end": 689.06, "confidence": 0.966}, {"text": "us", "start": 689.06, "end": 689.16, "confidence": 0.983}, {"text": "understand", "start": 689.16, "end": 689.6, "confidence": 0.92}, {"text": "how", "start": 689.6, "end": 690.6, "confidence": 0.988}, {"text": "language", "start": 690.6, "end": 690.62, "confidence": 0.856}, {"text": "evolved", "start": 690.62, "end": 691.0, "confidence": 0.578}, {"text": "in", "start": 691.0, "end": 691.26, "confidence": 0.981}, {"text": "the", "start": 691.26, "end": 691.28, "confidence": 0.999}, {"text": "first", "start": 691.28, "end": 691.36, "confidence": 0.971}, {"text": "place.", "start": 691.36, "end": 691.72, "confidence": 0.991}, {"text": "But", "start": 692.0, "end": 692.12, "confidence": 0.934}, {"text": "if", "start": 692.12, "end": 692.3, "confidence": 0.98}, {"text": "it's", "start": 692.3, "end": 692.32, "confidence": 0.992}, {"text": "just", "start": 692.32, "end": 692.52, "confidence": 0.984}, {"text": "an", "start": 692.52, "end": 692.76, "confidence": 0.989}, {"text": "artifact", "start": 692.76, "end": 693.16, "confidence": 0.776}, {"text": "of", "start": 693.16, "end": 693.34, "confidence": 0.971}, {"text": "the", "start": 693.34, "end": 693.36, "confidence": 0.998}, {"text": "training", "start": 693.36, "end": 693.68, "confidence": 0.946}, {"text": "process,", "start": 693.68, "end": 694.46, "confidence": 0.945}, {"text": "then", "start": 695.22, "end": 695.24, "confidence": 0.955}, {"text": "the", "start": 695.24, "end": 695.26, "confidence": 0.998}, {"text": "question", "start": 695.26, "end": 695.28, "confidence": 0.953}, {"text": "becomes,", "start": 695.28, "end": 695.9, "confidence": 0.911}, {"text": "can", "start": 696.3, "end": 696.36, "confidence": 0.971}, {"text": "we", "start": 696.36, "end": 696.56, "confidence": 0.994}, {"text": "change", "start": 696.56, "end": 697.02, "confidence": 0.977}, {"text": "that", "start": 697.02, "end": 697.2, "confidence": 0.997}, {"text": "process?", "start": 697.2, "end": 697.98, "confidence": 0.956}, {"text": "Can", "start": 697.98, "end": 698.22, "confidence": 0.942}, {"text": "we", "start": 698.22, "end": 698.36, "confidence": 0.99}, {"text": "guide", "start": 698.36, "end": 698.76, "confidence": 0.983}, {"text": "those", "start": 698.76, "end": 698.94, "confidence": 0.993}, {"text": "experts", "start": 698.94, "end": 699.44, "confidence": 0.891}, {"text": "towards", "start": 699.44, "end": 699.68, "confidence": 0.975}, {"text": "more", "start": 699.68, "end": 700.02, "confidence": 0.987}, {"text": "specialized", "start": 700.02, "end": 700.44, "confidence": 0.797}, {"text": "linguistic", "start": 700.44, "end": 700.98, "confidence": 0.639}, {"text": "skills?", "start": 700.98, "end": 701.34, "confidence": 0.963}]}, {"id": 43, "seek": 68214, "start": 701.76, "end": 709.9, "text": " Those are questions that will drive AI research for years to come. And the answers could reshape our understanding of both artificial and human intelligence.", "tokens": [51314, 3950, 366, 1651, 220, 6780, 486, 3332, 7318, 2132, 337, 924, 220, 1353, 808, 13, 400, 220, 3322, 6338, 727, 725, 42406, 527, 3701, 295, 1293, 11677, 293, 1952, 7599, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17205182059866483, "compression_ratio": 1.6501650165016502, "no_speech_prob": 0.8276246190071106, "confidence": 0.919, "words": [{"text": "Those", "start": 701.76, "end": 701.98, "confidence": 0.924}, {"text": "are", "start": 701.98, "end": 702.14, "confidence": 0.989}, {"text": "questions", "start": 702.14, "end": 702.46, "confidence": 0.99}, {"text": "that", "start": 702.46, "end": 702.78, "confidence": 0.997}, {"text": "will", "start": 702.78, "end": 702.92, "confidence": 0.997}, {"text": "drive", "start": 702.92, "end": 703.1, "confidence": 0.979}, {"text": "AI", "start": 703.1, "end": 703.4, "confidence": 0.949}, {"text": "research", "start": 703.4, "end": 703.94, "confidence": 0.985}, {"text": "for", "start": 703.94, "end": 704.04, "confidence": 0.998}, {"text": "years", "start": 704.04, "end": 704.44, "confidence": 0.985}, {"text": "to", "start": 704.44, "end": 704.72, "confidence": 0.999}, {"text": "come.", "start": 704.72, "end": 705.08, "confidence": 0.997}, {"text": "And", "start": 705.18, "end": 705.48, "confidence": 0.975}, {"text": "the", "start": 705.48, "end": 705.64, "confidence": 0.998}, {"text": "answers", "start": 705.64, "end": 706.02, "confidence": 0.942}, {"text": "could", "start": 706.02, "end": 706.16, "confidence": 0.996}, {"text": "reshape", "start": 706.16, "end": 706.76, "confidence": 0.804}, {"text": "our", "start": 706.76, "end": 706.92, "confidence": 0.984}, {"text": "understanding", "start": 706.92, "end": 707.58, "confidence": 0.445}, {"text": "of", "start": 707.58, "end": 707.88, "confidence": 0.988}, {"text": "both", "start": 707.88, "end": 708.18, "confidence": 0.863}, {"text": "artificial", "start": 708.18, "end": 708.68, "confidence": 0.815}, {"text": "and", "start": 708.68, "end": 709.02, "confidence": 0.99}, {"text": "human", "start": 709.02, "end": 709.4, "confidence": 0.963}, {"text": "intelligence.", "start": 709.4, "end": 709.9, "confidence": 0.627}]}, {"id": 44, "seek": 71214, "start": 712.92, "end": 715.98, "text": " Let's take a moment to recap what we've learned about STEM OE.", "tokens": [50414, 961, 311, 220, 27612, 257, 1623, 220, 1353, 20928, 437, 321, 600, 3264, 466, 4904, 6683, 422, 36, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1985220258886164, "compression_ratio": 0.9117647058823529, "no_speech_prob": 0.8668889403343201, "confidence": 0.84, "words": [{"text": "Let's", "start": 712.92, "end": 713.32, "confidence": 0.735}, {"text": "take", "start": 713.32, "end": 713.54, "confidence": 0.909}, {"text": "a", "start": 713.54, "end": 713.7, "confidence": 0.989}, {"text": "moment", "start": 713.7, "end": 713.92, "confidence": 0.975}, {"text": "to", "start": 713.92, "end": 714.14, "confidence": 0.978}, {"text": "recap", "start": 714.14, "end": 714.52, "confidence": 0.959}, {"text": "what", "start": 714.52, "end": 714.68, "confidence": 0.976}, {"text": "we've", "start": 714.68, "end": 714.9, "confidence": 0.937}, {"text": "learned", "start": 714.9, "end": 715.14, "confidence": 0.977}, {"text": "about", "start": 715.14, "end": 715.28, "confidence": 0.953}, {"text": "STEM", "start": 715.28, "end": 715.66, "confidence": 0.488}, {"text": "OE.", "start": 715.66, "end": 715.98, "confidence": 0.758}]}, {"id": 45, "seek": 74214, "start": 742.64, "end": 753.94, "text": " We've delved into some of the fascinating questions raised by this research, such as the specialization of encoder versus decoder experts, and the surprising lack of language specialization when trained on multilingual data.", "tokens": [50414, 492, 600, 1103, 937, 666, 512, 295, 220, 3322, 10343, 1651, 6005, 538, 220, 11176, 2132, 11, 1270, 382, 220, 3322, 2121, 2144, 295, 2058, 19866, 5717, 979, 19866, 8572, 11, 293, 220, 3322, 8830, 5011, 295, 2856, 2121, 2144, 562, 220, 17227, 2001, 322, 2120, 4883, 901, 1412, 13, 50964], "temperature": 0.0, "avg_logprob": -0.12848087526717275, "compression_ratio": 1.4933333333333334, "no_speech_prob": 0.8580923080444336, "confidence": 0.902, "words": [{"text": "We've", "start": 742.64, "end": 742.66, "confidence": 0.407}, {"text": "delved", "start": 742.66, "end": 742.68, "confidence": 0.85}, {"text": "into", "start": 742.68, "end": 742.72, "confidence": 0.913}, {"text": "some", "start": 742.72, "end": 742.88, "confidence": 0.848}, {"text": "of", "start": 742.88, "end": 742.9, "confidence": 0.984}, {"text": "the", "start": 742.9, "end": 742.92, "confidence": 0.999}, {"text": "fascinating", "start": 742.92, "end": 743.5, "confidence": 0.777}, {"text": "questions", "start": 743.5, "end": 744.02, "confidence": 0.988}, {"text": "raised", "start": 744.02, "end": 744.34, "confidence": 0.844}, {"text": "by", "start": 744.34, "end": 744.56, "confidence": 0.984}, {"text": "this", "start": 744.56, "end": 744.74, "confidence": 0.991}, {"text": "research,", "start": 744.74, "end": 745.44, "confidence": 0.989}, {"text": "such", "start": 745.76, "end": 745.8, "confidence": 0.976}, {"text": "as", "start": 745.8, "end": 745.98, "confidence": 0.981}, {"text": "the", "start": 745.98, "end": 746.04, "confidence": 0.994}, {"text": "specialization", "start": 746.04, "end": 746.82, "confidence": 0.984}, {"text": "of", "start": 746.82, "end": 747.12, "confidence": 0.992}, {"text": "encoder", "start": 747.12, "end": 747.58, "confidence": 0.936}, {"text": "versus", "start": 747.58, "end": 747.86, "confidence": 0.907}, {"text": "decoder", "start": 747.86, "end": 748.44, "confidence": 0.978}, {"text": "experts,", "start": 748.44, "end": 749.02, "confidence": 0.868}, {"text": "and", "start": 749.16, "end": 749.44, "confidence": 0.984}, {"text": "the", "start": 749.44, "end": 749.6, "confidence": 0.998}, {"text": "surprising", "start": 749.6, "end": 750.2, "confidence": 0.972}, {"text": "lack", "start": 750.2, "end": 750.66, "confidence": 0.814}, {"text": "of", "start": 750.66, "end": 750.9, "confidence": 0.992}, {"text": "language", "start": 750.9, "end": 751.16, "confidence": 0.898}, {"text": "specialization", "start": 751.16, "end": 751.9, "confidence": 0.992}, {"text": "when", "start": 751.9, "end": 752.2, "confidence": 0.978}, {"text": "trained", "start": 752.2, "end": 752.64, "confidence": 0.853}, {"text": "on", "start": 752.64, "end": 752.92, "confidence": 0.991}, {"text": "multilingual", "start": 752.92, "end": 753.56, "confidence": 0.835}, {"text": "data.", "start": 753.56, "end": 753.94, "confidence": 0.974}]}, {"id": 46, "seek": 77214, "start": 772.88, "end": 786.12, "text": " Not necessarily. Think of it this way. Sparsity allows us to do more with less. It's like optimizing the layout of a city. Instead of sprawling suburbs, we're building these dense, interconnected urban centers.", "tokens": [50414, 1726, 4725, 13, 6557, 295, 309, 220, 11176, 636, 13, 1738, 685, 507, 4045, 505, 220, 1353, 360, 544, 365, 1570, 13, 467, 311, 411, 40425, 220, 3322, 13333, 295, 257, 2307, 13, 7156, 295, 637, 424, 86, 1688, 34185, 11, 321, 434, 2390, 220, 42678, 24505, 68, 11, 36611, 9681, 10898, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11929782231648763, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.8544510006904602, "confidence": 0.908, "words": [{"text": "Not", "start": 772.88, "end": 773.38, "confidence": 0.907}, {"text": "necessarily.", "start": 773.38, "end": 774.18, "confidence": 0.552}, {"text": "Think", "start": 775.24, "end": 775.32, "confidence": 0.921}, {"text": "of", "start": 775.32, "end": 775.52, "confidence": 0.986}, {"text": "it", "start": 775.52, "end": 775.68, "confidence": 0.984}, {"text": "this", "start": 775.68, "end": 775.7, "confidence": 0.996}, {"text": "way.", "start": 775.7, "end": 775.9, "confidence": 0.999}, {"text": "Sparsity", "start": 776.26, "end": 776.74, "confidence": 0.98}, {"text": "allows", "start": 776.74, "end": 777.1, "confidence": 0.931}, {"text": "us", "start": 777.1, "end": 777.26, "confidence": 0.976}, {"text": "to", "start": 777.26, "end": 777.34, "confidence": 0.997}, {"text": "do", "start": 777.34, "end": 777.54, "confidence": 0.992}, {"text": "more", "start": 777.54, "end": 777.8, "confidence": 0.987}, {"text": "with", "start": 777.8, "end": 777.92, "confidence": 0.997}, {"text": "less.", "start": 777.92, "end": 778.36, "confidence": 0.899}, {"text": "It's", "start": 778.56, "end": 779.14, "confidence": 0.977}, {"text": "like", "start": 779.14, "end": 779.3, "confidence": 0.989}, {"text": "optimizing", "start": 779.3, "end": 779.92, "confidence": 0.488}, {"text": "the", "start": 779.92, "end": 780.12, "confidence": 0.998}, {"text": "layout", "start": 780.12, "end": 780.44, "confidence": 0.786}, {"text": "of", "start": 780.44, "end": 780.52, "confidence": 0.993}, {"text": "a", "start": 780.52, "end": 780.9, "confidence": 0.898}, {"text": "city.", "start": 780.9, "end": 781.18, "confidence": 0.992}, {"text": "Instead", "start": 781.36, "end": 781.68, "confidence": 0.925}, {"text": "of", "start": 781.68, "end": 781.88, "confidence": 0.992}, {"text": "sprawling", "start": 781.88, "end": 782.46, "confidence": 0.853}, {"text": "suburbs,", "start": 782.46, "end": 783.0, "confidence": 0.791}, {"text": "we're", "start": 783.12, "end": 783.22, "confidence": 0.977}, {"text": "building", "start": 783.22, "end": 783.6, "confidence": 0.973}, {"text": "these", "start": 783.6, "end": 783.9, "confidence": 0.94}, {"text": "dense,", "start": 783.9, "end": 784.98, "confidence": 0.687}, {"text": "interconnected", "start": 784.98, "end": 785.5, "confidence": 0.897}, {"text": "urban", "start": 785.5, "end": 785.86, "confidence": 0.948}, {"text": "centers.", "start": 785.86, "end": 786.12, "confidence": 0.87}]}, {"id": 47, "seek": 77214, "start": 786.12, "end": 791.64, "text": " So we can still achieve incredible things with AI, but we can do it in a more sustainable and efficient way.", "tokens": [51064, 407, 321, 393, 920, 4584, 4651, 220, 825, 82, 365, 7318, 11, 457, 321, 393, 360, 309, 294, 257, 544, 11235, 293, 1244, 24549, 636, 13, 51314], "temperature": 0.0, "avg_logprob": -0.11929782231648763, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.8544510006904602, "confidence": 0.914, "words": [{"text": "So", "start": 786.12, "end": 786.6, "confidence": 0.943}, {"text": "we", "start": 786.6, "end": 786.7, "confidence": 0.982}, {"text": "can", "start": 786.7, "end": 786.82, "confidence": 0.985}, {"text": "still", "start": 786.82, "end": 787.1, "confidence": 0.993}, {"text": "achieve", "start": 787.1, "end": 787.38, "confidence": 0.907}, {"text": "incredible", "start": 787.38, "end": 787.86, "confidence": 0.981}, {"text": "things", "start": 787.86, "end": 788.24, "confidence": 0.994}, {"text": "with", "start": 788.24, "end": 788.38, "confidence": 0.996}, {"text": "AI,", "start": 788.38, "end": 788.66, "confidence": 0.975}, {"text": "but", "start": 788.98, "end": 789.3, "confidence": 0.99}, {"text": "we", "start": 789.3, "end": 789.48, "confidence": 0.979}, {"text": "can", "start": 789.48, "end": 789.64, "confidence": 0.985}, {"text": "do", "start": 789.64, "end": 789.82, "confidence": 0.989}, {"text": "it", "start": 789.82, "end": 790.04, "confidence": 0.986}, {"text": "in", "start": 790.04, "end": 790.06, "confidence": 0.983}, {"text": "a", "start": 790.06, "end": 790.14, "confidence": 0.994}, {"text": "more", "start": 790.14, "end": 790.36, "confidence": 0.99}, {"text": "sustainable", "start": 790.36, "end": 790.98, "confidence": 0.537}, {"text": "and", "start": 790.98, "end": 791.22, "confidence": 0.979}, {"text": "efficient", "start": 791.22, "end": 791.62, "confidence": 0.567}, {"text": "way.", "start": 791.62, "end": 791.64, "confidence": 0.998}]}, {"id": 48, "seek": 80214, "start": 802.7, "end": 811.22, "text": " It's like we're discovering a whole new set of architectural principles for building AI. It's not just about brute force anymore. It's about elegance in efficiency.", "tokens": [50414, 467, 311, 411, 321, 434, 24773, 257, 1379, 777, 992, 295, 26621, 582, 21961, 2622, 337, 2390, 7318, 13, 467, 311, 406, 445, 466, 12603, 68, 3464, 3602, 13, 467, 311, 466, 14459, 719, 294, 1244, 299, 1053, 1344, 13, 50864], "temperature": 0.0, "avg_logprob": -0.13822167551415598, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.1351412981748581, "confidence": 0.871, "words": [{"text": "It's", "start": 802.7, "end": 802.94, "confidence": 0.936}, {"text": "like", "start": 802.94, "end": 803.0, "confidence": 0.978}, {"text": "we're", "start": 803.0, "end": 803.18, "confidence": 0.983}, {"text": "discovering", "start": 803.18, "end": 803.68, "confidence": 0.285}, {"text": "a", "start": 803.68, "end": 803.78, "confidence": 0.998}, {"text": "whole", "start": 803.78, "end": 804.06, "confidence": 0.964}, {"text": "new", "start": 804.06, "end": 804.32, "confidence": 0.972}, {"text": "set", "start": 804.32, "end": 804.48, "confidence": 0.986}, {"text": "of", "start": 804.48, "end": 804.64, "confidence": 0.995}, {"text": "architectural", "start": 804.64, "end": 805.28, "confidence": 0.798}, {"text": "principles", "start": 805.28, "end": 805.82, "confidence": 0.951}, {"text": "for", "start": 805.82, "end": 805.94, "confidence": 0.992}, {"text": "building", "start": 805.94, "end": 806.26, "confidence": 0.977}, {"text": "AI.", "start": 806.26, "end": 806.52, "confidence": 0.937}, {"text": "It's", "start": 806.66, "end": 807.3, "confidence": 0.99}, {"text": "not", "start": 807.3, "end": 807.42, "confidence": 0.971}, {"text": "just", "start": 807.42, "end": 807.64, "confidence": 0.987}, {"text": "about", "start": 807.64, "end": 807.88, "confidence": 0.982}, {"text": "brute", "start": 807.88, "end": 808.22, "confidence": 0.78}, {"text": "force", "start": 808.22, "end": 808.64, "confidence": 0.961}, {"text": "anymore.", "start": 808.64, "end": 809.0, "confidence": 0.946}, {"text": "It's", "start": 809.0, "end": 809.14, "confidence": 0.996}, {"text": "about", "start": 809.14, "end": 809.7, "confidence": 0.983}, {"text": "elegance", "start": 809.7, "end": 810.56, "confidence": 0.927}, {"text": "in", "start": 810.56, "end": 810.66, "confidence": 0.703}, {"text": "efficiency.", "start": 810.66, "end": 811.22, "confidence": 0.618}]}, {"id": 49, "seek": 80214, "start": 811.86, "end": 819.76, "text": " And that brings us back to one of the most fascinating aspects of this research, the way these specialized experts seem to emerge organically during training.", "tokens": [50864, 400, 220, 6780, 5607, 505, 646, 220, 1353, 472, 295, 220, 3322, 881, 10343, 382, 494, 349, 82, 295, 220, 11176, 2132, 11, 220, 3322, 636, 220, 42678, 768, 1013, 1602, 8572, 1643, 220, 1353, 846, 260, 432, 1798, 984, 1830, 220, 17227, 1760, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13822167551415598, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.1351412981748581, "confidence": 0.907, "words": [{"text": "And", "start": 811.86, "end": 812.02, "confidence": 0.87}, {"text": "that", "start": 812.02, "end": 812.2, "confidence": 0.989}, {"text": "brings", "start": 812.2, "end": 812.48, "confidence": 0.91}, {"text": "us", "start": 812.48, "end": 812.6, "confidence": 0.977}, {"text": "back", "start": 812.6, "end": 812.86, "confidence": 0.992}, {"text": "to", "start": 812.86, "end": 813.02, "confidence": 0.999}, {"text": "one", "start": 813.02, "end": 813.16, "confidence": 0.967}, {"text": "of", "start": 813.16, "end": 813.3, "confidence": 0.99}, {"text": "the", "start": 813.3, "end": 813.44, "confidence": 0.999}, {"text": "most", "start": 813.44, "end": 813.74, "confidence": 0.93}, {"text": "fascinating", "start": 813.74, "end": 814.22, "confidence": 0.708}, {"text": "aspects", "start": 814.22, "end": 814.88, "confidence": 0.776}, {"text": "of", "start": 814.88, "end": 815.02, "confidence": 0.985}, {"text": "this", "start": 815.02, "end": 815.18, "confidence": 0.991}, {"text": "research,", "start": 815.18, "end": 815.72, "confidence": 0.986}, {"text": "the", "start": 815.72, "end": 816.12, "confidence": 0.996}, {"text": "way", "start": 816.12, "end": 816.34, "confidence": 0.998}, {"text": "these", "start": 816.34, "end": 816.56, "confidence": 0.758}, {"text": "specialized", "start": 816.56, "end": 817.14, "confidence": 0.748}, {"text": "experts", "start": 817.14, "end": 817.56, "confidence": 0.853}, {"text": "seem", "start": 817.56, "end": 817.94, "confidence": 0.975}, {"text": "to", "start": 817.94, "end": 817.98, "confidence": 0.999}, {"text": "emerge", "start": 817.98, "end": 818.38, "confidence": 0.834}, {"text": "organically", "start": 818.38, "end": 819.1, "confidence": 0.987}, {"text": "during", "start": 819.1, "end": 819.46, "confidence": 0.901}, {"text": "training.", "start": 819.46, "end": 819.76, "confidence": 0.972}]}, {"id": 50, "seek": 80214, "start": 819.76, "end": 825.14, "text": " It's like they're self-organizing, almost like cells forming different organs in a developing embryo.", "tokens": [51264, 467, 311, 411, 220, 13162, 434, 2698, 12, 12372, 3319, 11, 1920, 411, 5438, 15745, 819, 20659, 294, 257, 368, 779, 26125, 31588, 78, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13822167551415598, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.1351412981748581, "confidence": 0.908, "words": [{"text": "It's", "start": 819.76, "end": 820.28, "confidence": 0.968}, {"text": "like", "start": 820.28, "end": 820.4, "confidence": 0.988}, {"text": "they're", "start": 820.4, "end": 820.52, "confidence": 0.979}, {"text": "self-organizing,", "start": 820.52, "end": 821.32, "confidence": 0.983}, {"text": "almost", "start": 821.5, "end": 821.76, "confidence": 0.91}, {"text": "like", "start": 821.76, "end": 821.78, "confidence": 0.986}, {"text": "cells", "start": 821.78, "end": 822.52, "confidence": 0.882}, {"text": "forming", "start": 822.52, "end": 823.24, "confidence": 0.811}, {"text": "different", "start": 823.24, "end": 823.62, "confidence": 0.932}, {"text": "organs", "start": 823.62, "end": 824.16, "confidence": 0.973}, {"text": "in", "start": 824.16, "end": 824.36, "confidence": 0.977}, {"text": "a", "start": 824.36, "end": 824.56, "confidence": 0.657}, {"text": "developing", "start": 824.56, "end": 824.86, "confidence": 0.711}, {"text": "embryo.", "start": 824.86, "end": 825.14, "confidence": 0.993}]}, {"id": 51, "seek": 83214, "start": 832.8, "end": 860.72, "text": " So it's like they planted a seed and then nurtured the AI as it grew, allowing those specialized skills to blossom. And that raises profound questions about the nature of learning, both in AI and in humans. How does the self-organization occur? What are the underlying principles that guide the formation of expertise? It's like we're witnessing a form of AI evolution in action where the fittest experts survive and thrive based on their ability to handle specific types of information. And it underscores the importance of the training process itself.", "tokens": [50414, 407, 309, 311, 411, 220, 13162, 17395, 257, 8871, 293, 220, 19096, 297, 6224, 3831, 220, 3322, 7318, 382, 309, 6109, 11, 439, 9637, 220, 49833, 768, 1013, 1602, 3942, 220, 1353, 38524, 13, 400, 220, 6780, 19658, 447, 17493, 1651, 466, 220, 3322, 3687, 295, 2539, 11, 1293, 294, 7318, 293, 294, 6255, 13, 1012, 775, 220, 3322, 2698, 12, 12372, 2144, 5160, 30, 708, 366, 220, 3322, 833, 356, 278, 582, 21961, 2622, 220, 6780, 5934, 220, 3322, 11723, 295, 11769, 30, 467, 311, 411, 321, 434, 39233, 257, 1254, 295, 7318, 7117, 1448, 294, 3069, 689, 220, 3322, 48876, 377, 8572, 7867, 293, 220, 392, 8003, 2361, 322, 220, 3322, 347, 3485, 220, 1353, 4813, 637, 3045, 1089, 220, 874, 5190, 295, 1589, 13, 400, 309, 16692, 66, 2706, 220, 3322, 7379, 295, 220, 3322, 220, 17227, 1760, 1399, 2564, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10880397614978608, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.44306284189224243, "confidence": 0.905, "words": [{"text": "So", "start": 832.8, "end": 833.12, "confidence": 0.636}, {"text": "it's", "start": 833.12, "end": 833.26, "confidence": 0.983}, {"text": "like", "start": 833.26, "end": 833.34, "confidence": 0.988}, {"text": "they", "start": 833.34, "end": 833.5, "confidence": 0.986}, {"text": "planted", "start": 833.5, "end": 833.86, "confidence": 0.97}, {"text": "a", "start": 833.86, "end": 834.0, "confidence": 0.983}, {"text": "seed", "start": 834.0, "end": 834.2, "confidence": 0.988}, {"text": "and", "start": 834.2, "end": 834.36, "confidence": 0.929}, {"text": "then", "start": 834.36, "end": 834.56, "confidence": 0.969}, {"text": "nurtured", "start": 834.56, "end": 834.72, "confidence": 0.757}, {"text": "the", "start": 834.72, "end": 835.02, "confidence": 0.997}, {"text": "AI", "start": 835.02, "end": 835.3, "confidence": 0.829}, {"text": "as", "start": 835.3, "end": 835.5, "confidence": 0.974}, {"text": "it", "start": 835.5, "end": 835.64, "confidence": 0.985}, {"text": "grew,", "start": 835.64, "end": 836.22, "confidence": 0.827}, {"text": "allowing", "start": 836.5, "end": 836.66, "confidence": 0.822}, {"text": "those", "start": 836.66, "end": 836.86, "confidence": 0.99}, {"text": "specialized", "start": 836.86, "end": 837.38, "confidence": 0.79}, {"text": "skills", "start": 837.38, "end": 837.98, "confidence": 0.961}, {"text": "to", "start": 837.98, "end": 838.0, "confidence": 0.998}, {"text": "blossom.", "start": 838.0, "end": 838.54, "confidence": 0.892}, {"text": "And", "start": 838.58, "end": 838.72, "confidence": 0.521}, {"text": "that", "start": 838.72, "end": 838.88, "confidence": 0.991}, {"text": "raises", "start": 838.88, "end": 839.24, "confidence": 0.668}, {"text": "profound", "start": 839.24, "end": 839.8, "confidence": 0.667}, {"text": "questions", "start": 839.8, "end": 840.26, "confidence": 0.986}, {"text": "about", "start": 840.26, "end": 840.48, "confidence": 0.969}, {"text": "the", "start": 840.48, "end": 840.62, "confidence": 0.997}, {"text": "nature", "start": 840.62, "end": 840.96, "confidence": 0.952}, {"text": "of", "start": 840.96, "end": 841.14, "confidence": 0.991}, {"text": "learning,", "start": 841.14, "end": 841.42, "confidence": 0.98}, {"text": "both", "start": 841.66, "end": 841.68, "confidence": 0.958}, {"text": "in", "start": 841.68, "end": 841.82, "confidence": 0.985}, {"text": "AI", "start": 841.82, "end": 842.14, "confidence": 0.973}, {"text": "and", "start": 842.14, "end": 842.36, "confidence": 0.988}, {"text": "in", "start": 842.36, "end": 842.8, "confidence": 0.986}, {"text": "humans.", "start": 842.8, "end": 843.36, "confidence": 0.937}, {"text": "How", "start": 843.88, "end": 843.94, "confidence": 0.844}, {"text": "does", "start": 843.94, "end": 844.24, "confidence": 0.991}, {"text": "the", "start": 844.24, "end": 844.4, "confidence": 0.729}, {"text": "self-organization", "start": 844.4, "end": 845.34, "confidence": 0.98}, {"text": "occur?", "start": 845.34, "end": 846.16, "confidence": 0.391}, {"text": "What", "start": 846.34, "end": 846.42, "confidence": 0.962}, {"text": "are", "start": 846.42, "end": 846.62, "confidence": 0.987}, {"text": "the", "start": 846.62, "end": 846.66, "confidence": 0.998}, {"text": "underlying", "start": 846.66, "end": 847.14, "confidence": 0.912}, {"text": "principles", "start": 847.14, "end": 847.72, "confidence": 0.935}, {"text": "that", "start": 847.72, "end": 847.92, "confidence": 0.995}, {"text": "guide", "start": 847.92, "end": 848.2, "confidence": 0.98}, {"text": "the", "start": 848.2, "end": 848.38, "confidence": 0.998}, {"text": "formation", "start": 848.38, "end": 848.86, "confidence": 0.909}, {"text": "of", "start": 848.86, "end": 848.88, "confidence": 0.993}, {"text": "expertise?", "start": 848.88, "end": 849.82, "confidence": 0.458}, {"text": "It's", "start": 850.22, "end": 850.4, "confidence": 0.707}, {"text": "like", "start": 850.4, "end": 850.46, "confidence": 0.983}, {"text": "we're", "start": 850.46, "end": 850.7, "confidence": 0.982}, {"text": "witnessing", "start": 850.7, "end": 851.1, "confidence": 0.809}, {"text": "a", "start": 851.1, "end": 851.36, "confidence": 0.995}, {"text": "form", "start": 851.36, "end": 851.6, "confidence": 0.971}, {"text": "of", "start": 851.6, "end": 851.82, "confidence": 0.992}, {"text": "AI", "start": 851.82, "end": 852.12, "confidence": 0.944}, {"text": "evolution", "start": 852.12, "end": 852.76, "confidence": 0.863}, {"text": "in", "start": 852.76, "end": 852.84, "confidence": 0.971}, {"text": "action", "start": 852.84, "end": 853.48, "confidence": 0.972}, {"text": "where", "start": 853.48, "end": 853.76, "confidence": 0.577}, {"text": "the", "start": 853.76, "end": 853.84, "confidence": 0.996}, {"text": "fittest", "start": 853.84, "end": 854.34, "confidence": 0.967}, {"text": "experts", "start": 854.34, "end": 854.78, "confidence": 0.871}, {"text": "survive", "start": 854.78, "end": 855.32, "confidence": 0.936}, {"text": "and", "start": 855.32, "end": 855.62, "confidence": 0.979}, {"text": "thrive", "start": 855.62, "end": 856.08, "confidence": 0.991}, {"text": "based", "start": 856.08, "end": 856.4, "confidence": 0.837}, {"text": "on", "start": 856.4, "end": 856.56, "confidence": 0.994}, {"text": "their", "start": 856.56, "end": 856.76, "confidence": 0.993}, {"text": "ability", "start": 856.76, "end": 857.02, "confidence": 0.985}, {"text": "to", "start": 857.02, "end": 857.22, "confidence": 0.998}, {"text": "handle", "start": 857.22, "end": 857.52, "confidence": 0.98}, {"text": "specific", "start": 857.52, "end": 858.34, "confidence": 0.811}, {"text": "types", "start": 858.34, "end": 858.8, "confidence": 0.983}, {"text": "of", "start": 858.8, "end": 858.96, "confidence": 0.992}, {"text": "information.", "start": 858.96, "end": 859.56, "confidence": 0.864}, {"text": "And", "start": 859.74, "end": 859.76, "confidence": 0.481}, {"text": "it", "start": 859.76, "end": 859.92, "confidence": 0.963}, {"text": "underscores", "start": 859.92, "end": 860.42, "confidence": 0.992}, {"text": "the", "start": 860.42, "end": 860.56, "confidence": 0.991}, {"text": "importance", "start": 860.56, "end": 860.62, "confidence": 0.95}, {"text": "of", "start": 860.62, "end": 860.64, "confidence": 0.977}, {"text": "the", "start": 860.64, "end": 860.66, "confidence": 0.998}, {"text": "training", "start": 860.66, "end": 860.68, "confidence": 0.933}, {"text": "process", "start": 860.68, "end": 860.7, "confidence": 0.894}, {"text": "itself.", "start": 860.7, "end": 860.72, "confidence": 0.732}]}, {"id": 52, "seek": 86214, "start": 862.64, "end": 892.3, "text": " It's not just about feeding the AI data. It's about creating the right environment for learning and adaptation. As we wrap up this deep dive, I want to circle back to something we discussed earlier. The idea that these sparse expert models might be reflecting some aspects of human cognition, the way our brains specialize in different tasks. It's a compelling thought, isn't it? We have areas dedicated to language, vision, memory, motor skills. And we don't use all of our brainpower for every task we allocate our resources strategically. So could these AI models be too complicated? And could they be too complicated to understand?", "tokens": [50414, 467, 311, 406, 445, 466, 12919, 220, 3322, 7318, 1412, 13, 467, 311, 466, 4084, 220, 3322, 558, 2823, 337, 2539, 293, 21549, 13, 1018, 321, 7019, 493, 220, 11176, 2452, 9192, 11, 286, 528, 220, 1353, 6329, 646, 220, 1353, 746, 321, 717, 2169, 292, 3071, 13, 440, 1558, 220, 6780, 220, 42678, 637, 11668, 5844, 5245, 1062, 312, 23543, 512, 382, 494, 349, 82, 295, 1952, 46905, 11, 220, 3322, 636, 527, 15442, 37938, 294, 819, 220, 83, 296, 1694, 13, 467, 311, 257, 20050, 220, 43135, 11, 1943, 380, 309, 30, 492, 362, 3179, 8374, 220, 1353, 2856, 11, 5201, 11, 4675, 11, 5932, 3942, 13, 400, 321, 500, 380, 764, 439, 295, 527, 3567, 9513, 337, 633, 220, 83, 3863, 321, 439, 42869, 527, 3593, 5464, 804, 356, 13, 407, 727, 220, 42678, 7318, 5245, 312, 220, 32599, 6179, 30, 400, 727, 220, 13162, 312, 220, 32599, 6179, 220, 1353, 1223, 30], "temperature": 0.0, "avg_logprob": -0.19998918605756155, "compression_ratio": 1.7162162162162162, "no_speech_prob": 0.3601120412349701, "confidence": 0.829, "words": [{"text": "It's", "start": 862.64, "end": 862.66, "confidence": 0.99}, {"text": "not", "start": 862.66, "end": 862.78, "confidence": 0.962}, {"text": "just", "start": 862.78, "end": 862.92, "confidence": 0.994}, {"text": "about", "start": 862.92, "end": 863.14, "confidence": 0.981}, {"text": "feeding", "start": 863.14, "end": 863.48, "confidence": 0.882}, {"text": "the", "start": 863.48, "end": 863.74, "confidence": 0.995}, {"text": "AI", "start": 863.74, "end": 863.82, "confidence": 0.838}, {"text": "data.", "start": 863.82, "end": 864.2, "confidence": 0.975}, {"text": "It's", "start": 864.6, "end": 864.62, "confidence": 0.997}, {"text": "about", "start": 864.62, "end": 864.78, "confidence": 0.98}, {"text": "creating", "start": 864.78, "end": 865.12, "confidence": 0.877}, {"text": "the", "start": 865.12, "end": 865.26, "confidence": 0.999}, {"text": "right", "start": 865.26, "end": 865.54, "confidence": 0.989}, {"text": "environment", "start": 865.54, "end": 866.12, "confidence": 0.888}, {"text": "for", "start": 866.12, "end": 866.48, "confidence": 0.998}, {"text": "learning", "start": 866.48, "end": 866.62, "confidence": 0.987}, {"text": "and", "start": 866.62, "end": 866.84, "confidence": 0.986}, {"text": "adaptation.", "start": 866.84, "end": 867.48, "confidence": 0.688}, {"text": "As", "start": 868.16, "end": 868.28, "confidence": 0.644}, {"text": "we", "start": 868.28, "end": 868.48, "confidence": 0.989}, {"text": "wrap", "start": 868.48, "end": 868.62, "confidence": 0.985}, {"text": "up", "start": 868.62, "end": 868.86, "confidence": 0.985}, {"text": "this", "start": 868.86, "end": 868.9, "confidence": 0.985}, {"text": "deep", "start": 868.9, "end": 869.26, "confidence": 0.973}, {"text": "dive,", "start": 869.26, "end": 869.4, "confidence": 0.891}, {"text": "I", "start": 869.58, "end": 869.6, "confidence": 0.998}, {"text": "want", "start": 869.6, "end": 869.66, "confidence": 0.983}, {"text": "to", "start": 869.66, "end": 869.68, "confidence": 0.998}, {"text": "circle", "start": 869.68, "end": 870.0, "confidence": 0.993}, {"text": "back", "start": 870.0, "end": 870.14, "confidence": 0.988}, {"text": "to", "start": 870.14, "end": 870.34, "confidence": 0.887}, {"text": "something", "start": 870.34, "end": 870.54, "confidence": 0.948}, {"text": "we", "start": 870.54, "end": 870.58, "confidence": 0.979}, {"text": "discussed", "start": 870.58, "end": 870.9, "confidence": 0.651}, {"text": "earlier.", "start": 870.9, "end": 871.64, "confidence": 0.578}, {"text": "The", "start": 872.02, "end": 872.04, "confidence": 0.931}, {"text": "idea", "start": 872.04, "end": 872.5, "confidence": 0.933}, {"text": "that", "start": 872.5, "end": 872.66, "confidence": 0.986}, {"text": "these", "start": 872.66, "end": 872.9, "confidence": 0.983}, {"text": "sparse", "start": 872.9, "end": 873.62, "confidence": 0.952}, {"text": "expert", "start": 873.62, "end": 874.0, "confidence": 0.693}, {"text": "models", "start": 874.0, "end": 874.34, "confidence": 0.937}, {"text": "might", "start": 874.34, "end": 874.64, "confidence": 0.961}, {"text": "be", "start": 874.64, "end": 874.82, "confidence": 0.997}, {"text": "reflecting", "start": 874.82, "end": 875.18, "confidence": 0.839}, {"text": "some", "start": 875.18, "end": 875.5, "confidence": 0.862}, {"text": "aspects", "start": 875.5, "end": 876.02, "confidence": 0.768}, {"text": "of", "start": 876.02, "end": 876.18, "confidence": 0.995}, {"text": "human", "start": 876.18, "end": 876.7, "confidence": 0.978}, {"text": "cognition,", "start": 876.7, "end": 876.98, "confidence": 0.877}, {"text": "the", "start": 877.68, "end": 877.7, "confidence": 0.998}, {"text": "way", "start": 877.7, "end": 877.72, "confidence": 0.998}, {"text": "our", "start": 877.72, "end": 878.08, "confidence": 0.986}, {"text": "brains", "start": 878.08, "end": 878.1, "confidence": 0.729}, {"text": "specialize", "start": 878.1, "end": 878.86, "confidence": 0.552}, {"text": "in", "start": 878.86, "end": 879.04, "confidence": 0.974}, {"text": "different", "start": 879.04, "end": 879.46, "confidence": 0.951}, {"text": "tasks.", "start": 879.46, "end": 879.94, "confidence": 0.989}, {"text": "It's", "start": 880.04, "end": 880.22, "confidence": 0.953}, {"text": "a", "start": 880.22, "end": 880.38, "confidence": 0.999}, {"text": "compelling", "start": 880.38, "end": 880.64, "confidence": 0.927}, {"text": "thought,", "start": 880.64, "end": 881.06, "confidence": 0.996}, {"text": "isn't", "start": 881.26, "end": 881.36, "confidence": 0.994}, {"text": "it?", "start": 881.36, "end": 881.6, "confidence": 0.986}, {"text": "We", "start": 881.78, "end": 881.82, "confidence": 0.948}, {"text": "have", "start": 881.82, "end": 882.04, "confidence": 0.978}, {"text": "areas", "start": 882.04, "end": 882.5, "confidence": 0.827}, {"text": "dedicated", "start": 882.5, "end": 883.08, "confidence": 0.929}, {"text": "to", "start": 883.08, "end": 883.32, "confidence": 0.999}, {"text": "language,", "start": 883.32, "end": 883.88, "confidence": 0.837}, {"text": "vision,", "start": 884.22, "end": 884.24, "confidence": 0.804}, {"text": "memory,", "start": 884.52, "end": 884.54, "confidence": 0.962}, {"text": "motor", "start": 884.66, "end": 884.82, "confidence": 0.989}, {"text": "skills.", "start": 884.82, "end": 885.2, "confidence": 0.951}, {"text": "And", "start": 885.4, "end": 885.86, "confidence": 0.977}, {"text": "we", "start": 885.86, "end": 886.1, "confidence": 0.994}, {"text": "don't", "start": 886.1, "end": 886.3, "confidence": 0.997}, {"text": "use", "start": 886.3, "end": 886.68, "confidence": 0.91}, {"text": "all", "start": 886.68, "end": 886.98, "confidence": 0.991}, {"text": "of", "start": 886.98, "end": 887.06, "confidence": 0.994}, {"text": "our", "start": 887.06, "end": 887.14, "confidence": 0.99}, {"text": "brainpower", "start": 887.14, "end": 887.74, "confidence": 0.875}, {"text": "for", "start": 887.74, "end": 888.04, "confidence": 0.998}, {"text": "every", "start": 888.04, "end": 888.26, "confidence": 0.964}, {"text": "task", "start": 888.26, "end": 888.56, "confidence": 0.987}, {"text": "we", "start": 888.56, "end": 889.24, "confidence": 0.841}, {"text": "allocate", "start": 889.24, "end": 889.26, "confidence": 0.631}, {"text": "our", "start": 889.26, "end": 889.36, "confidence": 0.983}, {"text": "resources", "start": 889.36, "end": 889.74, "confidence": 0.701}, {"text": "strategically.", "start": 889.74, "end": 890.6, "confidence": 0.817}, {"text": "So", "start": 890.8, "end": 890.86, "confidence": 0.494}, {"text": "could", "start": 890.86, "end": 891.1, "confidence": 0.976}, {"text": "these", "start": 891.1, "end": 891.34, "confidence": 0.982}, {"text": "AI", "start": 891.34, "end": 891.58, "confidence": 0.957}, {"text": "models", "start": 891.58, "end": 891.92, "confidence": 0.907}, {"text": "be", "start": 891.92, "end": 892.06, "confidence": 0.981}, {"text": "too", "start": 892.06, "end": 892.12, "confidence": 0.872}, {"text": "complicated?", "start": 892.12, "end": 892.14, "confidence": 0.06}, {"text": "And", "start": 892.14, "end": 892.16, "confidence": 0.11}, {"text": "could", "start": 892.16, "end": 892.18, "confidence": 0.183}, {"text": "they", "start": 892.18, "end": 892.2, "confidence": 0.448}, {"text": "be", "start": 892.2, "end": 892.22, "confidence": 0.49}, {"text": "too", "start": 892.22, "end": 892.24, "confidence": 0.563}, {"text": "complicated", "start": 892.24, "end": 892.26, "confidence": 0.298}, {"text": "to", "start": 892.26, "end": 892.28, "confidence": 0.582}, {"text": "understand?", "start": 892.28, "end": 892.3, "confidence": 0.168}]}, {"id": 53, "seek": 89214, "start": 892.3, "end": 918.92, "text": " And could they be teaching us something about ourselves? Could they be revealing fundamental principles of how intelligence, both biological and artificial, arises from these specialized systems working together? That's one of the most exciting frontiers of AI research. As we build increasingly sophisticated models, we're not only developing new technologies, we're also gaining insights into the very nature of thought and learning. This deep dive has been a real journey full of surprising twists and turns.", "tokens": [50364, 400, 727, 220, 13162, 312, 220, 975, 2834, 505, 746, 466, 4175, 30, 7497, 220, 13162, 312, 23983, 8088, 582, 21961, 2622, 295, 577, 7599, 11, 1293, 3228, 1132, 804, 293, 11677, 11, 27388, 490, 220, 42678, 19813, 3652, 1364, 220, 83, 9622, 30, 663, 311, 472, 295, 220, 3322, 881, 4670, 1868, 4890, 295, 7318, 2132, 13, 1018, 321, 1322, 12980, 262, 5317, 468, 3587, 5245, 11, 321, 434, 406, 787, 368, 779, 26125, 777, 220, 29113, 6204, 11, 321, 434, 611, 5959, 1760, 14310, 666, 220, 3322, 588, 3687, 295, 220, 43135, 293, 2539, 13, 639, 2452, 9192, 575, 668, 257, 957, 4671, 1577, 295, 8830, 220, 20270, 1751, 293, 220, 33886, 82, 13], "temperature": 0.0, "avg_logprob": -0.12456449411683164, "compression_ratio": 1.61198738170347, "no_speech_prob": 0.1732521951198578, "confidence": 0.876, "words": [{"text": "And", "start": 892.3, "end": 892.32, "confidence": 0.154}, {"text": "could", "start": 892.32, "end": 892.34, "confidence": 0.363}, {"text": "they", "start": 892.34, "end": 892.36, "confidence": 0.937}, {"text": "be", "start": 892.36, "end": 892.38, "confidence": 0.909}, {"text": "teaching", "start": 892.38, "end": 892.4, "confidence": 0.769}, {"text": "us", "start": 892.4, "end": 892.52, "confidence": 0.955}, {"text": "something", "start": 892.52, "end": 892.8, "confidence": 0.94}, {"text": "about", "start": 892.8, "end": 893.06, "confidence": 0.981}, {"text": "ourselves?", "start": 893.06, "end": 893.7, "confidence": 0.966}, {"text": "Could", "start": 893.72, "end": 894.28, "confidence": 0.882}, {"text": "they", "start": 894.28, "end": 894.48, "confidence": 0.991}, {"text": "be", "start": 894.48, "end": 894.76, "confidence": 0.994}, {"text": "revealing", "start": 894.76, "end": 895.1, "confidence": 0.896}, {"text": "fundamental", "start": 895.1, "end": 895.82, "confidence": 0.949}, {"text": "principles", "start": 895.82, "end": 896.26, "confidence": 0.92}, {"text": "of", "start": 896.26, "end": 896.44, "confidence": 0.965}, {"text": "how", "start": 896.44, "end": 896.8, "confidence": 0.984}, {"text": "intelligence,", "start": 896.8, "end": 897.2, "confidence": 0.625}, {"text": "both", "start": 897.98, "end": 898.04, "confidence": 0.9}, {"text": "biological", "start": 898.04, "end": 898.5, "confidence": 0.825}, {"text": "and", "start": 898.5, "end": 898.96, "confidence": 0.986}, {"text": "artificial,", "start": 898.96, "end": 899.08, "confidence": 0.807}, {"text": "arises", "start": 899.84, "end": 899.86, "confidence": 0.868}, {"text": "from", "start": 899.86, "end": 900.04, "confidence": 0.976}, {"text": "these", "start": 900.04, "end": 900.42, "confidence": 0.979}, {"text": "specialized", "start": 900.42, "end": 901.3, "confidence": 0.342}, {"text": "systems", "start": 901.3, "end": 901.74, "confidence": 0.948}, {"text": "working", "start": 901.74, "end": 902.0, "confidence": 0.987}, {"text": "together?", "start": 902.0, "end": 902.42, "confidence": 0.99}, {"text": "That's", "start": 902.64, "end": 902.96, "confidence": 0.919}, {"text": "one", "start": 902.96, "end": 903.14, "confidence": 0.982}, {"text": "of", "start": 903.14, "end": 903.28, "confidence": 0.985}, {"text": "the", "start": 903.28, "end": 903.3, "confidence": 0.999}, {"text": "most", "start": 903.3, "end": 904.12, "confidence": 0.928}, {"text": "exciting", "start": 904.12, "end": 904.14, "confidence": 0.984}, {"text": "frontiers", "start": 904.14, "end": 904.86, "confidence": 0.992}, {"text": "of", "start": 904.86, "end": 905.02, "confidence": 0.986}, {"text": "AI", "start": 905.02, "end": 905.4, "confidence": 0.966}, {"text": "research.", "start": 905.4, "end": 905.96, "confidence": 0.972}, {"text": "As", "start": 906.04, "end": 906.22, "confidence": 0.981}, {"text": "we", "start": 906.22, "end": 906.44, "confidence": 0.994}, {"text": "build", "start": 906.44, "end": 906.7, "confidence": 0.987}, {"text": "increasingly", "start": 906.7, "end": 907.54, "confidence": 0.707}, {"text": "sophisticated", "start": 907.54, "end": 907.92, "confidence": 0.777}, {"text": "models,", "start": 907.92, "end": 908.42, "confidence": 0.917}, {"text": "we're", "start": 908.56, "end": 908.74, "confidence": 0.974}, {"text": "not", "start": 908.74, "end": 908.88, "confidence": 0.975}, {"text": "only", "start": 908.88, "end": 909.04, "confidence": 0.992}, {"text": "developing", "start": 909.04, "end": 909.48, "confidence": 0.712}, {"text": "new", "start": 909.48, "end": 909.92, "confidence": 0.903}, {"text": "technologies,", "start": 909.92, "end": 910.34, "confidence": 0.91}, {"text": "we're", "start": 910.56, "end": 910.74, "confidence": 0.965}, {"text": "also", "start": 910.74, "end": 910.96, "confidence": 0.946}, {"text": "gaining", "start": 910.96, "end": 911.44, "confidence": 0.689}, {"text": "insights", "start": 911.44, "end": 912.0, "confidence": 0.447}, {"text": "into", "start": 912.0, "end": 912.22, "confidence": 0.906}, {"text": "the", "start": 912.22, "end": 912.36, "confidence": 0.998}, {"text": "very", "start": 912.36, "end": 912.78, "confidence": 0.897}, {"text": "nature", "start": 912.78, "end": 913.08, "confidence": 0.95}, {"text": "of", "start": 913.08, "end": 913.24, "confidence": 0.987}, {"text": "thought", "start": 913.24, "end": 913.66, "confidence": 0.995}, {"text": "and", "start": 913.66, "end": 913.88, "confidence": 0.983}, {"text": "learning.", "start": 913.88, "end": 914.2, "confidence": 0.986}, {"text": "This", "start": 914.26, "end": 914.96, "confidence": 0.648}, {"text": "deep", "start": 914.96, "end": 915.2, "confidence": 0.924}, {"text": "dive", "start": 915.2, "end": 915.54, "confidence": 0.908}, {"text": "has", "start": 915.54, "end": 915.74, "confidence": 0.949}, {"text": "been", "start": 915.74, "end": 915.92, "confidence": 0.98}, {"text": "a", "start": 915.92, "end": 916.08, "confidence": 0.998}, {"text": "real", "start": 916.08, "end": 916.5, "confidence": 0.991}, {"text": "journey", "start": 916.5, "end": 916.9, "confidence": 0.965}, {"text": "full", "start": 916.9, "end": 917.26, "confidence": 0.754}, {"text": "of", "start": 917.26, "end": 917.48, "confidence": 0.991}, {"text": "surprising", "start": 917.48, "end": 917.96, "confidence": 0.875}, {"text": "twists", "start": 917.96, "end": 918.54, "confidence": 0.968}, {"text": "and", "start": 918.54, "end": 918.56, "confidence": 0.986}, {"text": "turns.", "start": 918.56, "end": 918.92, "confidence": 0.98}]}, {"id": 54, "seek": 92214, "start": 922.14, "end": 925.98, "text": " We ended up exploring some of the deepest mysteries of AI and the human mind.", "tokens": [50380, 492, 4590, 493, 12736, 512, 295, 220, 3322, 28288, 30785, 295, 7318, 293, 220, 3322, 1952, 1575, 13, 50558], "temperature": 0.0, "avg_logprob": -0.1988020477294922, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.004972647875547409, "confidence": 0.837, "words": [{"text": "We", "start": 922.14, "end": 922.18, "confidence": 0.262}, {"text": "ended", "start": 922.18, "end": 922.3, "confidence": 0.358}, {"text": "up", "start": 922.3, "end": 922.42, "confidence": 0.993}, {"text": "exploring", "start": 922.42, "end": 922.86, "confidence": 0.885}, {"text": "some", "start": 922.86, "end": 923.04, "confidence": 0.801}, {"text": "of", "start": 923.04, "end": 923.16, "confidence": 0.991}, {"text": "the", "start": 923.16, "end": 923.42, "confidence": 0.999}, {"text": "deepest", "start": 923.42, "end": 923.64, "confidence": 0.904}, {"text": "mysteries", "start": 923.64, "end": 924.06, "confidence": 0.956}, {"text": "of", "start": 924.06, "end": 924.3, "confidence": 0.992}, {"text": "AI", "start": 924.3, "end": 924.82, "confidence": 0.977}, {"text": "and", "start": 924.82, "end": 925.28, "confidence": 0.962}, {"text": "the", "start": 925.28, "end": 925.62, "confidence": 0.997}, {"text": "human", "start": 925.62, "end": 925.72, "confidence": 0.949}, {"text": "mind.", "start": 925.72, "end": 925.98, "confidence": 0.979}]}, {"id": 55, "seek": 92214, "start": 926.2, "end": 935.94, "text": " And to our listener, we hope this has inspired you to keep exploring, keep questioning, and keep diving deep into this fascinating world of AI. Who knows what other wonders await us out there?", "tokens": [50558, 400, 220, 1353, 527, 31569, 11, 321, 1454, 220, 11176, 575, 7547, 291, 220, 1353, 1066, 12736, 11, 1066, 21257, 11, 293, 1066, 20241, 2452, 666, 220, 11176, 10343, 1002, 295, 7318, 13, 2102, 3255, 437, 661, 27348, 19670, 505, 484, 220, 15456, 30, 51058], "temperature": 0.0, "avg_logprob": -0.1988020477294922, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.004972647875547409, "confidence": 0.936, "words": [{"text": "And", "start": 926.2, "end": 926.36, "confidence": 0.914}, {"text": "to", "start": 926.36, "end": 926.56, "confidence": 0.983}, {"text": "our", "start": 926.56, "end": 926.7, "confidence": 0.989}, {"text": "listener,", "start": 926.7, "end": 927.0, "confidence": 0.662}, {"text": "we", "start": 927.12, "end": 927.18, "confidence": 0.984}, {"text": "hope", "start": 927.18, "end": 927.38, "confidence": 0.974}, {"text": "this", "start": 927.38, "end": 927.6, "confidence": 0.992}, {"text": "has", "start": 927.6, "end": 927.66, "confidence": 0.945}, {"text": "inspired", "start": 927.66, "end": 928.08, "confidence": 0.621}, {"text": "you", "start": 928.08, "end": 928.26, "confidence": 0.994}, {"text": "to", "start": 928.26, "end": 928.38, "confidence": 0.996}, {"text": "keep", "start": 928.38, "end": 928.66, "confidence": 0.967}, {"text": "exploring,", "start": 928.66, "end": 929.18, "confidence": 0.975}, {"text": "keep", "start": 929.34, "end": 929.56, "confidence": 0.94}, {"text": "questioning,", "start": 929.56, "end": 930.04, "confidence": 0.902}, {"text": "and", "start": 930.12, "end": 930.24, "confidence": 0.932}, {"text": "keep", "start": 930.24, "end": 930.44, "confidence": 0.95}, {"text": "diving", "start": 930.44, "end": 930.84, "confidence": 0.864}, {"text": "deep", "start": 930.84, "end": 931.28, "confidence": 0.986}, {"text": "into", "start": 931.28, "end": 931.5, "confidence": 0.898}, {"text": "this", "start": 931.5, "end": 931.76, "confidence": 0.995}, {"text": "fascinating", "start": 931.76, "end": 932.32, "confidence": 0.85}, {"text": "world", "start": 932.32, "end": 932.66, "confidence": 0.997}, {"text": "of", "start": 932.66, "end": 932.78, "confidence": 0.991}, {"text": "AI.", "start": 932.78, "end": 933.22, "confidence": 0.986}, {"text": "Who", "start": 933.28, "end": 933.96, "confidence": 0.778}, {"text": "knows", "start": 933.96, "end": 934.32, "confidence": 0.976}, {"text": "what", "start": 934.32, "end": 934.48, "confidence": 0.993}, {"text": "other", "start": 934.48, "end": 934.76, "confidence": 0.965}, {"text": "wonders", "start": 934.76, "end": 935.16, "confidence": 0.966}, {"text": "await", "start": 935.16, "end": 935.36, "confidence": 0.862}, {"text": "us", "start": 935.36, "end": 935.6, "confidence": 0.978}, {"text": "out", "start": 935.6, "end": 935.84, "confidence": 0.944}, {"text": "there?", "start": 935.84, "end": 935.94, "confidence": 0.993}]}, {"id": 56, "seek": 92214, "start": 936.36, "end": 946.44, "text": " If this deep dive has left you wanting more, we encourage you to check out the Estimo research paper you sent us. It's a treasure trove of insights. And until next time, keep that curiosity burning bright.", "tokens": [51058, 759, 220, 11176, 2452, 9192, 575, 1411, 291, 7935, 544, 11, 321, 5373, 291, 220, 1353, 1520, 484, 220, 3322, 4410, 6934, 2132, 3035, 291, 2279, 505, 13, 467, 311, 257, 220, 3599, 2508, 220, 83, 32467, 295, 14310, 13, 400, 1826, 958, 220, 3766, 11, 1066, 220, 6780, 1262, 72, 9598, 88, 9488, 4730, 13, 51586], "temperature": 0.0, "avg_logprob": -0.1988020477294922, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.004972647875547409, "confidence": 0.918, "words": [{"text": "If", "start": 936.36, "end": 936.52, "confidence": 0.987}, {"text": "this", "start": 936.52, "end": 936.72, "confidence": 0.998}, {"text": "deep", "start": 936.72, "end": 936.98, "confidence": 0.981}, {"text": "dive", "start": 936.98, "end": 937.3, "confidence": 0.898}, {"text": "has", "start": 937.3, "end": 937.38, "confidence": 0.933}, {"text": "left", "start": 937.38, "end": 937.56, "confidence": 0.993}, {"text": "you", "start": 937.56, "end": 937.72, "confidence": 0.995}, {"text": "wanting", "start": 937.72, "end": 937.98, "confidence": 0.995}, {"text": "more,", "start": 937.98, "end": 938.62, "confidence": 0.989}, {"text": "we", "start": 938.74, "end": 938.76, "confidence": 0.99}, {"text": "encourage", "start": 938.76, "end": 939.24, "confidence": 0.853}, {"text": "you", "start": 939.24, "end": 939.38, "confidence": 0.994}, {"text": "to", "start": 939.38, "end": 939.6, "confidence": 0.999}, {"text": "check", "start": 939.6, "end": 939.7, "confidence": 0.965}, {"text": "out", "start": 939.7, "end": 939.8, "confidence": 0.992}, {"text": "the", "start": 939.8, "end": 939.94, "confidence": 0.997}, {"text": "Estimo", "start": 939.94, "end": 940.36, "confidence": 0.772}, {"text": "research", "start": 940.36, "end": 940.82, "confidence": 0.951}, {"text": "paper", "start": 940.82, "end": 941.04, "confidence": 0.908}, {"text": "you", "start": 941.04, "end": 941.18, "confidence": 0.981}, {"text": "sent", "start": 941.18, "end": 941.54, "confidence": 0.9}, {"text": "us.", "start": 941.54, "end": 941.74, "confidence": 0.978}, {"text": "It's", "start": 941.88, "end": 942.0, "confidence": 0.985}, {"text": "a", "start": 942.0, "end": 942.18, "confidence": 0.999}, {"text": "treasure", "start": 942.18, "end": 942.44, "confidence": 0.983}, {"text": "trove", "start": 942.44, "end": 942.86, "confidence": 0.752}, {"text": "of", "start": 942.86, "end": 943.0, "confidence": 0.992}, {"text": "insights.", "start": 943.0, "end": 943.78, "confidence": 0.448}, {"text": "And", "start": 943.94, "end": 943.98, "confidence": 0.928}, {"text": "until", "start": 943.98, "end": 944.22, "confidence": 0.925}, {"text": "next", "start": 944.22, "end": 944.52, "confidence": 0.868}, {"text": "time,", "start": 944.52, "end": 944.84, "confidence": 0.994}, {"text": "keep", "start": 945.0, "end": 945.1, "confidence": 0.961}, {"text": "that", "start": 945.1, "end": 945.3, "confidence": 0.994}, {"text": "curiosity", "start": 945.3, "end": 945.9, "confidence": 0.795}, {"text": "burning", "start": 945.9, "end": 946.14, "confidence": 0.954}, {"text": "bright.", "start": 946.14, "end": 946.44, "confidence": 0.963}]}], "language": "en"}